{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load  GCC gt as csv and and train the model with backend.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMa2IK9b42vLTEIlCejIGxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukmals/crowd-monitoring-system-model-development/blob/main/load_GCC_gt_as_csv_and_and_train_the_model_with_backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJaKbi50QHmO",
        "outputId": "99477214-f092-441d-8bff-58f136e759fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evOtGkDMQPEQ",
        "outputId": "d44dc9c1-2133-427c-8143-af7251ee70a5"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTF-WAC-QQE3",
        "outputId": "eb9b7ec0-8c9d-4edd-d149-c7b836239703"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen RAM Free: 25.1 GB  | Proc size: 4.0 GB\n",
            "GPU RAM Free: 1351MB | Used: 14929MB | Util  92% | Total 16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY91bqXTQeLD"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from PIL import Image,ImageFilter,ImageDraw\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import ImageStat\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "# import from library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from torchvision import models"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx5FZS7bQgk6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, \\\n",
        "                stride=1, NL='relu', same_padding=False, bn=False, dilation=1):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) // 2) if same_padding else 0\n",
        "        self.conv = []\n",
        "        if dilation==1:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=dilation, dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else nn.Identity()\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU()\n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      if self.bn is not None:\n",
        "          x = self.bn(x)\n",
        "      if self.relu is not None:\n",
        "          x = self.relu(x)   \n",
        "      return x\n",
        "  \n",
        "# the module definition for the multi-branch in the density head\n",
        "class MultiBranchModule(nn.Module):\n",
        "    def __init__(self, in_channels, sync=False):\n",
        "        super(MultiBranchModule, self).__init__()\n",
        "        self.branch_column1_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column1_2 = BasicConv2d(in_channels//2, in_channels, kernel_size=1, sync=sync)\n",
        "\n",
        "        self.branch_column2_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column2_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=(3, 3), padding=(1, 1), sync=sync)\n",
        "\n",
        "        self.branch_column3_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column3_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=5, padding=2, sync=sync)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_1 = self.branch_column1_1(x)\n",
        "        branch_1 = self.branch_column1_2(branch_1)\n",
        "\n",
        "        branch_2 = self.branch_column2_1(x)\n",
        "        branch_2 = self.branch_column2_2(branch_2)\n",
        "\n",
        "        branch_3 = self.branch_column3_1(x)\n",
        "        branch_3 = self.branch_column3_2(branch_3)\n",
        "\n",
        "        outputs = [branch_1, branch_2, branch_3, x]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "# the module definition for the basic conv module\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, sync=False, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        if sync:\n",
        "            # for sync bn\n",
        "            print('use sync inception')\n",
        "            self.bn = nn.SyncBatchNorm(out_channels, eps=0.001)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(TestNet, self).__init__()\n",
        "        \n",
        "        vgg = models.vgg16_bn(pretrained=pretrained)\n",
        "        \n",
        "        self.backend_feat  = [256,128,64]\n",
        "\n",
        "\n",
        "        # Front End Development VGG - 16 \n",
        "        features = list(vgg.features.children())\n",
        "        # get each stage of the VGG - 16\n",
        "        self.features1 = nn.Sequential(*features[0:6])\n",
        "        self.features2 = nn.Sequential(*features[6:13])\n",
        "        self.features3 = nn.Sequential(*features[13:23])\n",
        "        self.features4 = nn.Sequential(*features[23:33])\n",
        "        self.features5 = nn.Sequential(*features[33:43])\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        self.p5 = nn.Sequential(\n",
        "            Conv2d(512, 1024, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p4 = nn.Sequential(\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(512, 256, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p3 = nn.Sequential(\n",
        "            Conv2d(512 , 256, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p2 = nn.Sequential(\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p1 = nn.Sequential(\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(64, 64, 3, same_padding=True, NL='relu'),\n",
        "        ) \n",
        "\n",
        "        # Multi-Branch moules\n",
        "        self.multi_branch5 = nn.Sequential(\n",
        "            MultiBranchModule(512),\n",
        "            Conv2d(2048, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch4 = nn.Sequential(\n",
        "            MultiBranchModule(256),\n",
        "            Conv2d(1024, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch3 = nn.Sequential(\n",
        "            MultiBranchModule(128),\n",
        "            Conv2d(512, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch2 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch1 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 5,dilation = True)\n",
        "\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x1)\n",
        "        x3 = self.features3(x2)\n",
        "        x4 = self.features4(x3)\n",
        "        x5 = self.features5(x4)\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        x = self.p5(x5)\n",
        "        x5_out = x\n",
        "        x = F.upsample_bilinear(x, size=x4.size()[2:])\n",
        "\n",
        "        x = torch.cat([x4, x], 1)\n",
        "        x = self.p4(x)\n",
        "        x4_out = x\n",
        "        x = F.upsample_bilinear(x, size=x3.size()[2:])\n",
        "\n",
        "        x = torch.cat([x3, x], 1)\n",
        "        x = self.p3(x)\n",
        "        x3_out = x\n",
        "        x = F.upsample_bilinear(x, size=x2.size()[2:])\n",
        "\n",
        "        x = torch.cat([x2, x], 1)\n",
        "        x = self.p2(x)\n",
        "        x2_out = x\n",
        "        x = F.upsample_bilinear(x, size=x1.size()[2:])\n",
        "\n",
        "        x = torch.cat([x1, x], 1)\n",
        "        x = self.p1(x)\n",
        "        x1_out = x\n",
        "\n",
        "\n",
        "        # multi-branch predictions\n",
        "        x5_density = self.multi_branch5(x5_out)\n",
        "        x4_density = self.multi_branch4(x4_out)\n",
        "        x3_density = self.multi_branch3(x3_out)\n",
        "        x2_density = self.multi_branch2(x2_out)\n",
        "        x1_density = self.multi_branch1(x1_out)\n",
        "\n",
        "        # upsample the multi-branch predictions to be the same with the input size\n",
        "        x5_density = F.upsample_nearest(x5_density, size=x1.size()[2:])\n",
        "        x4_density = F.upsample_nearest(x4_density, size=x1.size()[2:])\n",
        "        x3_density = F.upsample_nearest(x3_density, size=x1.size()[2:])\n",
        "        x2_density = F.upsample_nearest(x2_density, size=x1.size()[2:])\n",
        "        x1_density = F.upsample_nearest(x1_density, size=x1.size()[2:])\n",
        "\n",
        "\n",
        "        density_map = torch.cat([x5_density, x4_density, x3_density, x2_density, x1_density], 1)\n",
        "\n",
        "\n",
        "        x_out = self.backend(density_map)\n",
        "        density_map_out = self.output_layer(x_out)\n",
        "        return density_map_out\n",
        "        #return density_map\n",
        "                \n",
        "                \n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    layers = []\n",
        "    dilation_rates = [2,3,5]\n",
        "    #for v in cfg:\n",
        "    for v in range(len(cfg)):\n",
        "        if cfg[v] == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, cfg[v], kernel_size=3, padding=dilation_rates[v],dilation = dilation_rates[v])\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(cfg[v]), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = cfg[v]\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwbP2lpQQo4B"
      },
      "source": [
        "import numbers\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import torch\n",
        "\n",
        "class LabelNormalize(object):\n",
        "    def __init__(self, para):\n",
        "        self.para = para\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # tensor = 1./(tensor+self.para).log()\n",
        "        tensor = torch.from_numpy(np.array(tensor))\n",
        "        tensor = tensor*self.para\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if bbx is None:\n",
        "            for t in self.transforms:\n",
        "                img, mask = t(img, mask)\n",
        "            return img, mask\n",
        "        for t in self.transforms:\n",
        "            img, mask, bbx = t(img, mask, bbx)\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomHorizontallyFlip(object):\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if random.random() < 0.5:\n",
        "            if bbx is None:\n",
        "                return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            w, h = img.size\n",
        "            xmin = w - bbx[:,3]\n",
        "            xmax = w - bbx[:,1]\n",
        "            bbx[:,1] = xmin\n",
        "            bbx[:,3] = xmax\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), bbx\n",
        "        if bbx is None:\n",
        "            return img, mask\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size, padding=0):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "        self.padding = padding\n",
        "\n",
        "    def __call__(self, img, mask):\n",
        "\n",
        "        w, h = img.size\n",
        "        th, tw  = self.size\n",
        "        if w == tw and h == th:\n",
        "            return img, mask\n",
        "        if w < tw or h < th:\n",
        "            return img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST)\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68Cp8FyQsGJ"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(img_path,train = True):\n",
        "    #path = \"/content/drive/MyDrive/GCC_CSV_DataSet/Part 0/scene_00_0/csv_den_maps_k15_s4_544_960\"\n",
        "    gt_path = img_path.replace('.png','.csv').replace('pngs_544_960','csv_den_maps_k15_s4_544_960')\n",
        "    img = Image.open(img_path)\n",
        "    target = pd.read_csv(gt_path, sep=',', header=None).values\n",
        "    target = target.astype(np.float32, copy=False)\n",
        "    target = Image.fromarray(target)\n",
        "    return img,target\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, main_transform = None , img_transform=None, gt_transform = None, train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.main_transform = main_transform\n",
        "        self.img_transform = img_transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "\n",
        "        if self.main_transform is not None:\n",
        "            img, target = self.main_transform(img, target)\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.gt_transform is not None:\n",
        "            target = self.gt_transform(target)   \n",
        "        return img,target"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCj5iWFmQu-N"
      },
      "source": [
        "model = TestNet()\n",
        "model = model.cuda()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtA_rpx_QxaD"
      },
      "source": [
        "def get_image_path(file_path):\n",
        "  file_path_list = file_path.split(\" \")\n",
        "  scene = file_path_list[3][4:]\n",
        "  image_number = file_path_list[4]\n",
        "  image_path = \"/content/drive/MyDrive/GCC_CSV_DataSet/\"+\"Part\"+\"_\"+scene[7]+scene+\"/\"+\"pngs_544_960/\"+image_number+\".png\"\n",
        "  return image_path\n",
        "  \n",
        "def get_image_pathlist(path_list, part):\n",
        "    image_path_list_part_ = []\n",
        "    for line_ in path_list:\n",
        "        if line_.find(part)!=-1:\n",
        "            image_path_list_part_.append(line_)\n",
        "    return image_path_list_part_\n",
        "\n",
        "def extract_image_path_list(image_file, part):\n",
        "  file_ = open(image_file, 'r')\n",
        "  file_list = file_.readlines()\n",
        "  image_path_list_train = []  \n",
        "  for line in file_list:\n",
        "      image_path_list_train.append(get_image_path(line))\n",
        "  train_list = get_image_pathlist(image_path_list_train, part)\n",
        "  print(\"data size: \",len(train_list))\n",
        "  return train_list\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWMxCv84Q1Cn",
        "outputId": "c1528b49-81f0-450b-d583-c37a602e5e3d"
      },
      "source": [
        "train_list = '/content/drive/MyDrive/GCC/train_list.txt'\n",
        "part0_train_list = extract_image_path_list(train_list, \"Part_0\")\n",
        "part1_train_list = extract_image_path_list(train_list, \"Part_1\")\n",
        "part2_train_list = extract_image_path_list(train_list, \"Part_2\")\n",
        "part3_train_list = extract_image_path_list(train_list, \"Part_3\")\n",
        "part4_train_list = extract_image_path_list(train_list, \"Part_4\")\n",
        "part5_train_list = extract_image_path_list(train_list, \"Part_5\")\n",
        "part6_train_list = extract_image_path_list(train_list, \"Part_6\")\n",
        "part7_train_list = extract_image_path_list(train_list, \"Part_7\")\n",
        "part8_train_list = extract_image_path_list(train_list, \"Part_8\")\n",
        "part9_train_list = extract_image_path_list(train_list, \"Part_9\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  1320\n",
            "data size:  1160\n",
            "data size:  1258\n",
            "data size:  1135\n",
            "data size:  1055\n",
            "data size:  1037\n",
            "data size:  1000\n",
            "data size:  1026\n",
            "data size:  992\n",
            "data size:  1461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJHZ2uZjQ5jD",
        "outputId": "a391adcb-68e5-4aaf-c3f5-0bf11d09551e"
      },
      "source": [
        "test_list = '/content/drive/MyDrive/GCC/test_list.txt'\n",
        "part0_test_list = extract_image_path_list(test_list, \"Part_0\")\n",
        "part1_test_list = extract_image_path_list(test_list, \"Part_1\")\n",
        "part2_test_list = extract_image_path_list(test_list, \"Part_2\")\n",
        "part3_test_list = extract_image_path_list(test_list, \"Part_3\")\n",
        "part4_test_list = extract_image_path_list(test_list, \"Part_4\")\n",
        "part5_test_list = extract_image_path_list(test_list, \"Part_5\")\n",
        "part6_test_list = extract_image_path_list(test_list, \"Part_6\")\n",
        "part7_test_list = extract_image_path_list(test_list, \"Part_7\")\n",
        "part8_test_list = extract_image_path_list(test_list, \"Part_8\")\n",
        "part9_test_list = extract_image_path_list(test_list, \"Part_9\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  473\n",
            "data size:  385\n",
            "data size:  415\n",
            "data size:  368\n",
            "data size:  356\n",
            "data size:  335\n",
            "data size:  341\n",
            "data size:  322\n",
            "data size:  335\n",
            "data size:  438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbeOHY0UQ7md"
      },
      "source": [
        "train_data = part0_train_list + part1_train_list+part2_train_list+part3_train_list+part4_train_list+part5_train_list+part6_train_list+part7_train_list+part8_train_list+part9_train_list\n",
        "test_data = part0_test_list + part1_test_list+part2_test_list+part3_test_list+part4_test_list+part5_test_list+part6_test_list+part7_test_list+part8_test_list+part9_test_list"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eObg0vFRQ9tw"
      },
      "source": [
        "sou_main_transform = Compose([\n",
        "        RandomCrop((480,480)),\n",
        "        RandomHorizontallyFlip(),\n",
        "        # Rand_Augment()\n",
        "    ])\n",
        "train_loader = torch.utils.data.DataLoader(ListDataset(train_data,shuffle=True,\n",
        "                                                                main_transform = sou_main_transform,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIn8hVTZRCN0"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(ListDataset(test_data,shuffle=False,\n",
        "                                                                main_transform = None,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NpL1Y-wRFuW",
        "outputId": "9da7255c-1a9d-46fa-e391-57f8a981be6e"
      },
      "source": [
        "lr = 1e-5\n",
        "criterion = nn.MSELoss(size_average=False).cuda()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.95,weight_decay=5 * 1e-4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.98)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT2y1_g0RHyR"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, cur_val):\n",
        "        self.cur_val = cur_val\n",
        "        self.sum += cur_val\n",
        "        self.count += 1\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mOPyHOsRKC7"
      },
      "source": [
        "\n",
        "def mae_mse_update(pred,label,maes,mses=None,ssims=None,psnrs=None,losses=None,cls_id=None):\n",
        "        for num in range(pred.size()[0]):\n",
        "            sub_pred = pred[num].data.cpu().squeeze().numpy()/ 100\n",
        "            sub_label = label[num].data.cpu().squeeze().numpy() / 100\n",
        "            pred_cnt = np.sum(sub_pred)\n",
        "            gt_cnt =   np.sum(sub_label)\n",
        "            mae = abs(pred_cnt - gt_cnt)\n",
        "            mse = (pred_cnt - gt_cnt)*(pred_cnt - gt_cnt)\n",
        "\n",
        "            if ssims and psnrs is not None:\n",
        "                ssims.update(get_ssim(sub_label,sub_pred))\n",
        "                psnrs.update(get_psnr(sub_label,sub_pred))\n",
        "\n",
        "            if cls_id is not None:\n",
        "                maes.update(mae,cls_id)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item(),cls_id)\n",
        "                if mses is not None:\n",
        "                    mses.update(mse,cls_id)\n",
        "            else:\n",
        "                maes.update(mae)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item())\n",
        "                if mses is not None:\n",
        "                    mses.update(mse)\n",
        "\n",
        "        return pred_cnt,gt_cnt"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7lc4zJRLvc",
        "outputId": "67434b63-4631-4e56-ef70-18a3d40d0516"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNet_checkpoint_gcc_data_Whole_aug.pth'\n",
        "end_epoch = 15\n",
        "start_epoch = 0\n",
        "if (os.path.isfile(PATH))==True:\n",
        "  checkpoint = torch.load(PATH)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"Successfully load the check point\")\n",
        "else:\n",
        "  print(\"No check point Available!!!\")\n",
        "print(end_epoch , start_epoch)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully load the check point\n",
            "15 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIZYL2GwRasx",
        "outputId": "8ff778aa-2f66-470c-8214-404a8d6d2607"
      },
      "source": [
        "train_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/train_mae_part1and0.txt\",\"a\")\n",
        "test_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/test_mae_part1and0.txt\",\"a\")\n",
        "train_mae_file.truncate(0)\n",
        "test_mae_file.truncate(0)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUr65zdERvEq",
        "outputId": "5625f70d-2f7c-4da0-eedd-006299b3cd13"
      },
      "source": [
        "for epoch in range(start_epoch,end_epoch):\n",
        "    losses = AverageMeter()\n",
        "    model.train()\n",
        "    train_mae = AverageMeter()\n",
        "    train_mse = AverageMeter()\n",
        "    for i, (img, target) in enumerate(train_loader):\n",
        "\n",
        "        img = img.cuda()\n",
        "        img = Variable(img) \n",
        "        output = model(img)\n",
        "\n",
        "        loss = criterion(output.squeeze(), target.squeeze().cuda())\n",
        "        losses.update(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sou_pred_cnt, sou_label_cnt = mae_mse_update(output, target, train_mae, train_mse)\n",
        "        if i % 1000 == 0:\n",
        "            print('Epoch {}, Loss={:.4f} s_gt={:.1f} s_pre={:.1f}, lr={:.4f}'.format(\n",
        "                    epoch, loss.item(), sou_label_cnt,sou_pred_cnt, optimizer.param_groups[0]['lr']*10000))\n",
        "    \n",
        "    #scheduler.step()  \n",
        "    print('train_mae_sou', float(train_mae.avg), epoch)\n",
        "    print('train_mse_sou', float(np.sqrt(train_mse.avg)), epoch)\n",
        "    train_mae_file.write(str(train_mae.avg))\n",
        "    train_mae_file.write(\"\\n\")\n",
        "    torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH) \n",
        "    print(\"testing...................\")  \n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      test_mae = AverageMeter()\n",
        "      test_mse = AverageMeter()\n",
        "      for j, (img_test, target_test) in enumerate(test_loader):\n",
        "          img_test = img_test.cuda()\n",
        "          img_test = Variable(img_test)   \n",
        "          output_test = model(img_test)\n",
        "\n",
        "          sou_pred_cnt_test, sou_label_cnt_test = mae_mse_update(output_test, target_test, test_mae, test_mse)\n",
        "          if j % 1000 == 0:\n",
        "            print('Epoch {}, s_gt={:.1f} s_pre={:.1f} '.format(epoch, sou_label_cnt_test,sou_pred_cnt_test))\n",
        "      print('test_mae_sou', float(test_mae.avg), epoch)\n",
        "      print('test_mse_sou', float(np.sqrt(test_mse.avg)), epoch)\n",
        "      test_mae_file.write(str(test_mae.avg))\n",
        "      test_mae_file.write(\"\\n\")\n",
        "\n",
        "train_mae_file.close()\n",
        "test_mae_file.close()\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withbackend.pth'\n",
        "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3770: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss=3392.4014 s_gt=23.0 s_pre=15.1, lr=0.1000\n",
            "Epoch 13, Loss=1381.0873 s_gt=42.3 s_pre=36.5, lr=0.1000\n",
            "Epoch 13, Loss=49351.5312 s_gt=1316.8 s_pre=1387.1, lr=0.1000\n",
            "Epoch 13, Loss=9298.5752 s_gt=166.3 s_pre=149.6, lr=0.1000\n",
            "Epoch 13, Loss=420.7001 s_gt=0.0 s_pre=13.2, lr=0.1000\n",
            "Epoch 13, Loss=2338.4546 s_gt=30.0 s_pre=48.9, lr=0.1000\n",
            "train_mae_sou 34.71612787986424 13\n",
            "train_mse_sou 66.93395318396072 13\n",
            "testing...................\n",
            "Epoch 13, s_gt=1895.6 s_pre=1936.8 \n",
            "Epoch 13, s_gt=565.7 s_pre=361.1 \n",
            "test_mae_sou 106.37844497231161 13\n",
            "test_mse_sou 158.6500394138314 13\n",
            "Epoch 14, Loss=3442.8232 s_gt=24.4 s_pre=-8.6, lr=0.1000\n",
            "Epoch 14, Loss=6007.3164 s_gt=158.4 s_pre=124.3, lr=0.1000\n",
            "Epoch 14, Loss=19089.0020 s_gt=515.9 s_pre=642.8, lr=0.1000\n",
            "Epoch 14, Loss=7697.4189 s_gt=66.5 s_pre=27.9, lr=0.1000\n",
            "Epoch 14, Loss=452.5775 s_gt=1.0 s_pre=2.5, lr=0.1000\n",
            "Epoch 14, Loss=7270.6738 s_gt=27.1 s_pre=42.5, lr=0.1000\n",
            "train_mae_sou 32.136807044283756 14\n",
            "train_mse_sou 64.30248668547013 14\n",
            "testing...................\n",
            "Epoch 14, s_gt=1895.6 s_pre=1855.6 \n",
            "Epoch 14, s_gt=565.7 s_pre=471.0 \n",
            "test_mae_sou 54.13763761431802 14\n",
            "test_mse_sou 115.27209739042229 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H38QiW6SSBf-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7e08901a-c814-46a8-be7e-a1b8de3bf35e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "x1 = [1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
        "y1 = [108 ,67]+[59, 51, 47]+[44, 40, 40 , 41,38,37 , 35,33,34,32]\n",
        "y2 = [128,89]+[108, 103, 115]+[69, 83, 54,66 , 83,81,109,61,106,54]\n",
        "plt.plot(x1, y1)\n",
        "plt.plot(x1, y2)\n",
        "\n",
        "plt.legend([\"Train MAE\", \"Test MAE\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f70f1057450>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD_4nYCyMewt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}