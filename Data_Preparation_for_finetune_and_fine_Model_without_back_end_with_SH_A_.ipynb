{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Preparation for finetune and  fine Model without back end with SH_A .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLCu4ntcP/Liigr/JDvCCU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukmals/crowd-monitoring-system-model-development/blob/main/Data_Preparation_for_finetune_and_fine_Model_without_back_end_with_SH_A_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaAACAlG8G0C",
        "outputId": "2b4a6294-39a0-4ba5-81cc-7a2e32b052d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjQFwxYO8hdB"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import glob\n",
        "import json\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "# import from library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from torchvision import models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAcENis-8QCm"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(img_path,train = True):\n",
        "    gt_path = img_path.replace('.jpg','.h5').replace('images','ground-truth-h5')\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    gt_file = h5py.File(gt_path, 'r')\n",
        "    target = np.asarray(gt_file['density'])\n",
        "    target = target.astype(np.float32, copy=False)\n",
        "    target = Image.fromarray(target)\n",
        "    return img,target\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, main_transform = None , img_transform=None, gt_transform = None, train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.main_transform = main_transform\n",
        "        self.img_transform = img_transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "\n",
        "        if self.main_transform is not None:\n",
        "            img, target = self.main_transform(img, target)\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.gt_transform is not None:\n",
        "            target = self.gt_transform(target)   \n",
        "        return img,target"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__GLTDsM8ctY"
      },
      "source": [
        "img , target = load_data(\"/content/drive/MyDrive/Model_Test_Data/PartB/test_data/images/IMG_1.jpg\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOqeYUzN9VFH"
      },
      "source": [
        "#img"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3D2c5c5AfKY"
      },
      "source": [
        "import numbers\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import torch\n",
        "\n",
        "class LabelNormalize(object):\n",
        "    def __init__(self, para):\n",
        "        self.para = para\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # tensor = 1./(tensor+self.para).log()\n",
        "        tensor = torch.from_numpy(np.array(tensor))\n",
        "        tensor = tensor*self.para\n",
        "        return tensor\n",
        "\n",
        "# ===============================img tranforms============================\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if bbx is None:\n",
        "            for t in self.transforms:\n",
        "                img, mask = t(img, mask)\n",
        "            return img, mask\n",
        "        for t in self.transforms:\n",
        "            img, mask, bbx = t(img, mask, bbx)\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomHorizontallyFlip(object):\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if random.random() < 0.5:# 随机生成0-1之间的浮点数 ，每次执行生成的不一样\n",
        "            if bbx is None:\n",
        "                return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            w, h = img.size\n",
        "            xmin = w - bbx[:,3]\n",
        "            xmax = w - bbx[:,1]\n",
        "            bbx[:,1] = xmin\n",
        "            bbx[:,3] = xmax\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), bbx\n",
        "        if bbx is None:\n",
        "            return img, mask\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size, padding=0):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "        self.padding = padding\n",
        "\n",
        "    def __call__(self, img, mask):\n",
        "        # if self.padding > 0:\n",
        "        #     img = ImageOps.expand(img, border=self.padding, fill=0)\n",
        "        #     mask = ImageOps.expand(mask, border=self.padding, fill=0)\n",
        "        #\n",
        "        # assert img.size == mask.size\n",
        "        w, h = img.size\n",
        "        th, tw  = self.size\n",
        "        if w == tw and h == th:\n",
        "            return img, mask\n",
        "        if w < tw or h < th:\n",
        "            return img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST)\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOMNEjPlBJ5q"
      },
      "source": [
        "img_train_list = os.listdir(\"/content/drive/MyDrive/Model_Test_Data/PartA/train_data/images\")\n",
        "img_list = []\n",
        "for img in img_train_list:\n",
        "  if '.jpg' in img:\n",
        "    img_list.append(img)\n",
        "\n",
        "sh_train_list = []\n",
        "for img_ in img_list:\n",
        "  img_ = \"/content/drive/MyDrive/Model_Test_Data/PartA/train_data/images/\"+img_\n",
        "  sh_train_list.append(img_)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJBbx44NBVLX",
        "outputId": "233eedbf-2a93-4231-cd4d-660c9963c240"
      },
      "source": [
        "len(sh_train_list)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HabqGLxdAg2C"
      },
      "source": [
        "tar_main_transform = Compose([\n",
        "        RandomCrop(((576,768))),\n",
        "        RandomHorizontallyFlip(),\n",
        "        # Rand_Augment()\n",
        "    ])\n",
        "\n",
        "tar_shot_loader = torch.utils.data.DataLoader(ListDataset(sh_train_list,shuffle=True,\n",
        "                                                                main_transform = tar_main_transform,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgetksvP8VPV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, \\\n",
        "                stride=1, NL='relu', same_padding=False, bn=False, dilation=1):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) // 2) if same_padding else 0\n",
        "        self.conv = []\n",
        "        if dilation==1:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=dilation, dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else nn.Identity()\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU()\n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      if self.bn is not None:\n",
        "          x = self.bn(x)\n",
        "      if self.relu is not None:\n",
        "          x = self.relu(x)   \n",
        "      return x\n",
        "  \n",
        "# the module definition for the multi-branch in the density head\n",
        "class MultiBranchModule(nn.Module):\n",
        "    def __init__(self, in_channels, sync=False):\n",
        "        super(MultiBranchModule, self).__init__()\n",
        "        self.branch_column1_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column1_2 = BasicConv2d(in_channels//2, in_channels, kernel_size=1, sync=sync)\n",
        "\n",
        "        self.branch_column2_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column2_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=(3, 3), padding=(1, 1), sync=sync)\n",
        "\n",
        "        self.branch_column3_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column3_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=5, padding=2, sync=sync)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_1 = self.branch_column1_1(x)\n",
        "        branch_1 = self.branch_column1_2(branch_1)\n",
        "\n",
        "        branch_2 = self.branch_column2_1(x)\n",
        "        branch_2 = self.branch_column2_2(branch_2)\n",
        "\n",
        "        branch_3 = self.branch_column3_1(x)\n",
        "        branch_3 = self.branch_column3_2(branch_3)\n",
        "\n",
        "        outputs = [branch_1, branch_2, branch_3, x]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "# the module definition for the basic conv module\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, sync=False, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        if sync:\n",
        "            # for sync bn\n",
        "            print('use sync inception')\n",
        "            self.bn = nn.SyncBatchNorm(out_channels, eps=0.001)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(TestNet, self).__init__()\n",
        "        \n",
        "        vgg = models.vgg16_bn(pretrained=pretrained)\n",
        "        \n",
        "        self.backend_feat  = [256,128,64]\n",
        "\n",
        "\n",
        "        # Front End Development VGG - 16 \n",
        "        features = list(vgg.features.children())\n",
        "        # get each stage of the VGG - 16\n",
        "        self.features1 = nn.Sequential(*features[0:6])\n",
        "        self.features2 = nn.Sequential(*features[6:13])\n",
        "        self.features3 = nn.Sequential(*features[13:23])\n",
        "        self.features4 = nn.Sequential(*features[23:33])\n",
        "        self.features5 = nn.Sequential(*features[33:43])\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        self.p5 = nn.Sequential(\n",
        "            Conv2d(512, 1024, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p4 = nn.Sequential(\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(512, 256, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p3 = nn.Sequential(\n",
        "            Conv2d(512 , 256, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p2 = nn.Sequential(\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p1 = nn.Sequential(\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(64, 64, 3, same_padding=True, NL='relu'),\n",
        "        ) \n",
        "\n",
        "        # Multi-Branch moules\n",
        "        self.multi_branch5 = nn.Sequential(\n",
        "            MultiBranchModule(512),\n",
        "            Conv2d(2048, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch4 = nn.Sequential(\n",
        "            MultiBranchModule(256),\n",
        "            Conv2d(1024, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch3 = nn.Sequential(\n",
        "            MultiBranchModule(128),\n",
        "            Conv2d(512, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch2 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch1 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 5,dilation = True)\n",
        "\n",
        "        self.output_layer = nn.Conv2d(5, 1, kernel_size=1)\n",
        "\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x1)\n",
        "        x3 = self.features3(x2)\n",
        "        x4 = self.features4(x3)\n",
        "        x5 = self.features5(x4)\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        x = self.p5(x5)\n",
        "        x5_out = x\n",
        "        x = F.upsample_bilinear(x, size=x4.size()[2:])\n",
        "\n",
        "        x = torch.cat([x4, x], 1)\n",
        "        x = self.p4(x)\n",
        "        x4_out = x\n",
        "        x = F.upsample_bilinear(x, size=x3.size()[2:])\n",
        "\n",
        "        x = torch.cat([x3, x], 1)\n",
        "        x = self.p3(x)\n",
        "        x3_out = x\n",
        "        x = F.upsample_bilinear(x, size=x2.size()[2:])\n",
        "\n",
        "        x = torch.cat([x2, x], 1)\n",
        "        x = self.p2(x)\n",
        "        x2_out = x\n",
        "        x = F.upsample_bilinear(x, size=x1.size()[2:])\n",
        "\n",
        "        x = torch.cat([x1, x], 1)\n",
        "        x = self.p1(x)\n",
        "        x1_out = x\n",
        "\n",
        "\n",
        "        # multi-branch predictions\n",
        "        x5_density = self.multi_branch5(x5_out)\n",
        "        x4_density = self.multi_branch4(x4_out)\n",
        "        x3_density = self.multi_branch3(x3_out)\n",
        "        x2_density = self.multi_branch2(x2_out)\n",
        "        x1_density = self.multi_branch1(x1_out)\n",
        "\n",
        "        # upsample the multi-branch predictions to be the same with the input size\n",
        "        x5_density = F.upsample_nearest(x5_density, size=x1.size()[2:])\n",
        "        x4_density = F.upsample_nearest(x4_density, size=x1.size()[2:])\n",
        "        x3_density = F.upsample_nearest(x3_density, size=x1.size()[2:])\n",
        "        x2_density = F.upsample_nearest(x2_density, size=x1.size()[2:])\n",
        "        x1_density = F.upsample_nearest(x1_density, size=x1.size()[2:])\n",
        "\n",
        "\n",
        "        density_map = torch.cat([x5_density, x4_density, x3_density, x2_density, x1_density], 1)\n",
        "\n",
        "\n",
        "        #x_out = self.backend(density_map)\n",
        "        density_map_out = self.output_layer(density_map)\n",
        "        return density_map_out\n",
        "        #return density_map\n",
        "                \n",
        "                \n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    layers = []\n",
        "    dilation_rates = [2,3,5]\n",
        "    #for v in cfg:\n",
        "    for v in range(len(cfg)):\n",
        "        if cfg[v] == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, cfg[v], kernel_size=3, padding=dilation_rates[v],dilation = dilation_rates[v])\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(cfg[v]), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = cfg[v]\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlJFMcuv7q50",
        "outputId": "ccd92f10-635c-41bb-b16e-f67ac3dae77c"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withoutbackend.pth'\n",
        "\n",
        "tar_model = TestNet().cuda()\n",
        "# load the trained model\n",
        "tar_model.load_state_dict(torch.load(model_path))\n",
        "#checkpoint = torch.load(PATH)\n",
        "#model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print('successfully load model from', model_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully load model from /content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withoutbackend.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe4lWhXM109S"
      },
      "source": [
        "lr = 1e-5\n",
        "tar_optimizer =  torch.optim.Adam(tar_model.parameters(), lr = lr, weight_decay=1e-4)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh7xKjfgAgu_",
        "outputId": "1070a30a-25cf-445a-c057-8fcd60c7f510"
      },
      "source": [
        "for epoch in range(1,14):\n",
        "  for i, (shot_img, shot_label) in enumerate(tar_shot_loader, 1):\n",
        "    if i <= 50:\n",
        "      shot_img = shot_img.cuda()\n",
        "      shot_label = shot_label.cuda()\n",
        "      shot_pred = tar_model(shot_img)\n",
        "\n",
        "      loss = F.mse_loss(shot_pred.squeeze(), shot_label.squeeze())\n",
        "      tar_optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      tar_optimizer.step()\n",
        "    else:\n",
        "      break\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withoutbackend_finetuned.pth'\n",
        "torch.save(tar_model.state_dict(), MODEL_SAVE_PATH)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3770: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHNiZSArAsB5"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhMwTnU1Aupy"
      },
      "source": [
        "img_test_list = os.listdir(\"/content/drive/MyDrive/Model_Test_Data/PartA/test_data/images\")\n",
        "img_test_name = []\n",
        "for img in img_test_list:\n",
        "  if '.jpg' in img:\n",
        "    img_test_name.append(img)\n",
        "\n",
        "sh_test_list = []\n",
        "for img_ in img_test_name:\n",
        "  img_ = \"/content/drive/MyDrive/Model_Test_Data/PartA/test_data/images/\"+img_\n",
        "  sh_test_list.append(img_)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYsJaw8-Cht1",
        "outputId": "994d47b5-e62d-4fa2-b194-ddf862d253e8"
      },
      "source": [
        "len(sh_test_list)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "182"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTg163XGCnWp",
        "outputId": "8a0bfeb3-eb3d-424c-9b37-2c2689ab87e5"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withoutbackend_finetuned.pth'\n",
        "\n",
        "model = TestNet().cuda()\n",
        "# load the trained model\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "print('successfully load model from', model_path)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully load model from /content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withoutbackend_finetuned.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKctDCH2Cy6z"
      },
      "source": [
        "pred_transform=transforms.Compose([transforms.ToTensor(), \n",
        "                                  transforms.Resize(480), \n",
        "                                  transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                  std=[0.227743327618, 0.211051672697, 0.184846073389]),])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqb0uilLAglb",
        "outputId": "3b87f2f3-68ad-476b-9492-059f64957745"
      },
      "source": [
        "mae = 0\n",
        "for im_path in sh_test_list:\n",
        "  image = Image.open(im_path).convert('RGB')\n",
        "  #print(image.shape)\n",
        "  output = model(pred_transform(image)[None].cuda())\n",
        "  gt_path = im_path.replace('.jpg','.h5').replace('images','ground-truth-h5')\n",
        "  gt_file = h5py.File(gt_path, 'r')\n",
        "  target = np.asarray(gt_file['density'])\n",
        "  print(\"ground trueth count\", np.sum(target))\n",
        "  output = output.cpu()\n",
        "  output = output.detach().numpy()\n",
        "  print(\"Model Predicted Count\",np.sum(output)/100)\n",
        "  \n",
        "  mae += abs(np.sum(target) -np.sum(output)/100)\n",
        "\n",
        "mae = mae / len(sh_test_list)\n",
        "print(' * TESTING MAE {mae:.3f} '.format(mae=mae))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3770: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ground trueth count 1017.58057\n",
            "Model Predicted Count 652.39109375\n",
            "ground trueth count 175.61815\n",
            "Model Predicted Count 157.048974609375\n",
            "ground trueth count 497.06363\n",
            "Model Predicted Count 308.313984375\n",
            "ground trueth count 217.37694\n",
            "Model Predicted Count 295.3471484375\n",
            "ground trueth count 257.08725\n",
            "Model Predicted Count 231.75708984375\n",
            "ground trueth count 427.6055\n",
            "Model Predicted Count 372.4476953125\n",
            "ground trueth count 383.92606\n",
            "Model Predicted Count 475.19921875\n",
            "ground trueth count 210.39726\n",
            "Model Predicted Count 228.8810546875\n",
            "ground trueth count 1063.9664\n",
            "Model Predicted Count 721.11265625\n",
            "ground trueth count 1163.238\n",
            "Model Predicted Count 573.8032421875\n",
            "ground trueth count 171.82942\n",
            "Model Predicted Count 289.81923828125\n",
            "ground trueth count 292.20493\n",
            "Model Predicted Count 215.2463671875\n",
            "ground trueth count 1225.8102\n",
            "Model Predicted Count 762.68984375\n",
            "ground trueth count 373.51428\n",
            "Model Predicted Count 458.8263671875\n",
            "ground trueth count 285.33514\n",
            "Model Predicted Count 347.33078125\n",
            "ground trueth count 437.55542\n",
            "Model Predicted Count 306.71859375\n",
            "ground trueth count 254.88063\n",
            "Model Predicted Count 313.155390625\n",
            "ground trueth count 65.99532\n",
            "Model Predicted Count 227.09283203125\n",
            "ground trueth count 130.56168\n",
            "Model Predicted Count 203.891953125\n",
            "ground trueth count 982.9976\n",
            "Model Predicted Count 413.4196875\n",
            "ground trueth count 245.3326\n",
            "Model Predicted Count 303.24076171875\n",
            "ground trueth count 1588.7798\n",
            "Model Predicted Count 349.639140625\n",
            "ground trueth count 140.8374\n",
            "Model Predicted Count 127.5057421875\n",
            "ground trueth count 319.36566\n",
            "Model Predicted Count 163.431123046875\n",
            "ground trueth count 111.64411\n",
            "Model Predicted Count 225.298828125\n",
            "ground trueth count 220.17723\n",
            "Model Predicted Count 175.713125\n",
            "ground trueth count 1186.7006\n",
            "Model Predicted Count 415.6117578125\n",
            "ground trueth count 237.53749\n",
            "Model Predicted Count 279.73478515625\n",
            "ground trueth count 448.3899\n",
            "Model Predicted Count 219.47888671875\n",
            "ground trueth count 260.2796\n",
            "Model Predicted Count 311.9715234375\n",
            "ground trueth count 1204.2681\n",
            "Model Predicted Count 902.17625\n",
            "ground trueth count 412.44034\n",
            "Model Predicted Count 386.822109375\n",
            "ground trueth count 1145.509\n",
            "Model Predicted Count 376.737890625\n",
            "ground trueth count 755.43384\n",
            "Model Predicted Count 478.899921875\n",
            "ground trueth count 247.96066\n",
            "Model Predicted Count 185.72998046875\n",
            "ground trueth count 392.4957\n",
            "Model Predicted Count 462.63671875\n",
            "ground trueth count 254.70976\n",
            "Model Predicted Count 368.531875\n",
            "ground trueth count 583.2348\n",
            "Model Predicted Count 563.840390625\n",
            "ground trueth count 918.2924\n",
            "Model Predicted Count 564.2478125\n",
            "ground trueth count 295.35873\n",
            "Model Predicted Count 375.55078125\n",
            "ground trueth count 208.78564\n",
            "Model Predicted Count 334.7991015625\n",
            "ground trueth count 284.85266\n",
            "Model Predicted Count 287.70447265625\n",
            "ground trueth count 594.7378\n",
            "Model Predicted Count 579.4358984375\n",
            "ground trueth count 334.9111\n",
            "Model Predicted Count 397.611953125\n",
            "ground trueth count 68.211365\n",
            "Model Predicted Count 221.97171875\n",
            "ground trueth count 206.71077\n",
            "Model Predicted Count 181.81759765625\n",
            "ground trueth count 160.93246\n",
            "Model Predicted Count 256.4705859375\n",
            "ground trueth count 88.89336\n",
            "Model Predicted Count 110.29955078125\n",
            "ground trueth count 1293.5508\n",
            "Model Predicted Count 725.26453125\n",
            "ground trueth count 270.47882\n",
            "Model Predicted Count 248.54591796875\n",
            "ground trueth count 99.04653\n",
            "Model Predicted Count 219.5143359375\n",
            "ground trueth count 129.81789\n",
            "Model Predicted Count 269.195234375\n",
            "ground trueth count 372.23004\n",
            "Model Predicted Count 406.6800390625\n",
            "ground trueth count 580.9203\n",
            "Model Predicted Count 531.10796875\n",
            "ground trueth count 472.01843\n",
            "Model Predicted Count 406.974609375\n",
            "ground trueth count 481.11554\n",
            "Model Predicted Count 522.4238671875\n",
            "ground trueth count 224.98378\n",
            "Model Predicted Count 339.70625\n",
            "ground trueth count 348.45786\n",
            "Model Predicted Count 330.058046875\n",
            "ground trueth count 252.16818\n",
            "Model Predicted Count 389.634375\n",
            "ground trueth count 352.66354\n",
            "Model Predicted Count 492.44265625\n",
            "ground trueth count 476.91812\n",
            "Model Predicted Count 412.8679296875\n",
            "ground trueth count 1169.3971\n",
            "Model Predicted Count 910.329140625\n",
            "ground trueth count 389.61166\n",
            "Model Predicted Count 503.02328125\n",
            "ground trueth count 214.82822\n",
            "Model Predicted Count 323.14203125\n",
            "ground trueth count 107.51276\n",
            "Model Predicted Count 151.44064453125\n",
            "ground trueth count 413.1861\n",
            "Model Predicted Count 362.953515625\n",
            "ground trueth count 232.52945\n",
            "Model Predicted Count 304.94119140625\n",
            "ground trueth count 195.77771\n",
            "Model Predicted Count 278.68466796875\n",
            "ground trueth count 212.41875\n",
            "Model Predicted Count 254.8786328125\n",
            "ground trueth count 119.18763\n",
            "Model Predicted Count 171.93111328125\n",
            "ground trueth count 191.80472\n",
            "Model Predicted Count 306.60162109375\n",
            "ground trueth count 215.47945\n",
            "Model Predicted Count 346.8758203125\n",
            "ground trueth count 306.81796\n",
            "Model Predicted Count 398.157421875\n",
            "ground trueth count 484.72757\n",
            "Model Predicted Count 562.0283984375\n",
            "ground trueth count 123.24758\n",
            "Model Predicted Count 253.8165234375\n",
            "ground trueth count 477.43127\n",
            "Model Predicted Count 456.5996484375\n",
            "ground trueth count 127.75129\n",
            "Model Predicted Count 148.326162109375\n",
            "ground trueth count 440.7134\n",
            "Model Predicted Count 768.614375\n",
            "ground trueth count 237.83502\n",
            "Model Predicted Count 286.1948828125\n",
            "ground trueth count 663.70416\n",
            "Model Predicted Count 573.1458984375\n",
            "ground trueth count 265.32138\n",
            "Model Predicted Count 204.94390625\n",
            "ground trueth count 161.0757\n",
            "Model Predicted Count 156.68552734375\n",
            "ground trueth count 1147.4834\n",
            "Model Predicted Count 954.07\n",
            "ground trueth count 298.135\n",
            "Model Predicted Count 484.123046875\n",
            "ground trueth count 1577.9174\n",
            "Model Predicted Count 573.6575\n",
            "ground trueth count 162.17773\n",
            "Model Predicted Count 308.40302734375\n",
            "ground trueth count 397.026\n",
            "Model Predicted Count 323.183203125\n",
            "ground trueth count 542.5228\n",
            "Model Predicted Count 403.9380078125\n",
            "ground trueth count 360.14505\n",
            "Model Predicted Count 313.2626171875\n",
            "ground trueth count 225.3106\n",
            "Model Predicted Count 218.97005859375\n",
            "ground trueth count 197.64445\n",
            "Model Predicted Count 232.98765625\n",
            "ground trueth count 397.94012\n",
            "Model Predicted Count 295.95541015625\n",
            "ground trueth count 211.16907\n",
            "Model Predicted Count 304.19716796875\n",
            "ground trueth count 551.4995\n",
            "Model Predicted Count 426.1422265625\n",
            "ground trueth count 493.84286\n",
            "Model Predicted Count 354.9196875\n",
            "ground trueth count 452.25302\n",
            "Model Predicted Count 341.73765625\n",
            "ground trueth count 1105.2463\n",
            "Model Predicted Count 922.418828125\n",
            "ground trueth count 422.756\n",
            "Model Predicted Count 371.4109375\n",
            "ground trueth count 714.09265\n",
            "Model Predicted Count 631.7828125\n",
            "ground trueth count 241.52519\n",
            "Model Predicted Count 158.91072265625\n",
            "ground trueth count 426.90814\n",
            "Model Predicted Count 367.669296875\n",
            "ground trueth count 228.37857\n",
            "Model Predicted Count 235.60302734375\n",
            "ground trueth count 757.57007\n",
            "Model Predicted Count 553.06671875\n",
            "ground trueth count 211.23973\n",
            "Model Predicted Count 258.050625\n",
            "ground trueth count 472.35562\n",
            "Model Predicted Count 346.0385546875\n",
            "ground trueth count 166.54193\n",
            "Model Predicted Count 324.5309375\n",
            "ground trueth count 136.58104\n",
            "Model Predicted Count 186.25966796875\n",
            "ground trueth count 955.494\n",
            "Model Predicted Count 590.627265625\n",
            "ground trueth count 1262.1188\n",
            "Model Predicted Count 925.37359375\n",
            "ground trueth count 360.02533\n",
            "Model Predicted Count 300.618984375\n",
            "ground trueth count 299.8536\n",
            "Model Predicted Count 338.3399609375\n",
            "ground trueth count 243.42487\n",
            "Model Predicted Count 193.54189453125\n",
            "ground trueth count 84.752235\n",
            "Model Predicted Count 234.10759765625\n",
            "ground trueth count 714.8893\n",
            "Model Predicted Count 468.004296875\n",
            "ground trueth count 190.62823\n",
            "Model Predicted Count 242.81162109375\n",
            "ground trueth count 307.76044\n",
            "Model Predicted Count 240.4645703125\n",
            "ground trueth count 193.97136\n",
            "Model Predicted Count 222.93123046875\n",
            "ground trueth count 377.63895\n",
            "Model Predicted Count 302.01458984375\n",
            "ground trueth count 297.93268\n",
            "Model Predicted Count 407.50953125\n",
            "ground trueth count 797.33716\n",
            "Model Predicted Count 696.525234375\n",
            "ground trueth count 376.6646\n",
            "Model Predicted Count 308.22025390625\n",
            "ground trueth count 246.90935\n",
            "Model Predicted Count 177.1898046875\n",
            "ground trueth count 117.44873\n",
            "Model Predicted Count 193.38966796875\n",
            "ground trueth count 234.67282\n",
            "Model Predicted Count 223.85494140625\n",
            "ground trueth count 565.353\n",
            "Model Predicted Count 532.25\n",
            "ground trueth count 510.92313\n",
            "Model Predicted Count 190.330625\n",
            "ground trueth count 308.17908\n",
            "Model Predicted Count 407.5543359375\n",
            "ground trueth count 565.5759\n",
            "Model Predicted Count 484.5621875\n",
            "ground trueth count 210.90535\n",
            "Model Predicted Count 304.05744140625\n",
            "ground trueth count 465.57\n",
            "Model Predicted Count 597.7420703125\n",
            "ground trueth count 293.46448\n",
            "Model Predicted Count 331.0601171875\n",
            "ground trueth count 193.19905\n",
            "Model Predicted Count 221.09283203125\n",
            "ground trueth count 526.4408\n",
            "Model Predicted Count 501.1026953125\n",
            "ground trueth count 848.2386\n",
            "Model Predicted Count 774.175078125\n",
            "ground trueth count 1001.21265\n",
            "Model Predicted Count 476.0831640625\n",
            "ground trueth count 286.9257\n",
            "Model Predicted Count 418.7775390625\n",
            "ground trueth count 358.87964\n",
            "Model Predicted Count 382.5325390625\n",
            "ground trueth count 146.51698\n",
            "Model Predicted Count 186.711875\n",
            "ground trueth count 664.6127\n",
            "Model Predicted Count 336.921953125\n",
            "ground trueth count 408.98007\n",
            "Model Predicted Count 434.530859375\n",
            "ground trueth count 799.2488\n",
            "Model Predicted Count 442.5210546875\n",
            "ground trueth count 190.22192\n",
            "Model Predicted Count 264.03640625\n",
            "ground trueth count 583.17126\n",
            "Model Predicted Count 610.961796875\n",
            "ground trueth count 352.79382\n",
            "Model Predicted Count 403.1432421875\n",
            "ground trueth count 130.97087\n",
            "Model Predicted Count 251.3934375\n",
            "ground trueth count 818.8945\n",
            "Model Predicted Count 711.71859375\n",
            "ground trueth count 213.44844\n",
            "Model Predicted Count 224.705078125\n",
            "ground trueth count 345.22836\n",
            "Model Predicted Count 424.650703125\n",
            "ground trueth count 191.32611\n",
            "Model Predicted Count 237.816015625\n",
            "ground trueth count 290.83832\n",
            "Model Predicted Count 361.2944921875\n",
            "ground trueth count 151.19795\n",
            "Model Predicted Count 214.693203125\n",
            "ground trueth count 1114.8992\n",
            "Model Predicted Count 490.4109765625\n",
            "ground trueth count 332.1628\n",
            "Model Predicted Count 261.8803515625\n",
            "ground trueth count 174.67075\n",
            "Model Predicted Count 325.85861328125\n",
            "ground trueth count 479.42715\n",
            "Model Predicted Count 548.3484765625\n",
            "ground trueth count 598.341\n",
            "Model Predicted Count 478.823203125\n",
            "ground trueth count 159.30164\n",
            "Model Predicted Count 183.3930078125\n",
            "ground trueth count 1323.5518\n",
            "Model Predicted Count 638.8678125\n",
            "ground trueth count 119.68352\n",
            "Model Predicted Count 197.046796875\n",
            "ground trueth count 350.43814\n",
            "Model Predicted Count 673.040625\n",
            "ground trueth count 155.25705\n",
            "Model Predicted Count 167.8203125\n",
            "ground trueth count 177.68884\n",
            "Model Predicted Count 222.46130859375\n",
            "ground trueth count 414.25952\n",
            "Model Predicted Count 406.1830078125\n",
            "ground trueth count 211.93158\n",
            "Model Predicted Count 221.63283203125\n",
            "ground trueth count 214.01727\n",
            "Model Predicted Count 195.310546875\n",
            "ground trueth count 90.65801\n",
            "Model Predicted Count 162.5459765625\n",
            "ground trueth count 269.53113\n",
            "Model Predicted Count 233.626953125\n",
            "ground trueth count 570.2489\n",
            "Model Predicted Count 384.897578125\n",
            "ground trueth count 204.68532\n",
            "Model Predicted Count 161.298291015625\n",
            "ground trueth count 240.43091\n",
            "Model Predicted Count 294.65212890625\n",
            "ground trueth count 367.93152\n",
            "Model Predicted Count 222.181484375\n",
            "ground trueth count 84.66741\n",
            "Model Predicted Count 102.153818359375\n",
            "ground trueth count 468.91245\n",
            "Model Predicted Count 421.9142578125\n",
            "ground trueth count 146.89885\n",
            "Model Predicted Count 194.90650390625\n",
            "ground trueth count 1358.6504\n",
            "Model Predicted Count 406.013203125\n",
            "ground trueth count 2244.069\n",
            "Model Predicted Count 989.8128125\n",
            "ground trueth count 250.42401\n",
            "Model Predicted Count 221.35755859375\n",
            "ground trueth count 185.49461\n",
            "Model Predicted Count 249.4258203125\n",
            "ground trueth count 376.90973\n",
            "Model Predicted Count 448.2281640625\n",
            "ground trueth count 240.05856\n",
            "Model Predicted Count 225.156875\n",
            "ground trueth count 95.6099\n",
            "Model Predicted Count 157.1440625\n",
            "ground trueth count 63.758347\n",
            "Model Predicted Count 199.3966796875\n",
            " * TESTING MAE 143.712 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxNWUjaH9Xm0"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRMADbzN-7EZ"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcbBwkj7947J"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSWjdNV69Z27"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EclqD9IX9p-3"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgdBP0fL9zWN"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmo2CT9T99kO"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJJwHTv--AkP"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm2ExUr6_AXq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}