{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load  GCC gt as csv and model train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO6TRQYp4DPyPIL4THSdpVl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "261c8119c95e4da4b6b245da10c15a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61d83f0ad2d04ddeab36b47004065060",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9ca6fa0500b74ec09fda4917ee1f5243",
              "IPY_MODEL_28eff19d695246e18e517afca7b9f254",
              "IPY_MODEL_e7a9c9426a0e40a09f0a547fc0394f10"
            ]
          }
        },
        "61d83f0ad2d04ddeab36b47004065060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ca6fa0500b74ec09fda4917ee1f5243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e47060c5c3349c7b74d3ff39e30b93f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9cf438376624a66a3bf963e951c4b62"
          }
        },
        "28eff19d695246e18e517afca7b9f254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61b5b0d8d7f2499a84ab409ad8a7e93a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553507836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553507836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fab3b267c894b919749d6640b45a67c"
          }
        },
        "e7a9c9426a0e40a09f0a547fc0394f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4b79a4017864dc0ad15161793f9aca8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:08&lt;00:00, 69.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9a91606665b487797b17e8bbdea2cab"
          }
        },
        "1e47060c5c3349c7b74d3ff39e30b93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9cf438376624a66a3bf963e951c4b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61b5b0d8d7f2499a84ab409ad8a7e93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fab3b267c894b919749d6640b45a67c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4b79a4017864dc0ad15161793f9aca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9a91606665b487797b17e8bbdea2cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukmals/crowd-monitoring-system-model-development/blob/main/load_GCC_gt_as_csv_and_model_train_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJaKbi50QHmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ba81ba-b0b0-4bfd-81a7-015bc5da50b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evOtGkDMQPEQ",
        "outputId": "a36c9798-76a7-4fe7-c994-6179255a10b9"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=203cf4a6c9851d807e922dafcba8f7ccc1388ccfe0315ee0f2dc706bded268ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTF-WAC-QQE3",
        "outputId": "51d31023-d742-4ce6-8eec-9f5bda2816b8"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen RAM Free: 26.3 GB  | Proc size: 120.0 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY91bqXTQeLD"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from PIL import Image,ImageFilter,ImageDraw\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import ImageStat\n",
        "import glob\n",
        "import json\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "# import from library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from torchvision import models"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx5FZS7bQgk6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, \\\n",
        "                stride=1, NL='relu', same_padding=False, bn=False, dilation=1):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) // 2) if same_padding else 0\n",
        "        self.conv = []\n",
        "        if dilation==1:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=dilation, dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else nn.Identity()\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU()\n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      if self.bn is not None:\n",
        "          x = self.bn(x)\n",
        "      if self.relu is not None:\n",
        "          x = self.relu(x)   \n",
        "      return x\n",
        "  \n",
        "# the module definition for the multi-branch in the density head\n",
        "class MultiBranchModule(nn.Module):\n",
        "    def __init__(self, in_channels, sync=False):\n",
        "        super(MultiBranchModule, self).__init__()\n",
        "        self.branch_column1_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column1_2 = BasicConv2d(in_channels//2, in_channels, kernel_size=1, sync=sync)\n",
        "\n",
        "        self.branch_column2_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column2_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=(3, 3), padding=(1, 1), sync=sync)\n",
        "\n",
        "        self.branch_column3_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column3_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=5, padding=2, sync=sync)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_1 = self.branch_column1_1(x)\n",
        "        branch_1 = self.branch_column1_2(branch_1)\n",
        "\n",
        "        branch_2 = self.branch_column2_1(x)\n",
        "        branch_2 = self.branch_column2_2(branch_2)\n",
        "\n",
        "        branch_3 = self.branch_column3_1(x)\n",
        "        branch_3 = self.branch_column3_2(branch_3)\n",
        "\n",
        "        outputs = [branch_1, branch_2, branch_3, x]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "# the module definition for the basic conv module\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, sync=False, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        if sync:\n",
        "            # for sync bn\n",
        "            print('use sync inception')\n",
        "            self.bn = nn.SyncBatchNorm(out_channels, eps=0.001)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(TestNet, self).__init__()\n",
        "        \n",
        "        vgg = models.vgg16_bn(pretrained=pretrained)\n",
        "        \n",
        "        self.backend_feat  = [256,128,64]\n",
        "\n",
        "\n",
        "        # Front End Development VGG - 16 \n",
        "        features = list(vgg.features.children())\n",
        "        # get each stage of the VGG - 16\n",
        "        self.features1 = nn.Sequential(*features[0:6])\n",
        "        self.features2 = nn.Sequential(*features[6:13])\n",
        "        self.features3 = nn.Sequential(*features[13:23])\n",
        "        self.features4 = nn.Sequential(*features[23:33])\n",
        "        self.features5 = nn.Sequential(*features[33:43])\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        self.p5 = nn.Sequential(\n",
        "            Conv2d(512, 1024, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p4 = nn.Sequential(\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(512, 256, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p3 = nn.Sequential(\n",
        "            Conv2d(512 , 256, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p2 = nn.Sequential(\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p1 = nn.Sequential(\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(64, 64, 3, same_padding=True, NL='relu'),\n",
        "        ) \n",
        "\n",
        "        # Multi-Branch moules\n",
        "        self.multi_branch5 = nn.Sequential(\n",
        "            MultiBranchModule(512),\n",
        "            Conv2d(2048, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch4 = nn.Sequential(\n",
        "            MultiBranchModule(256),\n",
        "            Conv2d(1024, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch3 = nn.Sequential(\n",
        "            MultiBranchModule(128),\n",
        "            Conv2d(512, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch2 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch1 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 5,dilation = True)\n",
        "\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x1)\n",
        "        x3 = self.features3(x2)\n",
        "        x4 = self.features4(x3)\n",
        "        x5 = self.features5(x4)\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        x = self.p5(x5)\n",
        "        x5_out = x\n",
        "        x = F.upsample_bilinear(x, size=x4.size()[2:])\n",
        "\n",
        "        x = torch.cat([x4, x], 1)\n",
        "        x = self.p4(x)\n",
        "        x4_out = x\n",
        "        x = F.upsample_bilinear(x, size=x3.size()[2:])\n",
        "\n",
        "        x = torch.cat([x3, x], 1)\n",
        "        x = self.p3(x)\n",
        "        x3_out = x\n",
        "        x = F.upsample_bilinear(x, size=x2.size()[2:])\n",
        "\n",
        "        x = torch.cat([x2, x], 1)\n",
        "        x = self.p2(x)\n",
        "        x2_out = x\n",
        "        x = F.upsample_bilinear(x, size=x1.size()[2:])\n",
        "\n",
        "        x = torch.cat([x1, x], 1)\n",
        "        x = self.p1(x)\n",
        "        x1_out = x\n",
        "\n",
        "\n",
        "        # multi-branch predictions\n",
        "        x5_density = self.multi_branch5(x5_out)\n",
        "        x4_density = self.multi_branch4(x4_out)\n",
        "        x3_density = self.multi_branch3(x3_out)\n",
        "        x2_density = self.multi_branch2(x2_out)\n",
        "        x1_density = self.multi_branch1(x1_out)\n",
        "\n",
        "        # upsample the multi-branch predictions to be the same with the input size\n",
        "        x5_density = F.upsample_nearest(x5_density, size=x1.size()[2:])\n",
        "        x4_density = F.upsample_nearest(x4_density, size=x1.size()[2:])\n",
        "        x3_density = F.upsample_nearest(x3_density, size=x1.size()[2:])\n",
        "        x2_density = F.upsample_nearest(x2_density, size=x1.size()[2:])\n",
        "        x1_density = F.upsample_nearest(x1_density, size=x1.size()[2:])\n",
        "\n",
        "\n",
        "        density_map = torch.cat([x5_density, x4_density, x3_density, x2_density, x1_density], 1)\n",
        "\n",
        "\n",
        "        x_out = self.backend(density_map)\n",
        "        density_map_out = self.output_layer(x_out)\n",
        "        return density_map_out\n",
        "        #return density_map\n",
        "                \n",
        "                \n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    layers = []\n",
        "    dilation_rates = [2,3,5]\n",
        "    #for v in cfg:\n",
        "    for v in range(len(cfg)):\n",
        "        if cfg[v] == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, cfg[v], kernel_size=3, padding=dilation_rates[v],dilation = dilation_rates[v])\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(cfg[v]), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = cfg[v]\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwbP2lpQQo4B"
      },
      "source": [
        "import numbers\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import torch\n",
        "\n",
        "class LabelNormalize(object):\n",
        "    def __init__(self, para):\n",
        "        self.para = para\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # tensor = 1./(tensor+self.para).log()\n",
        "        tensor = torch.from_numpy(np.array(tensor))\n",
        "        tensor = tensor*self.para\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if bbx is None:\n",
        "            for t in self.transforms:\n",
        "                img, mask = t(img, mask)\n",
        "            return img, mask\n",
        "        for t in self.transforms:\n",
        "            img, mask, bbx = t(img, mask, bbx)\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomHorizontallyFlip(object):\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if random.random() < 0.5:\n",
        "            if bbx is None:\n",
        "                return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            w, h = img.size\n",
        "            xmin = w - bbx[:,3]\n",
        "            xmax = w - bbx[:,1]\n",
        "            bbx[:,1] = xmin\n",
        "            bbx[:,3] = xmax\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), bbx\n",
        "        if bbx is None:\n",
        "            return img, mask\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size, padding=0):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "        self.padding = padding\n",
        "\n",
        "    def __call__(self, img, mask):\n",
        "\n",
        "        w, h = img.size\n",
        "        th, tw  = self.size\n",
        "        if w == tw and h == th:\n",
        "            return img, mask\n",
        "        if w < tw or h < th:\n",
        "            return img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST)\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68Cp8FyQsGJ"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(img_path,train = True):\n",
        "    #path = \"/content/drive/MyDrive/GCC_CSV_DataSet/Part 0/scene_00_0/csv_den_maps_k15_s4_544_960\"\n",
        "    gt_path = img_path.replace('.png','.csv').replace('pngs_544_960','csv_den_maps_k15_s4_544_960')\n",
        "    img = Image.open(img_path)\n",
        "    target = pd.read_csv(gt_path, sep=',', header=None).values\n",
        "    target = target.astype(np.float32, copy=False)\n",
        "    target = Image.fromarray(target)\n",
        "    return img,target\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, main_transform = None , img_transform=None, gt_transform = None, train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.main_transform = main_transform\n",
        "        self.img_transform = img_transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "\n",
        "        if self.main_transform is not None:\n",
        "            img, target = self.main_transform(img, target)\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.gt_transform is not None:\n",
        "            target = self.gt_transform(target)   \n",
        "        return img,target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "261c8119c95e4da4b6b245da10c15a28",
            "61d83f0ad2d04ddeab36b47004065060",
            "9ca6fa0500b74ec09fda4917ee1f5243",
            "28eff19d695246e18e517afca7b9f254",
            "e7a9c9426a0e40a09f0a547fc0394f10",
            "1e47060c5c3349c7b74d3ff39e30b93f",
            "c9cf438376624a66a3bf963e951c4b62",
            "61b5b0d8d7f2499a84ab409ad8a7e93a",
            "2fab3b267c894b919749d6640b45a67c",
            "e4b79a4017864dc0ad15161793f9aca8",
            "a9a91606665b487797b17e8bbdea2cab"
          ]
        },
        "id": "mCj5iWFmQu-N",
        "outputId": "2bffb8a9-7819-4ce2-9df6-52748ff9268f"
      },
      "source": [
        "model = TestNet()\n",
        "model = model.cuda()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "261c8119c95e4da4b6b245da10c15a28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtA_rpx_QxaD"
      },
      "source": [
        "def get_image_path(file_path):\n",
        "  file_path_list = file_path.split(\" \")\n",
        "  scene = file_path_list[3][4:]\n",
        "  image_number = file_path_list[4]\n",
        "  image_path = \"/content/drive/MyDrive/GCC_CSV_DataSet/\"+\"Part\"+\"_\"+scene[7]+scene+\"/\"+\"pngs_544_960/\"+image_number+\".png\"\n",
        "  return image_path\n",
        "  \n",
        "def get_image_pathlist(path_list, part):\n",
        "    image_path_list_part_ = []\n",
        "    for line_ in path_list:\n",
        "        if line_.find(part)!=-1:\n",
        "            image_path_list_part_.append(line_)\n",
        "    return image_path_list_part_\n",
        "\n",
        "def extract_image_path_list(image_file, part):\n",
        "  file_ = open(image_file, 'r')\n",
        "  file_list = file_.readlines()\n",
        "  image_path_list_train = []  \n",
        "  for line in file_list:\n",
        "      image_path_list_train.append(get_image_path(line))\n",
        "  train_list = get_image_pathlist(image_path_list_train, part)\n",
        "  print(\"data size: \",len(train_list))\n",
        "  return train_list\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWMxCv84Q1Cn",
        "outputId": "2088b322-7208-43ef-9730-cd84d1bdd143"
      },
      "source": [
        "train_list = '/content/drive/MyDrive/GCC/train_list.txt'\n",
        "part0_train_list = extract_image_path_list(train_list, \"Part_0\")\n",
        "part1_train_list = extract_image_path_list(train_list, \"Part_1\")\n",
        "part2_train_list = extract_image_path_list(train_list, \"Part_2\")\n",
        "part3_train_list = extract_image_path_list(train_list, \"Part_3\")\n",
        "part4_train_list = extract_image_path_list(train_list, \"Part_4\")\n",
        "part5_train_list = extract_image_path_list(train_list, \"Part_5\")\n",
        "part6_train_list = extract_image_path_list(train_list, \"Part_6\")\n",
        "part7_train_list = extract_image_path_list(train_list, \"Part_7\")\n",
        "part8_train_list = extract_image_path_list(train_list, \"Part_8\")\n",
        "part9_train_list = extract_image_path_list(train_list, \"Part_9\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  1320\n",
            "data size:  1160\n",
            "data size:  1258\n",
            "data size:  1135\n",
            "data size:  1055\n",
            "data size:  1037\n",
            "data size:  1000\n",
            "data size:  1026\n",
            "data size:  992\n",
            "data size:  1461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJHZ2uZjQ5jD",
        "outputId": "d1ea4da7-b2aa-42a2-edb3-b5b888929733"
      },
      "source": [
        "test_list = '/content/drive/MyDrive/GCC/test_list.txt'\n",
        "part0_test_list = extract_image_path_list(test_list, \"Part_0\")\n",
        "part1_test_list = extract_image_path_list(test_list, \"Part_1\")\n",
        "part2_test_list = extract_image_path_list(test_list, \"Part_2\")\n",
        "part3_test_list = extract_image_path_list(test_list, \"Part_3\")\n",
        "part4_test_list = extract_image_path_list(test_list, \"Part_4\")\n",
        "part5_test_list = extract_image_path_list(test_list, \"Part_5\")\n",
        "part6_test_list = extract_image_path_list(test_list, \"Part_6\")\n",
        "part7_test_list = extract_image_path_list(test_list, \"Part_7\")\n",
        "part8_test_list = extract_image_path_list(test_list, \"Part_8\")\n",
        "part9_test_list = extract_image_path_list(test_list, \"Part_9\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  473\n",
            "data size:  385\n",
            "data size:  415\n",
            "data size:  368\n",
            "data size:  356\n",
            "data size:  335\n",
            "data size:  341\n",
            "data size:  322\n",
            "data size:  335\n",
            "data size:  438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbeOHY0UQ7md"
      },
      "source": [
        "train_data = part0_train_list + part1_train_list+part2_train_list+part3_train_list+part4_train_list+part5_train_list+part6_train_list+part7_train_list+part8_train_list+part9_train_list\n",
        "test_data = part0_test_list + part1_test_list+part2_test_list+part3_test_list+part4_test_list+part5_test_list+part6_test_list+part7_test_list+part8_test_list+part9_test_list"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eObg0vFRQ9tw"
      },
      "source": [
        "sou_main_transform = Compose([\n",
        "        RandomCrop((480,480)),\n",
        "        RandomHorizontallyFlip(),\n",
        "        # Rand_Augment()\n",
        "    ])\n",
        "train_loader = torch.utils.data.DataLoader(ListDataset(train_data,shuffle=True,\n",
        "                                                                main_transform = sou_main_transform,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIn8hVTZRCN0"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(ListDataset(test_data,shuffle=False,\n",
        "                                                                main_transform = None,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NpL1Y-wRFuW",
        "outputId": "056a10dd-2bf3-4592-d6c8-9f149a0590c1"
      },
      "source": [
        "lr = 1e-5\n",
        "criterion = nn.MSELoss(size_average=False).cuda()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.95,weight_decay=5 * 1e-4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.98)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT2y1_g0RHyR"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, cur_val):\n",
        "        self.cur_val = cur_val\n",
        "        self.sum += cur_val\n",
        "        self.count += 1\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mOPyHOsRKC7"
      },
      "source": [
        "\n",
        "def mae_mse_update(pred,label,maes,mses=None,ssims=None,psnrs=None,losses=None,cls_id=None):\n",
        "        for num in range(pred.size()[0]):\n",
        "            sub_pred = pred[num].data.cpu().squeeze().numpy()/ 100\n",
        "            sub_label = label[num].data.cpu().squeeze().numpy() / 100\n",
        "            pred_cnt = np.sum(sub_pred)\n",
        "            gt_cnt =   np.sum(sub_label)\n",
        "            mae = abs(pred_cnt - gt_cnt)\n",
        "            mse = (pred_cnt - gt_cnt)*(pred_cnt - gt_cnt)\n",
        "\n",
        "            if ssims and psnrs is not None:\n",
        "                ssims.update(get_ssim(sub_label,sub_pred))\n",
        "                psnrs.update(get_psnr(sub_label,sub_pred))\n",
        "\n",
        "            if cls_id is not None:\n",
        "                maes.update(mae,cls_id)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item(),cls_id)\n",
        "                if mses is not None:\n",
        "                    mses.update(mse,cls_id)\n",
        "            else:\n",
        "                maes.update(mae)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item())\n",
        "                if mses is not None:\n",
        "                    mses.update(mse)\n",
        "\n",
        "        return pred_cnt,gt_cnt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7lc4zJRLvc",
        "outputId": "22b349ca-a7eb-4cbc-f11e-3bf6b14f8c32"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNet_checkpoint_gcc_data_Whole_aug.pth'\n",
        "end_epoch = 100\n",
        "start_epoch = 0\n",
        "if (os.path.isfile(PATH))==True:\n",
        "  checkpoint = torch.load(PATH)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"Successfully load the check point\")\n",
        "else:\n",
        "  print(\"No check point Available!!!\")\n",
        "print(end_epoch , start_epoch)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully load the check point\n",
            "100 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIZYL2GwRasx",
        "outputId": "2dfb71ae-cd0f-48de-ac88-1d680764b785"
      },
      "source": [
        "train_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/train_mae_part1and0.txt\",\"a\")\n",
        "test_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/test_mae_part1and0.txt\",\"a\")\n",
        "train_mae_file.truncate(0)\n",
        "test_mae_file.truncate(0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y4RmO-I_4xq"
      },
      "source": [
        "test_best_mae = 33.85"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUr65zdERvEq",
        "outputId": "9c6052f5-5415-4076-e3c5-96b5f39db7f9"
      },
      "source": [
        "for epoch in range(start_epoch,end_epoch):\n",
        "    losses = AverageMeter()\n",
        "    model.train()\n",
        "    train_mae = AverageMeter()\n",
        "    train_mse = AverageMeter()\n",
        "    for i, (img, target) in enumerate(train_loader):\n",
        "\n",
        "        img = img.cuda()\n",
        "        img = Variable(img) \n",
        "        output = model(img)\n",
        "\n",
        "        loss = criterion(output.squeeze(), target.squeeze().cuda())\n",
        "        losses.update(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sou_pred_cnt, sou_label_cnt = mae_mse_update(output, target, train_mae, train_mse)\n",
        "        if i % 1000 == 0:\n",
        "            print('Epoch {}, Loss={:.4f} s_gt={:.1f} s_pre={:.1f}, lr={:.4f}'.format(\n",
        "                    epoch, loss.item(), sou_label_cnt,sou_pred_cnt, optimizer.param_groups[0]['lr']*10000))\n",
        "    \n",
        "    scheduler.step()  \n",
        "    print('train_mae_sou', float(train_mae.avg), epoch)\n",
        "    print('train_mse_sou', float(np.sqrt(train_mse.avg)), epoch)\n",
        "    train_mae_file.write(str(train_mae.avg))\n",
        "    train_mae_file.write(\"\\n\")\n",
        "  \n",
        "    print(\"testing...................\")  \n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      test_mae = AverageMeter()\n",
        "      test_mse = AverageMeter()\n",
        "      for j, (img_test, target_test) in enumerate(test_loader):\n",
        "          img_test = img_test.cuda()\n",
        "          img_test = Variable(img_test)   \n",
        "          output_test = model(img_test)\n",
        "\n",
        "          sou_pred_cnt_test, sou_label_cnt_test = mae_mse_update(output_test, target_test, test_mae, test_mse)\n",
        "          if j % 1000 == 0:\n",
        "            print('Epoch {}, s_gt={:.1f} s_pre={:.1f} '.format(epoch, sou_label_cnt_test,sou_pred_cnt_test))\n",
        "      print('test_mae_sou', float(test_mae.avg), epoch)\n",
        "      print('test_mse_sou', float(np.sqrt(test_mse.avg)), epoch)\n",
        "      if test_mae.avg<test_best_mae:\n",
        "        test_best_mae = test_mae.avg\n",
        "        print(\"Best Train MAE\", test_best_mae)\n",
        "        MODEL_SAVE_PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withbackend_5.pth'\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "      test_mae_file.write(str(test_mae.avg))\n",
        "      test_mae_file.write(\"\\n\")\n",
        "      torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH) \n",
        "\n",
        "train_mae_file.close()\n",
        "test_mae_file.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3792: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92, Loss=16087.9707 s_gt=912.3 s_pre=866.4, lr=0.0524\n",
            "Epoch 92, Loss=6658.6553 s_gt=7.0 s_pre=9.6, lr=0.0524\n",
            "Epoch 92, Loss=1092.4775 s_gt=59.0 s_pre=58.5, lr=0.0524\n",
            "Epoch 92, Loss=427.2452 s_gt=12.0 s_pre=10.8, lr=0.0524\n",
            "Epoch 92, Loss=24394.6875 s_gt=17.7 s_pre=16.8, lr=0.0524\n",
            "Epoch 92, Loss=21833.6562 s_gt=103.4 s_pre=103.9, lr=0.0524\n",
            "train_mae_sou 12.30828899062769 92\n",
            "train_mse_sou 24.738398892519637 92\n",
            "testing...................\n",
            "Epoch 92, s_gt=1895.6 s_pre=1772.4 \n",
            "Epoch 92, s_gt=565.7 s_pre=506.7 \n",
            "test_mae_sou 57.306059340620116 92\n",
            "test_mse_sou 146.34040528077978 92\n",
            "Epoch 93, Loss=17690.6543 s_gt=941.6 s_pre=851.5, lr=0.0524\n",
            "Epoch 93, Loss=6396.9092 s_gt=8.0 s_pre=10.0, lr=0.0524\n",
            "Epoch 93, Loss=777.7853 s_gt=34.3 s_pre=31.5, lr=0.0524\n",
            "Epoch 93, Loss=227.8517 s_gt=11.4 s_pre=12.9, lr=0.0524\n",
            "Epoch 93, Loss=48220.7344 s_gt=16.0 s_pre=15.7, lr=0.0524\n",
            "Epoch 93, Loss=17485.0527 s_gt=126.2 s_pre=115.0, lr=0.0524\n",
            "train_mae_sou 12.077308747018643 93\n",
            "train_mse_sou 24.368226333588304 93\n",
            "testing...................\n",
            "Epoch 93, s_gt=1895.6 s_pre=1827.5 \n",
            "Epoch 93, s_gt=565.7 s_pre=514.5 \n",
            "test_mae_sou 50.214392575913855 93\n",
            "test_mse_sou 136.34550315388233 93\n",
            "Epoch 94, Loss=16393.4258 s_gt=985.9 s_pre=954.1, lr=0.0513\n",
            "Epoch 94, Loss=8852.1074 s_gt=6.1 s_pre=8.0, lr=0.0513\n",
            "Epoch 94, Loss=1325.9355 s_gt=60.1 s_pre=57.2, lr=0.0513\n",
            "Epoch 94, Loss=391.5821 s_gt=12.0 s_pre=14.5, lr=0.0513\n",
            "Epoch 94, Loss=54928.7500 s_gt=17.6 s_pre=20.4, lr=0.0513\n",
            "Epoch 94, Loss=13146.3154 s_gt=98.1 s_pre=92.4, lr=0.0513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "H38QiW6SSBf-",
        "outputId": "9edd16f3-2215-4165-c2d6-e6ae76b0dfc8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "x1 = [i for i in range(0,86)]\n",
        "y1 = [108 ,67]+[59, 51, 47]+[44, 40, 40 , 41,38,37 , 35,33,34,32,32,31,30,30,29,28,28,27,26,27,25,25 , 26 , 23 , 22 , 24, 23,22,21,21  ,20 , 20, 20,19 ,20,19,19,19,19,18,17,18,18,17,18,17,16,17,17,16,16,16,15,16,16,16,15,15,15,15,15,14,15,15,14,14,14,14,14,14,14,13,14,14,13,13,13,13,13,13,13]\n",
        "y2 = [128,108]+[108, 103, 100]+[99, 88, 83,81 , 83,81,78,71,69,64,69,71,74,73,75,71,65,62,64,60,52, 60, 56 , 52 , 49 , 55, 59,58,50,38 , 43,45 ,45,44,41,39,42,41,42,45,44,42,42,40,39,40,41,42,45,40,43,40,36,39,34,42,44,43,39,41,41,42,43,40,40,38,36,38,40,42,41,42,45,42,39,42,42,41,39,37,33]\n",
        "plt.plot(x1, y1)\n",
        "plt.plot(x1, y2)\n",
        "\n",
        "plt.legend([\"Train MAE\", \"Test MAE\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f493a4d2e10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD_4nYCyMewt"
      },
      "source": [
        "Epoch 87, Loss=873.5103 s_gt=12.0 s_pre=8.0, lr=0.0545\n",
        "Epoch 87, Loss=525.8693 s_gt=6.9 s_pre=10.9, lr=0.0545\n",
        "Epoch 87, Loss=584.4041 s_gt=81.1 s_pre=80.8, lr=0.0545\n",
        "Epoch 87, Loss=4968.6870 s_gt=12.9 s_pre=12.6, lr=0.0545\n",
        "Epoch 87, Loss=735.8824 s_gt=38.0 s_pre=34.6, lr=0.0545\n",
        "Epoch 87, Loss=4866.0815 s_gt=65.1 s_pre=58.8, lr=0.0545\n",
        "train_mae_sou 12.479149307519176 87\n",
        "train_mse_sou 24.888943948175456 87\n",
        "testing...................\n",
        "Epoch 87, s_gt=1895.6 s_pre=1803.1 \n",
        "Epoch 87, s_gt=565.7 s_pre=465.2 \n",
        "test_mae_sou 55.79668885779482 87\n",
        "test_mse_sou 134.97065540912124 87\n",
        "Epoch 88, Loss=509.4996 s_gt=2.0 s_pre=3.7, lr=0.0545\n",
        "Epoch 88, Loss=447.1147 s_gt=5.0 s_pre=8.5, lr=0.0545\n",
        "Epoch 88, Loss=2475.3442 s_gt=166.8 s_pre=170.9, lr=0.0545\n",
        "Epoch 88, Loss=1276.7296 s_gt=13.2 s_pre=10.1, lr=0.0545\n",
        "Epoch 88, Loss=1593.9288 s_gt=102.3 s_pre=105.1, lr=0.0545\n",
        "Epoch 88, Loss=4395.4434 s_gt=70.4 s_pre=58.9, lr=0.0545\n",
        "train_mae_sou 12.692552064458864 88\n",
        "train_mse_sou 25.586126889527446 88\n",
        "testing...................\n",
        "Epoch 88, s_gt=1895.6 s_pre=1835.4 \n",
        "Epoch 88, s_gt=565.7 s_pre=541.4 \n",
        "test_mae_sou 37.40849148474175 88\n",
        "test_mse_sou 100.68114825464883 88\n",
        "Epoch 89, Loss=959.3674 s_gt=2.0 s_pre=5.5, lr=0.0535\n",
        "Epoch 89, Loss=536.9408 s_gt=5.9 s_pre=9.7, lr=0.0535\n",
        "Epoch 89, Loss=2202.5764 s_gt=166.5 s_pre=156.0, lr=0.0535\n",
        "Epoch 89, Loss=1002.4481 s_gt=9.0 s_pre=12.9, lr=0.0535\n",
        "Epoch 89, Loss=901.8981 s_gt=49.4 s_pre=53.0, lr=0.0535\n",
        "Epoch 89, Loss=2963.7048 s_gt=54.2 s_pre=43.6, lr=0.0535\n",
        "train_mae_sou 12.66438981682441 89\n",
        "train_mse_sou 26.250692507467253 89\n",
        "testing...................\n",
        "Epoch 89, s_gt=1895.6 s_pre=1846.3 \n",
        "Epoch 89, s_gt=565.7 s_pre=524.2 \n",
        "test_mae_sou 39.99199535942888 89\n",
        "test_mse_sou 110.36035246792723 89\n",
        "\n",
        "Epoch 90, Loss=646.5372 s_gt=35.8 s_pre=39.6, lr=0.0535\n",
        "Epoch 90, Loss=5416.6172 s_gt=285.0 s_pre=322.8, lr=0.0535\n",
        "Epoch 90, Loss=1083.6299 s_gt=113.3 s_pre=121.8, lr=0.0535\n",
        "Epoch 90, Loss=69312.6406 s_gt=57.4 s_pre=52.4, lr=0.0535\n",
        "Epoch 90, Loss=4491.6001 s_gt=195.3 s_pre=202.7, lr=0.0535\n",
        "Epoch 90, Loss=10992.9209 s_gt=15.4 s_pre=16.8, lr=0.0535\n",
        "train_mae_sou 12.014944836386304 90\n",
        "train_mse_sou 24.777539003662486 90\n",
        "testing...................\n",
        "Epoch 90, s_gt=1895.6 s_pre=1820.9 \n",
        "Epoch 90, s_gt=565.7 s_pre=509.8 \n",
        "test_mae_sou 43.206938930371905 90\n",
        "test_mse_sou 121.20153292950876 90\n",
        "Epoch 91, Loss=750.8062 s_gt=39.0 s_pre=38.7, lr=0.0535\n",
        "Epoch 91, Loss=4567.5249 s_gt=242.9 s_pre=251.1, lr=0.0535\n",
        "Epoch 91, Loss=1083.3939 s_gt=98.4 s_pre=102.7, lr=0.0535\n",
        "Epoch 91, Loss=53011.6680 s_gt=64.0 s_pre=62.9, lr=0.0535\n",
        "Epoch 91, Loss=17944.6602 s_gt=538.2 s_pre=535.7, lr=0.0535\n",
        "Epoch 91, Loss=10476.9678 s_gt=23.0 s_pre=24.8, lr=0.0535\n",
        "train_mae_sou 12.407590258023117 91\n",
        "train_mse_sou 24.683947901944876 91\n",
        "testing...................\n",
        "Epoch 91, s_gt=1895.6 s_pre=1806.7 \n",
        "Epoch 91, s_gt=565.7 s_pre=517.1 \n",
        "test_mae_sou 48.766485980045516 91\n",
        "test_mse_sou 125.55581661519332 91"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kik8rvX4Debv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}