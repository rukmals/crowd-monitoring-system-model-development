{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load  GCC gt as csv and model train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPxTG6J/CMnIiS2dPhNltBQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "261c8119c95e4da4b6b245da10c15a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61d83f0ad2d04ddeab36b47004065060",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9ca6fa0500b74ec09fda4917ee1f5243",
              "IPY_MODEL_28eff19d695246e18e517afca7b9f254",
              "IPY_MODEL_e7a9c9426a0e40a09f0a547fc0394f10"
            ]
          }
        },
        "61d83f0ad2d04ddeab36b47004065060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ca6fa0500b74ec09fda4917ee1f5243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e47060c5c3349c7b74d3ff39e30b93f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9cf438376624a66a3bf963e951c4b62"
          }
        },
        "28eff19d695246e18e517afca7b9f254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61b5b0d8d7f2499a84ab409ad8a7e93a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553507836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553507836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fab3b267c894b919749d6640b45a67c"
          }
        },
        "e7a9c9426a0e40a09f0a547fc0394f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4b79a4017864dc0ad15161793f9aca8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:08&lt;00:00, 69.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9a91606665b487797b17e8bbdea2cab"
          }
        },
        "1e47060c5c3349c7b74d3ff39e30b93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9cf438376624a66a3bf963e951c4b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61b5b0d8d7f2499a84ab409ad8a7e93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fab3b267c894b919749d6640b45a67c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4b79a4017864dc0ad15161793f9aca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9a91606665b487797b17e8bbdea2cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukmals/crowd-monitoring-system-model-development/blob/main/load_GCC_gt_as_csv_and_model_train_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJaKbi50QHmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ba81ba-b0b0-4bfd-81a7-015bc5da50b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evOtGkDMQPEQ",
        "outputId": "a36c9798-76a7-4fe7-c994-6179255a10b9"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=203cf4a6c9851d807e922dafcba8f7ccc1388ccfe0315ee0f2dc706bded268ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTF-WAC-QQE3",
        "outputId": "51d31023-d742-4ce6-8eec-9f5bda2816b8"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen RAM Free: 26.3 GB  | Proc size: 120.0 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY91bqXTQeLD"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from PIL import Image,ImageFilter,ImageDraw\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import ImageStat\n",
        "import glob\n",
        "import json\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "# import from library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from torchvision import models"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx5FZS7bQgk6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, \\\n",
        "                stride=1, NL='relu', same_padding=False, bn=False, dilation=1):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) // 2) if same_padding else 0\n",
        "        self.conv = []\n",
        "        if dilation==1:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=dilation, dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else nn.Identity()\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU()\n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      if self.bn is not None:\n",
        "          x = self.bn(x)\n",
        "      if self.relu is not None:\n",
        "          x = self.relu(x)   \n",
        "      return x\n",
        "  \n",
        "# the module definition for the multi-branch in the density head\n",
        "class MultiBranchModule(nn.Module):\n",
        "    def __init__(self, in_channels, sync=False):\n",
        "        super(MultiBranchModule, self).__init__()\n",
        "        self.branch_column1_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column1_2 = BasicConv2d(in_channels//2, in_channels, kernel_size=1, sync=sync)\n",
        "\n",
        "        self.branch_column2_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column2_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=(3, 3), padding=(1, 1), sync=sync)\n",
        "\n",
        "        self.branch_column3_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column3_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=5, padding=2, sync=sync)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_1 = self.branch_column1_1(x)\n",
        "        branch_1 = self.branch_column1_2(branch_1)\n",
        "\n",
        "        branch_2 = self.branch_column2_1(x)\n",
        "        branch_2 = self.branch_column2_2(branch_2)\n",
        "\n",
        "        branch_3 = self.branch_column3_1(x)\n",
        "        branch_3 = self.branch_column3_2(branch_3)\n",
        "\n",
        "        outputs = [branch_1, branch_2, branch_3, x]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "# the module definition for the basic conv module\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, sync=False, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        if sync:\n",
        "            # for sync bn\n",
        "            print('use sync inception')\n",
        "            self.bn = nn.SyncBatchNorm(out_channels, eps=0.001)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(TestNet, self).__init__()\n",
        "        \n",
        "        vgg = models.vgg16_bn(pretrained=pretrained)\n",
        "        \n",
        "        self.backend_feat  = [256,128,64]\n",
        "\n",
        "\n",
        "        # Front End Development VGG - 16 \n",
        "        features = list(vgg.features.children())\n",
        "        # get each stage of the VGG - 16\n",
        "        self.features1 = nn.Sequential(*features[0:6])\n",
        "        self.features2 = nn.Sequential(*features[6:13])\n",
        "        self.features3 = nn.Sequential(*features[13:23])\n",
        "        self.features4 = nn.Sequential(*features[23:33])\n",
        "        self.features5 = nn.Sequential(*features[33:43])\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        self.p5 = nn.Sequential(\n",
        "            Conv2d(512, 1024, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p4 = nn.Sequential(\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(512, 256, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p3 = nn.Sequential(\n",
        "            Conv2d(512 , 256, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p2 = nn.Sequential(\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p1 = nn.Sequential(\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(64, 64, 3, same_padding=True, NL='relu'),\n",
        "        ) \n",
        "\n",
        "        # Multi-Branch moules\n",
        "        self.multi_branch5 = nn.Sequential(\n",
        "            MultiBranchModule(512),\n",
        "            Conv2d(2048, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch4 = nn.Sequential(\n",
        "            MultiBranchModule(256),\n",
        "            Conv2d(1024, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch3 = nn.Sequential(\n",
        "            MultiBranchModule(128),\n",
        "            Conv2d(512, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch2 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch1 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 5,dilation = True)\n",
        "\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x1)\n",
        "        x3 = self.features3(x2)\n",
        "        x4 = self.features4(x3)\n",
        "        x5 = self.features5(x4)\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        x = self.p5(x5)\n",
        "        x5_out = x\n",
        "        x = F.upsample_bilinear(x, size=x4.size()[2:])\n",
        "\n",
        "        x = torch.cat([x4, x], 1)\n",
        "        x = self.p4(x)\n",
        "        x4_out = x\n",
        "        x = F.upsample_bilinear(x, size=x3.size()[2:])\n",
        "\n",
        "        x = torch.cat([x3, x], 1)\n",
        "        x = self.p3(x)\n",
        "        x3_out = x\n",
        "        x = F.upsample_bilinear(x, size=x2.size()[2:])\n",
        "\n",
        "        x = torch.cat([x2, x], 1)\n",
        "        x = self.p2(x)\n",
        "        x2_out = x\n",
        "        x = F.upsample_bilinear(x, size=x1.size()[2:])\n",
        "\n",
        "        x = torch.cat([x1, x], 1)\n",
        "        x = self.p1(x)\n",
        "        x1_out = x\n",
        "\n",
        "\n",
        "        # multi-branch predictions\n",
        "        x5_density = self.multi_branch5(x5_out)\n",
        "        x4_density = self.multi_branch4(x4_out)\n",
        "        x3_density = self.multi_branch3(x3_out)\n",
        "        x2_density = self.multi_branch2(x2_out)\n",
        "        x1_density = self.multi_branch1(x1_out)\n",
        "\n",
        "        # upsample the multi-branch predictions to be the same with the input size\n",
        "        x5_density = F.upsample_nearest(x5_density, size=x1.size()[2:])\n",
        "        x4_density = F.upsample_nearest(x4_density, size=x1.size()[2:])\n",
        "        x3_density = F.upsample_nearest(x3_density, size=x1.size()[2:])\n",
        "        x2_density = F.upsample_nearest(x2_density, size=x1.size()[2:])\n",
        "        x1_density = F.upsample_nearest(x1_density, size=x1.size()[2:])\n",
        "\n",
        "\n",
        "        density_map = torch.cat([x5_density, x4_density, x3_density, x2_density, x1_density], 1)\n",
        "\n",
        "\n",
        "        x_out = self.backend(density_map)\n",
        "        density_map_out = self.output_layer(x_out)\n",
        "        return density_map_out\n",
        "        #return density_map\n",
        "                \n",
        "                \n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    layers = []\n",
        "    dilation_rates = [2,3,5]\n",
        "    #for v in cfg:\n",
        "    for v in range(len(cfg)):\n",
        "        if cfg[v] == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, cfg[v], kernel_size=3, padding=dilation_rates[v],dilation = dilation_rates[v])\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(cfg[v]), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = cfg[v]\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwbP2lpQQo4B"
      },
      "source": [
        "import numbers\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import torch\n",
        "\n",
        "class LabelNormalize(object):\n",
        "    def __init__(self, para):\n",
        "        self.para = para\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # tensor = 1./(tensor+self.para).log()\n",
        "        tensor = torch.from_numpy(np.array(tensor))\n",
        "        tensor = tensor*self.para\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if bbx is None:\n",
        "            for t in self.transforms:\n",
        "                img, mask = t(img, mask)\n",
        "            return img, mask\n",
        "        for t in self.transforms:\n",
        "            img, mask, bbx = t(img, mask, bbx)\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomHorizontallyFlip(object):\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if random.random() < 0.5:\n",
        "            if bbx is None:\n",
        "                return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            w, h = img.size\n",
        "            xmin = w - bbx[:,3]\n",
        "            xmax = w - bbx[:,1]\n",
        "            bbx[:,1] = xmin\n",
        "            bbx[:,3] = xmax\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), bbx\n",
        "        if bbx is None:\n",
        "            return img, mask\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size, padding=0):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "        self.padding = padding\n",
        "\n",
        "    def __call__(self, img, mask):\n",
        "\n",
        "        w, h = img.size\n",
        "        th, tw  = self.size\n",
        "        if w == tw and h == th:\n",
        "            return img, mask\n",
        "        if w < tw or h < th:\n",
        "            return img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST)\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68Cp8FyQsGJ"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(img_path,train = True):\n",
        "    #path = \"/content/drive/MyDrive/GCC_CSV_DataSet/Part 0/scene_00_0/csv_den_maps_k15_s4_544_960\"\n",
        "    gt_path = img_path.replace('.png','.csv').replace('pngs_544_960','csv_den_maps_k15_s4_544_960')\n",
        "    img = Image.open(img_path)\n",
        "    target = pd.read_csv(gt_path, sep=',', header=None).values\n",
        "    target = target.astype(np.float32, copy=False)\n",
        "    target = Image.fromarray(target)\n",
        "    return img,target\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, main_transform = None , img_transform=None, gt_transform = None, train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.main_transform = main_transform\n",
        "        self.img_transform = img_transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "\n",
        "        if self.main_transform is not None:\n",
        "            img, target = self.main_transform(img, target)\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.gt_transform is not None:\n",
        "            target = self.gt_transform(target)   \n",
        "        return img,target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "261c8119c95e4da4b6b245da10c15a28",
            "61d83f0ad2d04ddeab36b47004065060",
            "9ca6fa0500b74ec09fda4917ee1f5243",
            "28eff19d695246e18e517afca7b9f254",
            "e7a9c9426a0e40a09f0a547fc0394f10",
            "1e47060c5c3349c7b74d3ff39e30b93f",
            "c9cf438376624a66a3bf963e951c4b62",
            "61b5b0d8d7f2499a84ab409ad8a7e93a",
            "2fab3b267c894b919749d6640b45a67c",
            "e4b79a4017864dc0ad15161793f9aca8",
            "a9a91606665b487797b17e8bbdea2cab"
          ]
        },
        "id": "mCj5iWFmQu-N",
        "outputId": "2bffb8a9-7819-4ce2-9df6-52748ff9268f"
      },
      "source": [
        "model = TestNet()\n",
        "model = model.cuda()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "261c8119c95e4da4b6b245da10c15a28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtA_rpx_QxaD"
      },
      "source": [
        "def get_image_path(file_path):\n",
        "  file_path_list = file_path.split(\" \")\n",
        "  scene = file_path_list[3][4:]\n",
        "  image_number = file_path_list[4]\n",
        "  image_path = \"/content/drive/MyDrive/GCC_CSV_DataSet/\"+\"Part\"+\"_\"+scene[7]+scene+\"/\"+\"pngs_544_960/\"+image_number+\".png\"\n",
        "  return image_path\n",
        "  \n",
        "def get_image_pathlist(path_list, part):\n",
        "    image_path_list_part_ = []\n",
        "    for line_ in path_list:\n",
        "        if line_.find(part)!=-1:\n",
        "            image_path_list_part_.append(line_)\n",
        "    return image_path_list_part_\n",
        "\n",
        "def extract_image_path_list(image_file, part):\n",
        "  file_ = open(image_file, 'r')\n",
        "  file_list = file_.readlines()\n",
        "  image_path_list_train = []  \n",
        "  for line in file_list:\n",
        "      image_path_list_train.append(get_image_path(line))\n",
        "  train_list = get_image_pathlist(image_path_list_train, part)\n",
        "  print(\"data size: \",len(train_list))\n",
        "  return train_list\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWMxCv84Q1Cn",
        "outputId": "2088b322-7208-43ef-9730-cd84d1bdd143"
      },
      "source": [
        "train_list = '/content/drive/MyDrive/GCC/train_list.txt'\n",
        "part0_train_list = extract_image_path_list(train_list, \"Part_0\")\n",
        "part1_train_list = extract_image_path_list(train_list, \"Part_1\")\n",
        "part2_train_list = extract_image_path_list(train_list, \"Part_2\")\n",
        "part3_train_list = extract_image_path_list(train_list, \"Part_3\")\n",
        "part4_train_list = extract_image_path_list(train_list, \"Part_4\")\n",
        "part5_train_list = extract_image_path_list(train_list, \"Part_5\")\n",
        "part6_train_list = extract_image_path_list(train_list, \"Part_6\")\n",
        "part7_train_list = extract_image_path_list(train_list, \"Part_7\")\n",
        "part8_train_list = extract_image_path_list(train_list, \"Part_8\")\n",
        "part9_train_list = extract_image_path_list(train_list, \"Part_9\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  1320\n",
            "data size:  1160\n",
            "data size:  1258\n",
            "data size:  1135\n",
            "data size:  1055\n",
            "data size:  1037\n",
            "data size:  1000\n",
            "data size:  1026\n",
            "data size:  992\n",
            "data size:  1461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJHZ2uZjQ5jD",
        "outputId": "d1ea4da7-b2aa-42a2-edb3-b5b888929733"
      },
      "source": [
        "test_list = '/content/drive/MyDrive/GCC/test_list.txt'\n",
        "part0_test_list = extract_image_path_list(test_list, \"Part_0\")\n",
        "part1_test_list = extract_image_path_list(test_list, \"Part_1\")\n",
        "part2_test_list = extract_image_path_list(test_list, \"Part_2\")\n",
        "part3_test_list = extract_image_path_list(test_list, \"Part_3\")\n",
        "part4_test_list = extract_image_path_list(test_list, \"Part_4\")\n",
        "part5_test_list = extract_image_path_list(test_list, \"Part_5\")\n",
        "part6_test_list = extract_image_path_list(test_list, \"Part_6\")\n",
        "part7_test_list = extract_image_path_list(test_list, \"Part_7\")\n",
        "part8_test_list = extract_image_path_list(test_list, \"Part_8\")\n",
        "part9_test_list = extract_image_path_list(test_list, \"Part_9\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  473\n",
            "data size:  385\n",
            "data size:  415\n",
            "data size:  368\n",
            "data size:  356\n",
            "data size:  335\n",
            "data size:  341\n",
            "data size:  322\n",
            "data size:  335\n",
            "data size:  438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbeOHY0UQ7md"
      },
      "source": [
        "train_data = part0_train_list + part1_train_list+part2_train_list+part3_train_list+part4_train_list+part5_train_list+part6_train_list+part7_train_list+part8_train_list+part9_train_list\n",
        "test_data = part0_test_list + part1_test_list+part2_test_list+part3_test_list+part4_test_list+part5_test_list+part6_test_list+part7_test_list+part8_test_list+part9_test_list"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eObg0vFRQ9tw"
      },
      "source": [
        "sou_main_transform = Compose([\n",
        "        RandomCrop((480,480)),\n",
        "        RandomHorizontallyFlip(),\n",
        "        # Rand_Augment()\n",
        "    ])\n",
        "train_loader = torch.utils.data.DataLoader(ListDataset(train_data,shuffle=True,\n",
        "                                                                main_transform = sou_main_transform,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIn8hVTZRCN0"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(ListDataset(test_data,shuffle=False,\n",
        "                                                                main_transform = None,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NpL1Y-wRFuW",
        "outputId": "056a10dd-2bf3-4592-d6c8-9f149a0590c1"
      },
      "source": [
        "lr = 1e-5\n",
        "criterion = nn.MSELoss(size_average=False).cuda()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.95,weight_decay=5 * 1e-4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.98)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT2y1_g0RHyR"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, cur_val):\n",
        "        self.cur_val = cur_val\n",
        "        self.sum += cur_val\n",
        "        self.count += 1\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mOPyHOsRKC7"
      },
      "source": [
        "\n",
        "def mae_mse_update(pred,label,maes,mses=None,ssims=None,psnrs=None,losses=None,cls_id=None):\n",
        "        for num in range(pred.size()[0]):\n",
        "            sub_pred = pred[num].data.cpu().squeeze().numpy()/ 100\n",
        "            sub_label = label[num].data.cpu().squeeze().numpy() / 100\n",
        "            pred_cnt = np.sum(sub_pred)\n",
        "            gt_cnt =   np.sum(sub_label)\n",
        "            mae = abs(pred_cnt - gt_cnt)\n",
        "            mse = (pred_cnt - gt_cnt)*(pred_cnt - gt_cnt)\n",
        "\n",
        "            if ssims and psnrs is not None:\n",
        "                ssims.update(get_ssim(sub_label,sub_pred))\n",
        "                psnrs.update(get_psnr(sub_label,sub_pred))\n",
        "\n",
        "            if cls_id is not None:\n",
        "                maes.update(mae,cls_id)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item(),cls_id)\n",
        "                if mses is not None:\n",
        "                    mses.update(mse,cls_id)\n",
        "            else:\n",
        "                maes.update(mae)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item())\n",
        "                if mses is not None:\n",
        "                    mses.update(mse)\n",
        "\n",
        "        return pred_cnt,gt_cnt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7lc4zJRLvc",
        "outputId": "22b349ca-a7eb-4cbc-f11e-3bf6b14f8c32"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNet_checkpoint_gcc_data_Whole_aug.pth'\n",
        "end_epoch = 100\n",
        "start_epoch = 0\n",
        "if (os.path.isfile(PATH))==True:\n",
        "  checkpoint = torch.load(PATH)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"Successfully load the check point\")\n",
        "else:\n",
        "  print(\"No check point Available!!!\")\n",
        "print(end_epoch , start_epoch)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully load the check point\n",
            "100 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIZYL2GwRasx",
        "outputId": "2dfb71ae-cd0f-48de-ac88-1d680764b785"
      },
      "source": [
        "train_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/train_mae_part1and0.txt\",\"a\")\n",
        "test_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/test_mae_part1and0.txt\",\"a\")\n",
        "train_mae_file.truncate(0)\n",
        "test_mae_file.truncate(0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y4RmO-I_4xq"
      },
      "source": [
        "test_best_mae = 33.85"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUr65zdERvEq",
        "outputId": "9c6052f5-5415-4076-e3c5-96b5f39db7f9"
      },
      "source": [
        "for epoch in range(start_epoch,end_epoch):\n",
        "    losses = AverageMeter()\n",
        "    model.train()\n",
        "    train_mae = AverageMeter()\n",
        "    train_mse = AverageMeter()\n",
        "    for i, (img, target) in enumerate(train_loader):\n",
        "\n",
        "        img = img.cuda()\n",
        "        img = Variable(img) \n",
        "        output = model(img)\n",
        "\n",
        "        loss = criterion(output.squeeze(), target.squeeze().cuda())\n",
        "        losses.update(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sou_pred_cnt, sou_label_cnt = mae_mse_update(output, target, train_mae, train_mse)\n",
        "        if i % 1000 == 0:\n",
        "            print('Epoch {}, Loss={:.4f} s_gt={:.1f} s_pre={:.1f}, lr={:.4f}'.format(\n",
        "                    epoch, loss.item(), sou_label_cnt,sou_pred_cnt, optimizer.param_groups[0]['lr']*10000))\n",
        "    \n",
        "    scheduler.step()  \n",
        "    print('train_mae_sou', float(train_mae.avg), epoch)\n",
        "    print('train_mse_sou', float(np.sqrt(train_mse.avg)), epoch)\n",
        "    train_mae_file.write(str(train_mae.avg))\n",
        "    train_mae_file.write(\"\\n\")\n",
        "  \n",
        "    print(\"testing...................\")  \n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      test_mae = AverageMeter()\n",
        "      test_mse = AverageMeter()\n",
        "      for j, (img_test, target_test) in enumerate(test_loader):\n",
        "          img_test = img_test.cuda()\n",
        "          img_test = Variable(img_test)   \n",
        "          output_test = model(img_test)\n",
        "\n",
        "          sou_pred_cnt_test, sou_label_cnt_test = mae_mse_update(output_test, target_test, test_mae, test_mse)\n",
        "          if j % 1000 == 0:\n",
        "            print('Epoch {}, s_gt={:.1f} s_pre={:.1f} '.format(epoch, sou_label_cnt_test,sou_pred_cnt_test))\n",
        "      print('test_mae_sou', float(test_mae.avg), epoch)\n",
        "      print('test_mse_sou', float(np.sqrt(test_mse.avg)), epoch)\n",
        "      if test_mae.avg<test_best_mae:\n",
        "        test_best_mae = test_mae.avg\n",
        "        print(\"Best Train MAE\", test_best_mae)\n",
        "        MODEL_SAVE_PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withbackend_5.pth'\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "      test_mae_file.write(str(test_mae.avg))\n",
        "      test_mae_file.write(\"\\n\")\n",
        "      torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH) \n",
        "\n",
        "train_mae_file.close()\n",
        "test_mae_file.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3792: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92, Loss=16087.9707 s_gt=912.3 s_pre=866.4, lr=0.0524\n",
            "Epoch 92, Loss=6658.6553 s_gt=7.0 s_pre=9.6, lr=0.0524\n",
            "Epoch 92, Loss=1092.4775 s_gt=59.0 s_pre=58.5, lr=0.0524\n",
            "Epoch 92, Loss=427.2452 s_gt=12.0 s_pre=10.8, lr=0.0524\n",
            "Epoch 92, Loss=24394.6875 s_gt=17.7 s_pre=16.8, lr=0.0524\n",
            "Epoch 92, Loss=21833.6562 s_gt=103.4 s_pre=103.9, lr=0.0524\n",
            "train_mae_sou 12.30828899062769 92\n",
            "train_mse_sou 24.738398892519637 92\n",
            "testing...................\n",
            "Epoch 92, s_gt=1895.6 s_pre=1772.4 \n",
            "Epoch 92, s_gt=565.7 s_pre=506.7 \n",
            "test_mae_sou 57.306059340620116 92\n",
            "test_mse_sou 146.34040528077978 92\n",
            "Epoch 93, Loss=17690.6543 s_gt=941.6 s_pre=851.5, lr=0.0524\n",
            "Epoch 93, Loss=6396.9092 s_gt=8.0 s_pre=10.0, lr=0.0524\n",
            "Epoch 93, Loss=777.7853 s_gt=34.3 s_pre=31.5, lr=0.0524\n",
            "Epoch 93, Loss=227.8517 s_gt=11.4 s_pre=12.9, lr=0.0524\n",
            "Epoch 93, Loss=48220.7344 s_gt=16.0 s_pre=15.7, lr=0.0524\n",
            "Epoch 93, Loss=17485.0527 s_gt=126.2 s_pre=115.0, lr=0.0524\n",
            "train_mae_sou 12.077308747018643 93\n",
            "train_mse_sou 24.368226333588304 93\n",
            "testing...................\n",
            "Epoch 93, s_gt=1895.6 s_pre=1827.5 \n",
            "Epoch 93, s_gt=565.7 s_pre=514.5 \n",
            "test_mae_sou 50.214392575913855 93\n",
            "test_mse_sou 136.34550315388233 93\n",
            "Epoch 94, Loss=16393.4258 s_gt=985.9 s_pre=954.1, lr=0.0513\n",
            "Epoch 94, Loss=8852.1074 s_gt=6.1 s_pre=8.0, lr=0.0513\n",
            "Epoch 94, Loss=1325.9355 s_gt=60.1 s_pre=57.2, lr=0.0513\n",
            "Epoch 94, Loss=391.5821 s_gt=12.0 s_pre=14.5, lr=0.0513\n",
            "Epoch 94, Loss=54928.7500 s_gt=17.6 s_pre=20.4, lr=0.0513\n",
            "Epoch 94, Loss=13146.3154 s_gt=98.1 s_pre=92.4, lr=0.0513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "H38QiW6SSBf-",
        "outputId": "3e7e5b47-5a7e-426e-d650-ff15b1c3f602"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "x1 = [i for i in range(0,86)]\n",
        "y1 = [108 ,67]+[59, 51, 47]+[44, 40, 40 , 41,38,37 , 35,33,34,32,32,31,30,30,29,28,28,27,26,27,25,25 , 26 , 23 , 22 , 24, 23,22,21,21  ,20 , 20, 20,19 ,20,19,19,19,19,18,17,18,18,17,18,17,16,17,17,16,16,16,15,16,16,16,15,15,15,15,15,14,15,15,14,14,14,14,14,14,14,13,14,14,13,13,13,13,13,13,13]\n",
        "y2 = [128,108]+[108, 103, 100]+[99, 88, 83,81 , 83,81,78,71,69,54 ,61,71,80,76,80,41,65,42,44,60,42, 60, 56 , 72 , 49 , 60, 65,58,50,38 , 43,45 ,45,44,41,39,42,41,42,45,44,42,42,40,39,40,41,42,45,40,43,40,36,39,34,42,44,43,39,41,41,42,43,40,40,38,36,38,40,42,41,42,45,42,39,42,42,41,39,37,33]\n",
        "plt.plot(x1, y1)\n",
        "plt.plot(x1, y2)\n",
        "\n",
        "plt.legend([\"Train MAE\", \"Test MAE\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbc5130a9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD_4nYCyMewt"
      },
      "source": [
        "Epoch 87, Loss=873.5103 s_gt=12.0 s_pre=8.0, lr=0.0545\n",
        "Epoch 87, Loss=525.8693 s_gt=6.9 s_pre=10.9, lr=0.0545\n",
        "Epoch 87, Loss=584.4041 s_gt=81.1 s_pre=80.8, lr=0.0545\n",
        "Epoch 87, Loss=4968.6870 s_gt=12.9 s_pre=12.6, lr=0.0545\n",
        "Epoch 87, Loss=735.8824 s_gt=38.0 s_pre=34.6, lr=0.0545\n",
        "Epoch 87, Loss=4866.0815 s_gt=65.1 s_pre=58.8, lr=0.0545\n",
        "train_mae_sou 12.479149307519176 87\n",
        "train_mse_sou 24.888943948175456 87\n",
        "testing...................\n",
        "Epoch 87, s_gt=1895.6 s_pre=1803.1 \n",
        "Epoch 87, s_gt=565.7 s_pre=465.2 \n",
        "test_mae_sou 55.79668885779482 87\n",
        "test_mse_sou 134.97065540912124 87\n",
        "Epoch 88, Loss=509.4996 s_gt=2.0 s_pre=3.7, lr=0.0545\n",
        "Epoch 88, Loss=447.1147 s_gt=5.0 s_pre=8.5, lr=0.0545\n",
        "Epoch 88, Loss=2475.3442 s_gt=166.8 s_pre=170.9, lr=0.0545\n",
        "Epoch 88, Loss=1276.7296 s_gt=13.2 s_pre=10.1, lr=0.0545\n",
        "Epoch 88, Loss=1593.9288 s_gt=102.3 s_pre=105.1, lr=0.0545\n",
        "Epoch 88, Loss=4395.4434 s_gt=70.4 s_pre=58.9, lr=0.0545\n",
        "train_mae_sou 12.692552064458864 88\n",
        "train_mse_sou 25.586126889527446 88\n",
        "testing...................\n",
        "Epoch 88, s_gt=1895.6 s_pre=1835.4 \n",
        "Epoch 88, s_gt=565.7 s_pre=541.4 \n",
        "test_mae_sou 37.40849148474175 88\n",
        "test_mse_sou 100.68114825464883 88\n",
        "Epoch 89, Loss=959.3674 s_gt=2.0 s_pre=5.5, lr=0.0535\n",
        "Epoch 89, Loss=536.9408 s_gt=5.9 s_pre=9.7, lr=0.0535\n",
        "Epoch 89, Loss=2202.5764 s_gt=166.5 s_pre=156.0, lr=0.0535\n",
        "Epoch 89, Loss=1002.4481 s_gt=9.0 s_pre=12.9, lr=0.0535\n",
        "Epoch 89, Loss=901.8981 s_gt=49.4 s_pre=53.0, lr=0.0535\n",
        "Epoch 89, Loss=2963.7048 s_gt=54.2 s_pre=43.6, lr=0.0535\n",
        "train_mae_sou 12.66438981682441 89\n",
        "train_mse_sou 26.250692507467253 89\n",
        "testing...................\n",
        "Epoch 89, s_gt=1895.6 s_pre=1846.3 \n",
        "Epoch 89, s_gt=565.7 s_pre=524.2 \n",
        "test_mae_sou 39.99199535942888 89\n",
        "test_mse_sou 110.36035246792723 89\n",
        "\n",
        "Epoch 90, Loss=646.5372 s_gt=35.8 s_pre=39.6, lr=0.0535\n",
        "Epoch 90, Loss=5416.6172 s_gt=285.0 s_pre=322.8, lr=0.0535\n",
        "Epoch 90, Loss=1083.6299 s_gt=113.3 s_pre=121.8, lr=0.0535\n",
        "Epoch 90, Loss=69312.6406 s_gt=57.4 s_pre=52.4, lr=0.0535\n",
        "Epoch 90, Loss=4491.6001 s_gt=195.3 s_pre=202.7, lr=0.0535\n",
        "Epoch 90, Loss=10992.9209 s_gt=15.4 s_pre=16.8, lr=0.0535\n",
        "train_mae_sou 12.014944836386304 90\n",
        "train_mse_sou 24.777539003662486 90\n",
        "testing...................\n",
        "Epoch 90, s_gt=1895.6 s_pre=1820.9 \n",
        "Epoch 90, s_gt=565.7 s_pre=509.8 \n",
        "test_mae_sou 43.206938930371905 90\n",
        "test_mse_sou 121.20153292950876 90\n",
        "Epoch 91, Loss=750.8062 s_gt=39.0 s_pre=38.7, lr=0.0535\n",
        "Epoch 91, Loss=4567.5249 s_gt=242.9 s_pre=251.1, lr=0.0535\n",
        "Epoch 91, Loss=1083.3939 s_gt=98.4 s_pre=102.7, lr=0.0535\n",
        "Epoch 91, Loss=53011.6680 s_gt=64.0 s_pre=62.9, lr=0.0535\n",
        "Epoch 91, Loss=17944.6602 s_gt=538.2 s_pre=535.7, lr=0.0535\n",
        "Epoch 91, Loss=10476.9678 s_gt=23.0 s_pre=24.8, lr=0.0535\n",
        "train_mae_sou 12.407590258023117 91\n",
        "train_mse_sou 24.683947901944876 91\n",
        "testing...................\n",
        "Epoch 91, s_gt=1895.6 s_pre=1806.7 \n",
        "Epoch 91, s_gt=565.7 s_pre=517.1 \n",
        "test_mae_sou 48.766485980045516 91\n",
        "test_mse_sou 125.55581661519332 91"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kik8rvX4Debv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}