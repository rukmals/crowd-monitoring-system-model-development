{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine tune and Model Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQJelegk35dXA++TtIzODn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukmals/crowd-monitoring-system-model-development/blob/main/Fine_tune_and_Model_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYFCU7L0Z-Sw",
        "outputId": "5de0032d-6b9f-4282-d492-38212223ce6e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRo2kGTgaaRW"
      },
      "source": [
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.io import loadmat\n",
        "import glob\n",
        "import h5py\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from numpy.lib.stride_tricks import as_strided as ast\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSYPtMCkaw5y"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYqDnkAjasoK"
      },
      "source": [
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, \\\n",
        "                stride=1, NL='relu', same_padding=False, bn=False, dilation=1):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) // 2) if same_padding else 0\n",
        "        self.conv = []\n",
        "        if dilation==1:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=dilation, dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else nn.Identity()\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU()\n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      if self.bn is not None:\n",
        "          x = self.bn(x)\n",
        "      if self.relu is not None:\n",
        "          x = self.relu(x)   \n",
        "      return x\n",
        "  \n",
        "# the module definition for the multi-branch in the density head\n",
        "class MultiBranchModule(nn.Module):\n",
        "    def __init__(self, in_channels, sync=False):\n",
        "        super(MultiBranchModule, self).__init__()\n",
        "        self.branch_column1_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column1_2 = BasicConv2d(in_channels//2, in_channels, kernel_size=1, sync=sync)\n",
        "\n",
        "        self.branch_column2_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column2_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=(3, 3), padding=(1, 1), sync=sync)\n",
        "\n",
        "        self.branch_column3_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column3_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=5, padding=2, sync=sync)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_1 = self.branch_column1_1(x)\n",
        "        branch_1 = self.branch_column1_2(branch_1)\n",
        "\n",
        "        branch_2 = self.branch_column2_1(x)\n",
        "        branch_2 = self.branch_column2_2(branch_2)\n",
        "\n",
        "        branch_3 = self.branch_column3_1(x)\n",
        "        branch_3 = self.branch_column3_2(branch_3)\n",
        "\n",
        "        outputs = [branch_1, branch_2, branch_3, x]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "# the module definition for the basic conv module\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, sync=False, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        if sync:\n",
        "            # for sync bn\n",
        "            print('use sync inception')\n",
        "            self.bn = nn.SyncBatchNorm(out_channels, eps=0.001)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(TestNet, self).__init__()\n",
        "        \n",
        "        vgg = models.vgg16_bn(pretrained=pretrained)\n",
        "        \n",
        "        self.backend_feat  = [256,128,64]\n",
        "\n",
        "\n",
        "        # Front End Development VGG - 16 \n",
        "        features = list(vgg.features.children())\n",
        "        # get each stage of the VGG - 16\n",
        "        self.features1 = nn.Sequential(*features[0:6])\n",
        "        self.features2 = nn.Sequential(*features[6:13])\n",
        "        self.features3 = nn.Sequential(*features[13:23])\n",
        "        self.features4 = nn.Sequential(*features[23:33])\n",
        "        self.features5 = nn.Sequential(*features[33:43])\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        self.p5 = nn.Sequential(\n",
        "            Conv2d(512, 1024, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p4 = nn.Sequential(\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(512, 256, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p3 = nn.Sequential(\n",
        "            Conv2d(512 , 256, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p2 = nn.Sequential(\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p1 = nn.Sequential(\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(64, 64, 3, same_padding=True, NL='relu'),\n",
        "        ) \n",
        "\n",
        "        # Multi-Branch moules\n",
        "        self.multi_branch5 = nn.Sequential(\n",
        "            MultiBranchModule(512),\n",
        "            Conv2d(2048, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch4 = nn.Sequential(\n",
        "            MultiBranchModule(256),\n",
        "            Conv2d(1024, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch3 = nn.Sequential(\n",
        "            MultiBranchModule(128),\n",
        "            Conv2d(512, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch2 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch1 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 5,dilation = True)\n",
        "\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x1)\n",
        "        x3 = self.features3(x2)\n",
        "        x4 = self.features4(x3)\n",
        "        x5 = self.features5(x4)\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        x = self.p5(x5)\n",
        "        x5_out = x\n",
        "        x = F.upsample_bilinear(x, size=x4.size()[2:])\n",
        "\n",
        "        x = torch.cat([x4, x], 1)\n",
        "        x = self.p4(x)\n",
        "        x4_out = x\n",
        "        x = F.upsample_bilinear(x, size=x3.size()[2:])\n",
        "\n",
        "        x = torch.cat([x3, x], 1)\n",
        "        x = self.p3(x)\n",
        "        x3_out = x\n",
        "        x = F.upsample_bilinear(x, size=x2.size()[2:])\n",
        "\n",
        "        x = torch.cat([x2, x], 1)\n",
        "        x = self.p2(x)\n",
        "        x2_out = x\n",
        "        x = F.upsample_bilinear(x, size=x1.size()[2:])\n",
        "\n",
        "        x = torch.cat([x1, x], 1)\n",
        "        x = self.p1(x)\n",
        "        x1_out = x\n",
        "\n",
        "\n",
        "        # multi-branch predictions\n",
        "        x5_density = self.multi_branch5(x5_out)\n",
        "        x4_density = self.multi_branch4(x4_out)\n",
        "        x3_density = self.multi_branch3(x3_out)\n",
        "        x2_density = self.multi_branch2(x2_out)\n",
        "        x1_density = self.multi_branch1(x1_out)\n",
        "\n",
        "        # upsample the multi-branch predictions to be the same with the input size\n",
        "        x5_density = F.upsample_nearest(x5_density, size=x1.size()[2:])\n",
        "        x4_density = F.upsample_nearest(x4_density, size=x1.size()[2:])\n",
        "        x3_density = F.upsample_nearest(x3_density, size=x1.size()[2:])\n",
        "        x2_density = F.upsample_nearest(x2_density, size=x1.size()[2:])\n",
        "        x1_density = F.upsample_nearest(x1_density, size=x1.size()[2:])\n",
        "\n",
        "\n",
        "        density_map = torch.cat([x5_density, x4_density, x3_density, x2_density, x1_density], 1)\n",
        "\n",
        "\n",
        "        x_out = self.backend(density_map)\n",
        "        density_map_out = self.output_layer(x_out)\n",
        "        return density_map_out\n",
        "        #return density_map\n",
        "                \n",
        "                \n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    layers = []\n",
        "    dilation_rates = [2,3,5]\n",
        "    #for v in cfg:\n",
        "    for v in range(len(cfg)):\n",
        "        if cfg[v] == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, cfg[v], kernel_size=3, padding=dilation_rates[v],dilation = dilation_rates[v])\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(cfg[v]), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = cfg[v]\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPSi0OxmazE0"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(img_path,train = True):\n",
        "    gt_path = img_path.replace('.jpg','.h5').replace('images','ground-truth-h5')\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    gt_file = h5py.File(gt_path, 'r')\n",
        "    target = np.asarray(gt_file['density'])\n",
        "    target = target.astype(np.float32, copy=False)\n",
        "    target = Image.fromarray(target)\n",
        "    return img,target\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, main_transform = None , img_transform=None, gt_transform = None, train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.main_transform = main_transform\n",
        "        self.img_transform = img_transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "\n",
        "        if self.main_transform is not None:\n",
        "            img, target = self.main_transform(img, target)\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.gt_transform is not None:\n",
        "            target = self.gt_transform(target)   \n",
        "        return img,target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34XSUsRVa3VK"
      },
      "source": [
        "import numbers\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import torch\n",
        "\n",
        "class LabelNormalize(object):\n",
        "    def __init__(self, para):\n",
        "        self.para = para\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # tensor = 1./(tensor+self.para).log()\n",
        "        tensor = torch.from_numpy(np.array(tensor))\n",
        "        tensor = tensor*self.para\n",
        "        return tensor\n",
        "\n",
        "# ===============================img tranforms============================\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if bbx is None:\n",
        "            for t in self.transforms:\n",
        "                img, mask = t(img, mask)\n",
        "            return img, mask\n",
        "        for t in self.transforms:\n",
        "            img, mask, bbx = t(img, mask, bbx)\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomHorizontallyFlip(object):\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if random.random() < 0.5:# 随机生成0-1之间的浮点数 ，每次执行生成的不一样\n",
        "            if bbx is None:\n",
        "                return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            w, h = img.size\n",
        "            xmin = w - bbx[:,3]\n",
        "            xmax = w - bbx[:,1]\n",
        "            bbx[:,1] = xmin\n",
        "            bbx[:,3] = xmax\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), bbx\n",
        "        if bbx is None:\n",
        "            return img, mask\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size, padding=0):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "        self.padding = padding\n",
        "\n",
        "    def __call__(self, img, mask):\n",
        "        # if self.padding > 0:\n",
        "        #     img = ImageOps.expand(img, border=self.padding, fill=0)\n",
        "        #     mask = ImageOps.expand(mask, border=self.padding, fill=0)\n",
        "        #\n",
        "        # assert img.size == mask.size\n",
        "        w, h = img.size\n",
        "        th, tw  = self.size\n",
        "        if w == tw and h == th:\n",
        "            return img, mask\n",
        "        if w < tw or h < th:\n",
        "            return img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST)\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DL107NNbBPz"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9dib4PxrqMy"
      },
      "source": [
        "### SH_A and SH_B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfdyBbka6cO"
      },
      "source": [
        "def load_SH_trainData(part):\n",
        "  img_train_list = os.listdir(\"/content/drive/MyDrive/Model_Test_Data/\"+part+\"/train_data/images\") \n",
        "  img_list = []\n",
        "  for img in img_train_list:\n",
        "    if '.jpg' in img:\n",
        "      img_list.append(img)\n",
        "\n",
        "  sh_train_list_A = []\n",
        "  for img_ in img_list:\n",
        "    img_ = \"/content/drive/MyDrive/Model_Test_Data/\"+part+\"/train_data/images/\"+img_\n",
        "    sh_train_list_A.append(img_)\n",
        "  return sh_train_list_A\n",
        "\n",
        "def load_SH_testData(part):\n",
        "  img_test_list = os.listdir(\"/content/drive/MyDrive/Model_Test_Data/\"+part+\"/test_data/images\")\n",
        "  img_list = []\n",
        "  for img in img_test_list:\n",
        "    if '.jpg' in img:\n",
        "      img_list.append(img)\n",
        "  if part == \"PartB\":\n",
        "    img_list.remove(\"IMG_239 (1).jpg\")\n",
        "  sh_test_list = []\n",
        "  for img_ in img_list:\n",
        "    img_ = \"/content/drive/MyDrive/Model_Test_Data/\"+part+\"/test_data/images/\"+img_\n",
        "    sh_test_list.append(img_)\n",
        "  return sh_test_list"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3I6SEsVrvbo"
      },
      "source": [
        "#### UCF_CC_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYiVFQgqbeu6"
      },
      "source": [
        "def load_ucf_cc_50():\n",
        "  path = img_test_list = os.listdir(\"/content/drive/MyDrive/Model_Test_Data/UCF_CC_50\")\n",
        "  img_list = []\n",
        "  for img in path:\n",
        "    if '.jpg' in img:\n",
        "      img_list.append(img)\n",
        "  ucf_cc_list = []\n",
        "  for img_ in img_list:\n",
        "    img_ = \"/content/drive/MyDrive/Model_Test_Data/UCF_CC_50\"+\"/\"+img_\n",
        "    ucf_cc_list.append(img_)\n",
        "  return ucf_cc_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GEp4Jbr1URM"
      },
      "source": [
        "#### UCF_QNRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WC2gYB7bkVg"
      },
      "source": [
        "def load_data_ucf_qnrf(img_path,train = True):\n",
        "    gt_path = img_path.replace('.jpg','.h5').replace('Test/','ground-truth-h5-test/')\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    gt_file = h5py.File(gt_path, 'r')\n",
        "    target = np.asarray(gt_file['density'])\n",
        "    target = target.astype(np.float32, copy=False)\n",
        "    target = Image.fromarray(target)\n",
        "    return img,target\n",
        "\n",
        "class ListDataset_QNRF(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, main_transform = None , img_transform=None, gt_transform = None, train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.main_transform = main_transform\n",
        "        self.img_transform = img_transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data_ucf_qnrf(img_path,self.train)\n",
        "\n",
        "        if self.main_transform is not None:\n",
        "            img, target = self.main_transform(img, target)\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.gt_transform is not None:\n",
        "            target = self.gt_transform(target)   \n",
        "        return img,target\n",
        "\n",
        "\n",
        "def get_tar_shot_loader_ucf_qnrf(train_part , batch_size = 1):\n",
        "  tar_main_transform = Compose([\n",
        "        RandomCrop(((576,768))),\n",
        "        RandomHorizontallyFlip(),\n",
        "        # Rand_Augment()\n",
        "    ])\n",
        "\n",
        "  tar_shot_loader = torch.utils.data.DataLoader(ListDataset_QNRF(train_part,shuffle=True,\n",
        "                                                                main_transform = tar_main_transform,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                num_workers=2),batch_size=batch_size)  \n",
        "  \n",
        "  return tar_shot_loader\n",
        "\n",
        "\n",
        "def get_tar_test_loader_ucf_qnrf(test_part , batch_size = 1):\n",
        "  test_loader = torch.utils.data.DataLoader(ListDataset_QNRF(test_part,shuffle=False,\n",
        "                                                                main_transform = None,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Resize(480),\n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                num_workers=2),batch_size=batch_size) \n",
        "  return test_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_ucf_qnrf_test_data():\n",
        "  img_path_list = os.listdir(\"/content/drive/MyDrive/Model_Test_Data/UCF-QNRF/UCF-QNRF_ECCV18/Test/\")\n",
        "  imglist =[]\n",
        "  for img in img_path_list:\n",
        "    if '.jpg' in img:\n",
        "      #imglist.append(img)\n",
        "      img_path = \"/content/drive/MyDrive/Model_Test_Data/UCF-QNRF/UCF-QNRF_ECCV18/Test/\"+ img\n",
        "      imglist.append(img_path)\n",
        "\n",
        "  return imglist"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrrrgQoz4gwx"
      },
      "source": [
        "#### SH_A and B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqxoXi2Wb7wV"
      },
      "source": [
        "def get_tar_shot_loader(train_part , batch_size = 1):\n",
        "  tar_main_transform = Compose([\n",
        "        RandomCrop(((576,768))),\n",
        "        RandomHorizontallyFlip(),\n",
        "        # Rand_Augment()\n",
        "    ])\n",
        "\n",
        "  tar_shot_loader = torch.utils.data.DataLoader(ListDataset(train_part,shuffle=True,\n",
        "                                                                main_transform = tar_main_transform,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                num_workers=2),batch_size=batch_size)  \n",
        "  \n",
        "  return tar_shot_loader\n",
        "\n",
        "\n",
        "def get_tar_test_loader(test_part , batch_size = 1):\n",
        "  test_loader = torch.utils.data.DataLoader(ListDataset(test_part,shuffle=False,\n",
        "                                                                main_transform = None,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                num_workers=2),batch_size=batch_size) \n",
        "  return test_loader"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQRonatJb9zN"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrXaT6rkeVUd",
        "outputId": "c1f94a56-bc76-45fd-fa8e-d112da2f2162"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withbackend_3.pth'\n",
        "\n",
        "tar_model = TestNet().cuda()\n",
        "# load the trained model\n",
        "tar_model.load_state_dict(torch.load(model_path))\n",
        "print('successfully load model from', model_path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully load model from /content/drive/MyDrive/GCC_CSV_DataSet/model/TestNetGCC_whole_data_withbackend_3.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2xC0UcShFBG"
      },
      "source": [
        "lr = 1e-5\n",
        "tar_optimizer =  torch.optim.Adam(tar_model.parameters(), lr = lr, weight_decay=1e-4)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4XjEqpn86QS"
      },
      "source": [
        "def block_view(A, block=(3, 3)):\n",
        "    \"\"\"Provide a 2D block view to 2D array. No error checking made.\n",
        "    Therefore meaningful (as implemented) only for blocks strictly\n",
        "    compatible with the shape of A.\"\"\"\n",
        "    # simple shape and strides computations may seem at first strange\n",
        "    # unless one is able to recognize the 'tuple additions' involved ;-)\n",
        "    shape = (int(A.shape[0]/ block[0]), int(A.shape[1]/ block[1]))+ block\n",
        "    strides = (block[0]* A.strides[0], block[1]* A.strides[1])+ A.strides\n",
        "    return ast(A, shape= shape, strides= strides)\n",
        "\n",
        "def get_ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    bimg1 = block_view(img1, (11,11))\n",
        "    bimg2 = block_view(img2, (11,11))\n",
        "    s1  = numpy.sum(bimg1, (-1, -2))\n",
        "    s2  = numpy.sum(bimg2, (-1, -2))\n",
        "    ss  = numpy.sum(bimg1*bimg1, (-1, -2)) + numpy.sum(bimg2*bimg2, (-1, -2))\n",
        "    s12 = numpy.sum(bimg1*bimg2, (-1, -2))\n",
        "\n",
        "    vari = ss - s1*s1 - s2*s2\n",
        "    covar = s12 - s1*s2\n",
        "\n",
        "    ssim_map =  (2*s1*s2 + C1) * (2*covar + C2) / ((s1*s1 + s2*s2 + C1) * (vari + C2))\n",
        "\n",
        "    return numpy.mean(ssim_map)\n",
        "\n",
        "def get_psnr(im_true, im_test):\n",
        "    pixel_max = np.max(im_true)\n",
        "    if pixel_max != 0:\n",
        "        im_true = im_true/pixel_max*255\n",
        "    pixel_max = np.max(im_test)\n",
        "    if pixel_max != 0:\n",
        "        im_test = im_test/pixel_max*255\n",
        "\n",
        "    return compare_psnr(im_true,im_test,data_range=255)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtdpkJHfhOOx"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, cur_val):\n",
        "        self.cur_val = cur_val\n",
        "        self.sum += cur_val\n",
        "        self.count += 1\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def mae_mse_update(pred,label,maes,mses=None,ssims=None,psnrs=None,losses=None,cls_id=None):\n",
        "        for num in range(pred.size()[0]):\n",
        "            sub_pred = pred[num].data.cpu().squeeze().numpy()/ 100\n",
        "            sub_label = label[num].data.cpu().squeeze().numpy() / 100\n",
        "            pred_cnt = np.sum(sub_pred)\n",
        "            gt_cnt =   np.sum(sub_label)\n",
        "            mae = abs(pred_cnt - gt_cnt)\n",
        "            mse = (pred_cnt - gt_cnt)*(pred_cnt - gt_cnt)\n",
        "\n",
        "            if ssims and psnrs is not None:\n",
        "                ssims.update(get_ssim(sub_label,sub_pred))\n",
        "                psnrs.update(get_psnr(sub_label,sub_pred))\n",
        "\n",
        "            if cls_id is not None:\n",
        "                maes.update(mae,cls_id)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item(),cls_id)\n",
        "                if mses is not None:\n",
        "                    mses.update(mse,cls_id)\n",
        "            else:\n",
        "                maes.update(mae)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item())\n",
        "                if mses is not None:\n",
        "                    mses.update(mse)\n",
        "\n",
        "        return pred_cnt,gt_cnt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFvueTBUhXXZ",
        "outputId": "7a36052d-0604-4e0f-c433-1b7394ecf371"
      },
      "source": [
        "sh_train_list_partA = load_SH_trainData(\"PartA\")\n",
        "sh_train_list_partB = load_SH_trainData(\"PartB\")\n",
        "print(len(sh_train_list_partA))\n",
        "print(len(sh_train_list_partB))\n",
        "\n",
        "\n",
        "sh_test_list_partA = load_SH_testData(\"PartA\")\n",
        "sh_test_list_partB = load_SH_testData(\"PartB\")\n",
        "print(len(sh_test_list_partA))\n",
        "print(len(sh_test_list_partB))\n",
        "\n",
        "tar_shot_loader = get_tar_shot_loader(sh_train_list_partB)\n",
        "test_loader = get_tar_test_loader(sh_test_list_partB)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "400\n",
            "182\n",
            "316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx6b3bRTtQuM"
      },
      "source": [
        "test_ucf_cc_50 = (load_ucf_cc_50())\n",
        "test_loader_ucf = get_tar_test_loader(test_ucf_cc_50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyYkEp2Q4oDM"
      },
      "source": [
        "#tar_shot_loader = \n",
        "test_loader_ucf_qnrf = get_tar_test_loader_ucf_qnrf(load_ucf_qnrf_test_data())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZKltR94ihLV"
      },
      "source": [
        "## check no adapt result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va31PzA_4iWO"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from skimage.measure import compare_psnr, compare_ssim"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "OXqCrok0ieKg",
        "outputId": "223302f9-4f41-48b1-cbb1-4a31a2d5333c"
      },
      "source": [
        "  with torch.no_grad():\n",
        "    tar_model.eval()\n",
        "    test_mae = AverageMeter()\n",
        "    test_mse = AverageMeter()\n",
        "    ssims = AverageMeter()\n",
        "    psnrs = AverageMeter()\n",
        "    for j, (img_test, target_test) in enumerate(test_loader_ucf_qnrf):\n",
        "        img_test = img_test.cuda()\n",
        "        img_test = Variable(img_test)   \n",
        "        output_test = tar_model(img_test)\n",
        "        \n",
        "        sou_pred_cnt_test, sou_label_cnt_test = mae_mse_update(output_test, target_test, test_mae, test_mse)#,ssims , psnrs)\n",
        "        if j % 40== 0:\n",
        "          print('s_gt={:.1f} s_pre={:.1f} '.format(sou_label_cnt_test,sou_pred_cnt_test))\n",
        "  print('test_mae_tar', float(test_mae.avg))\n",
        "  print('test_mse_tar', float(np.sqrt(test_mse.avg)))\n",
        "  #print('test_ssims_tar', float(ssims.avg))\n",
        "  #print('test_psnrs_tar', float(psnrs.avg))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4734d1f20d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mimg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mimg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0moutput_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0msou_pred_cnt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msou_label_cnt_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_mse_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,ssims , psnrs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-3ada0d9f5393>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mx2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 14.76 GiB total capacity; 13.34 GiB already allocated; 65.75 MiB free; 13.43 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvGJ7uSMik4I"
      },
      "source": [
        "# fine tune and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_-BgaPYfoWU",
        "outputId": "eb0e4099-83c3-41e5-93db-939febf683b8"
      },
      "source": [
        "def get_pr_value(value):\n",
        "  pr_list = []\n",
        "  for i in range(1 , 10):\n",
        "    pr_val = value*(i*10)//100\n",
        "    pr_list.append(pr_val)\n",
        "  return pr_list\n",
        "\n",
        "persntage_list = get_pr_value(len(sh_train_list_partB))\n",
        "persntage_list"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 80, 120, 160, 200, 240, 280, 320, 360]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnLcUUl4j-qZ"
      },
      "source": [
        "mae_list =[]\n",
        "mse_list = []"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzFcf2GU6kS-"
      },
      "source": [
        "test_mae_ = AverageMeter()\n",
        "test_mse_ = AverageMeter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBNzIe47hrRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4e92c7-e7f3-45cb-8858-1145994b1158"
      },
      "source": [
        "for pr_val in persntage_list[:1]:\n",
        "  test_best_mae = 18.28\n",
        "  test_best_mse = 25.87\n",
        "  for epoch in range(1,101):\n",
        "    train_mae = AverageMeter()\n",
        "    train_mse = AverageMeter()\n",
        "    for i, (shot_img, shot_label) in enumerate(tar_shot_loader, 1):\n",
        "      if i <= pr_val:\n",
        "        shot_img = shot_img.cuda()\n",
        "        shot_label = shot_label.cuda()\n",
        "        shot_pred = tar_model(shot_img)\n",
        "\n",
        "        loss = F.mse_loss(shot_pred.squeeze(), shot_label.squeeze())\n",
        "        tar_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        tar_optimizer.step()\n",
        "\n",
        "        pred_cnt, label_cnt = mae_mse_update(shot_pred, shot_label , train_mae , train_mse)\n",
        "      else:\n",
        "        break\n",
        "    print('train_mae_tar', float(train_mae.avg), epoch)\n",
        "    print('train_mse_tar', float(np.sqrt(train_mse.avg)), epoch)\n",
        "    print(\"testing...................\")  \n",
        "    with torch.no_grad():\n",
        "      tar_model.eval()\n",
        "      test_mae_ = AverageMeter()\n",
        "      test_mse_ = AverageMeter()\n",
        "      for j, (img_test, target_test) in enumerate(test_loader):\n",
        "          img_test = img_test.cuda()\n",
        "          img_test = Variable(img_test)   \n",
        "          output_test = tar_model(img_test)\n",
        "\n",
        "          sou_pred_cnt_test, sou_label_cnt_test = mae_mse_update(output_test, target_test, test_mae_, test_mse_)\n",
        "          #if j % 100== 0:\n",
        "            #print('Epoch {}, s_gt={:.1f} s_pre={:.1f} '.format(epoch, sou_label_cnt_test,sou_pred_cnt_test))\n",
        "    print('test_mae_tar', float(test_mae_.avg), epoch)\n",
        "    print('test_mse_tar', float(np.sqrt(test_mse_.avg)), epoch)\n",
        "    if test_mae_.avg<test_best_mae:\n",
        "      test_best_mae = test_mae_.avg\n",
        "      print(\"Best test MAE\", test_best_mae)\n",
        "      MODEL_SAVE_PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/currently_best_TestNetGCC_whole_data_withbackend_finetuned_SH_B_best_3.pth'\n",
        "      torch.save(tar_model.state_dict(), MODEL_SAVE_PATH)\n",
        "    if np.sqrt(test_mse_.avg)<test_best_mse:\n",
        "      test_best_mse = np.sqrt(test_mse_.avg)\n",
        "      print(\"Best test MSE\", test_best_mse)\n",
        "  mae_list.append(test_best_mae)\n",
        "  mse_list.append(test_best_mse)\n",
        "  print(\"one persantage finished!!\")\n",
        "  print(mae_list)\n",
        "  print(mse_list)\n",
        "    #MODEL_SAVE_PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/currently_best_TestNetGCC_whole_data_withbackend_finetuned_SH_A_best_2.pth'\n",
        "    #torch.save(tar_model.state_dict(), MODEL_SAVE_PATH)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3770: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_mae_tar 12.965321004390717 1\n",
            "train_mse_tar 23.060750059049255 1\n",
            "testing...................\n",
            "test_mae_tar 17.19376222091385 1\n",
            "test_mse_tar 25.03622656003853 1\n",
            "Best test MAE 17.19376222091385\n",
            "Best test MSE 25.03622656003853\n",
            "train_mae_tar 13.16493468284607 2\n",
            "train_mse_tar 26.5942833123215 2\n",
            "testing...................\n",
            "test_mae_tar 16.51508990420571 2\n",
            "test_mse_tar 26.025413326921704 2\n",
            "Best test MAE 16.51508990420571\n",
            "train_mae_tar 13.155160355567933 3\n",
            "train_mse_tar 22.402340270676547 3\n",
            "testing...................\n",
            "test_mae_tar 15.856724570069131 3\n",
            "test_mse_tar 25.233501221574826 3\n",
            "Best test MAE 15.856724570069131\n",
            "train_mae_tar 14.670112991333008 4\n",
            "train_mse_tar 24.851522695187178 4\n",
            "testing...................\n",
            "test_mae_tar 14.132322054875049 4\n",
            "test_mse_tar 22.239505304550008 4\n",
            "Best test MAE 14.132322054875049\n",
            "Best test MSE 22.239505304550008\n",
            "train_mae_tar 9.87901508808136 5\n",
            "train_mse_tar 17.863069730478596 5\n",
            "testing...................\n",
            "test_mae_tar 16.245050822632223 5\n",
            "test_mse_tar 25.411249217571736 5\n",
            "train_mae_tar 11.439132344722747 6\n",
            "train_mse_tar 23.37067415646238 6\n",
            "testing...................\n",
            "test_mae_tar 15.63818437841874 6\n",
            "test_mse_tar 22.037771770642173 6\n",
            "Best test MSE 22.037771770642173\n",
            "train_mae_tar 11.81668142080307 7\n",
            "train_mse_tar 21.886914258463598 7\n",
            "testing...................\n",
            "test_mae_tar 14.507042088086092 7\n",
            "test_mse_tar 21.820326922994052 7\n",
            "Best test MSE 21.820326922994052\n",
            "train_mae_tar 10.25242372751236 8\n",
            "train_mse_tar 17.477747290784492 8\n",
            "testing...................\n",
            "test_mae_tar 13.902075692068172 8\n",
            "test_mse_tar 20.974103282853054 8\n",
            "Best test MAE 13.902075692068172\n",
            "Best test MSE 20.974103282853054\n",
            "train_mae_tar 9.101525068283081 9\n",
            "train_mse_tar 16.15491253089355 9\n",
            "testing...................\n",
            "test_mae_tar 15.94498966917207 9\n",
            "test_mse_tar 23.28075403683895 9\n",
            "train_mae_tar 9.512718069553376 10\n",
            "train_mse_tar 18.46817953208044 10\n",
            "testing...................\n",
            "test_mae_tar 15.341752903370917 10\n",
            "test_mse_tar 22.54846195771039 10\n",
            "train_mae_tar 10.798495364189147 11\n",
            "train_mse_tar 18.91589779391365 11\n",
            "testing...................\n",
            "test_mae_tar 18.737578322615803 11\n",
            "test_mse_tar 24.010709202380255 11\n",
            "train_mae_tar 12.019042086601257 12\n",
            "train_mse_tar 23.59630471541684 12\n",
            "testing...................\n",
            "test_mae_tar 19.214384178572065 12\n",
            "test_mse_tar 24.385710944344993 12\n",
            "train_mae_tar 12.588876581192016 13\n",
            "train_mse_tar 18.331091542766025 13\n",
            "testing...................\n",
            "test_mae_tar 20.05833855459962 13\n",
            "test_mse_tar 25.31213343817002 13\n",
            "train_mae_tar 14.049526715278626 14\n",
            "train_mse_tar 25.405924535909516 14\n",
            "testing...................\n",
            "test_mae_tar 27.134981777094588 14\n",
            "test_mse_tar 32.407345250867046 14\n",
            "train_mae_tar 14.720183956623078 15\n",
            "train_mse_tar 21.857618113330425 15\n",
            "testing...................\n",
            "test_mae_tar 14.382930067521107 15\n",
            "test_mse_tar 19.548513085324004 15\n",
            "Best test MSE 19.548513085324004\n",
            "train_mae_tar 9.994917631149292 16\n",
            "train_mse_tar 16.454744640876346 16\n",
            "testing...................\n",
            "test_mae_tar 16.798290255703503 16\n",
            "test_mse_tar 21.871919899400602 16\n",
            "train_mae_tar 11.8549780189991 17\n",
            "train_mse_tar 20.992925325633188 17\n",
            "testing...................\n",
            "test_mae_tar 27.384300147430807 17\n",
            "test_mse_tar 31.936777874301082 17\n",
            "train_mae_tar 16.335612016916276 18\n",
            "train_mse_tar 24.412202390747954 18\n",
            "testing...................\n",
            "test_mae_tar 27.89925479888916 18\n",
            "test_mse_tar 32.5994628500392 18\n",
            "train_mae_tar 15.956059670448303 19\n",
            "train_mse_tar 21.83848226996365 19\n",
            "testing...................\n",
            "test_mae_tar 27.527995375138296 19\n",
            "test_mse_tar 32.22666045111834 19\n",
            "train_mae_tar 14.307039350271225 20\n",
            "train_mse_tar 18.842118901343696 20\n",
            "testing...................\n",
            "test_mae_tar 28.09255888492246 20\n",
            "test_mse_tar 33.01671299825617 20\n",
            "train_mae_tar 9.673889350891113 21\n",
            "train_mse_tar 14.861396205487091 21\n",
            "testing...................\n",
            "test_mae_tar 23.444101049930236 21\n",
            "test_mse_tar 28.540590270489307 21\n",
            "train_mae_tar 13.454270219802856 22\n",
            "train_mse_tar 16.304164624003963 22\n",
            "testing...................\n",
            "test_mae_tar 40.37477458277835 22\n",
            "test_mse_tar 45.39240167507189 22\n",
            "train_mae_tar 7.88637683391571 23\n",
            "train_mse_tar 11.402579886720847 23\n",
            "testing...................\n",
            "test_mae_tar 20.43648280071307 23\n",
            "test_mse_tar 26.12539304990771 23\n",
            "train_mae_tar 10.347709429264068 24\n",
            "train_mse_tar 15.212954584214126 24\n",
            "testing...................\n",
            "test_mae_tar 31.190671631052524 24\n",
            "test_mse_tar 35.15494703112058 24\n",
            "train_mae_tar 10.470821380615234 25\n",
            "train_mse_tar 13.329820282618721 25\n",
            "testing...................\n",
            "test_mae_tar 14.975845964649055 25\n",
            "test_mse_tar 19.980682051612273 25\n",
            "train_mae_tar 9.753505271673202 26\n",
            "train_mse_tar 11.770106591055209 26\n",
            "testing...................\n",
            "test_mae_tar 17.088779530947722 26\n",
            "test_mse_tar 21.890430899759526 26\n",
            "train_mae_tar 7.919891607761383 27\n",
            "train_mse_tar 10.017995111754958 27\n",
            "testing...................\n",
            "test_mae_tar 13.88344080840485 27\n",
            "test_mse_tar 19.654535010925404 27\n",
            "Best test MAE 13.88344080840485\n",
            "train_mae_tar 6.270753133296966 28\n",
            "train_mse_tar 8.169919524319576 28\n",
            "testing...................\n",
            "test_mae_tar 16.071719054934345 28\n",
            "test_mse_tar 22.968440526338433 28\n",
            "train_mae_tar 7.368092858791352 29\n",
            "train_mse_tar 11.080575658301806 29\n",
            "testing...................\n",
            "test_mae_tar 28.775879751277877 29\n",
            "test_mse_tar 35.031715096545256 29\n",
            "train_mae_tar 9.196393656730653 30\n",
            "train_mse_tar 12.427596385608798 30\n",
            "testing...................\n",
            "test_mae_tar 13.650742986534215 30\n",
            "test_mse_tar 18.876973219577785 30\n",
            "Best test MAE 13.650742986534215\n",
            "Best test MSE 18.876973219577785\n",
            "train_mae_tar 7.688683861494065 31\n",
            "train_mse_tar 12.371131052935725 31\n",
            "testing...................\n",
            "test_mae_tar 41.8687219619751 31\n",
            "test_mse_tar 48.489887031247626 31\n",
            "train_mae_tar 9.798133528232574 32\n",
            "train_mse_tar 14.159049215061126 32\n",
            "testing...................\n",
            "test_mae_tar 16.130389439908765 32\n",
            "test_mse_tar 21.670185736370474 32\n",
            "train_mae_tar 9.243365442752838 33\n",
            "train_mse_tar 14.113768634406792 33\n",
            "testing...................\n",
            "test_mae_tar 19.424211456805846 33\n",
            "test_mse_tar 26.402430276370904 33\n",
            "train_mae_tar 9.741945505142212 34\n",
            "train_mse_tar 15.166709325477639 34\n",
            "testing...................\n",
            "test_mae_tar 22.443032364302045 34\n",
            "test_mse_tar 27.642807490264218 34\n",
            "train_mae_tar 15.365710878372193 35\n",
            "train_mse_tar 19.3213637141978 35\n",
            "testing...................\n",
            "test_mae_tar 39.74557525900346 35\n",
            "test_mse_tar 43.316541700711866 35\n",
            "train_mae_tar 12.830086350440979 36\n",
            "train_mse_tar 17.152366242835374 36\n",
            "testing...................\n",
            "test_mae_tar 24.374506624439096 36\n",
            "test_mse_tar 31.358175038145905 36\n",
            "train_mae_tar 11.131916451454163 37\n",
            "train_mse_tar 17.185639199790245 37\n",
            "testing...................\n",
            "test_mae_tar 19.198415391052826 37\n",
            "test_mse_tar 23.848717266977847 37\n",
            "train_mae_tar 11.018541872501373 38\n",
            "train_mse_tar 12.88879872002567 38\n",
            "testing...................\n",
            "test_mae_tar 15.88418691973143 38\n",
            "test_mse_tar 20.638780837857283 38\n",
            "train_mae_tar 11.094051158428192 39\n",
            "train_mse_tar 13.53855892134718 39\n",
            "testing...................\n",
            "test_mae_tar 23.499749231942094 39\n",
            "test_mse_tar 30.595934486303033 39\n",
            "train_mae_tar 10.791799688339234 40\n",
            "train_mse_tar 14.576812242541225 40\n",
            "testing...................\n",
            "test_mae_tar 17.493282900580876 40\n",
            "test_mse_tar 23.108057091044248 40\n",
            "train_mae_tar 8.08291831612587 41\n",
            "train_mse_tar 9.748197170792658 41\n",
            "testing...................\n",
            "test_mae_tar 17.101906402201593 41\n",
            "test_mse_tar 23.62424072771628 41\n",
            "train_mae_tar 7.6932124376296995 42\n",
            "train_mse_tar 10.53822031491843 42\n",
            "testing...................\n",
            "test_mae_tar 17.040542967711822 42\n",
            "test_mse_tar 21.79380098439491 42\n",
            "train_mae_tar 11.47305487394333 43\n",
            "train_mse_tar 15.277510242827804 43\n",
            "testing...................\n",
            "test_mae_tar 15.481812377519246 43\n",
            "test_mse_tar 22.383403849654453 43\n",
            "train_mae_tar 6.902892541885376 44\n",
            "train_mse_tar 12.999765981425634 44\n",
            "testing...................\n",
            "test_mae_tar 24.500374999227404 44\n",
            "test_mse_tar 28.340698497543343 44\n",
            "train_mae_tar 16.051323962211608 45\n",
            "train_mse_tar 19.704296766516073 45\n",
            "testing...................\n",
            "test_mae_tar 14.208214965047716 45\n",
            "test_mse_tar 19.578736187752856 45\n",
            "train_mae_tar 8.575122499465943 46\n",
            "train_mse_tar 11.684963580494406 46\n",
            "testing...................\n",
            "test_mae_tar 13.634341327449944 46\n",
            "test_mse_tar 19.300767168897416 46\n",
            "Best test MAE 13.634341327449944\n",
            "train_mae_tar 10.87095457315445 47\n",
            "train_mse_tar 17.798499596728778 47\n",
            "testing...................\n",
            "test_mae_tar 13.665006800542903 47\n",
            "test_mse_tar 19.682179510775008 47\n",
            "train_mae_tar 5.613855016231537 48\n",
            "train_mse_tar 7.052148745441546 48\n",
            "testing...................\n",
            "test_mae_tar 16.133433127705054 48\n",
            "test_mse_tar 22.29213846758029 48\n",
            "train_mae_tar 8.708337247371674 49\n",
            "train_mse_tar 13.527135664209386 49\n",
            "testing...................\n",
            "test_mae_tar 18.595826791811593 49\n",
            "test_mse_tar 23.351614645355838 49\n",
            "train_mae_tar 12.720307016372681 50\n",
            "train_mse_tar 18.276943183085734 50\n",
            "testing...................\n",
            "test_mae_tar 29.556653822524638 50\n",
            "test_mse_tar 36.96462651233088 50\n",
            "train_mae_tar 10.958834028244018 51\n",
            "train_mse_tar 18.36634219673039 51\n",
            "testing...................\n",
            "test_mae_tar 14.205548500712913 51\n",
            "test_mse_tar 19.247217367443533 51\n",
            "train_mae_tar 9.800809210538864 52\n",
            "train_mse_tar 21.105863815975468 52\n",
            "testing...................\n",
            "test_mae_tar 34.71114031272599 52\n",
            "test_mse_tar 38.59043104785412 52\n",
            "train_mae_tar 15.322336840629578 53\n",
            "train_mse_tar 18.51722577548117 53\n",
            "testing...................\n",
            "test_mae_tar 26.219192468667334 53\n",
            "test_mse_tar 30.009486623285884 53\n",
            "train_mae_tar 7.866884231567383 54\n",
            "train_mse_tar 10.209391578322458 54\n",
            "testing...................\n",
            "test_mae_tar 14.792751417884343 54\n",
            "test_mse_tar 21.907387565496638 54\n",
            "train_mae_tar 6.140461909770965 55\n",
            "train_mse_tar 8.323011819547723 55\n",
            "testing...................\n",
            "test_mae_tar 18.11151496669914 55\n",
            "test_mse_tar 22.744160253064155 55\n",
            "train_mae_tar 6.765689107775688 56\n",
            "train_mse_tar 8.63098506572678 56\n",
            "testing...................\n",
            "test_mae_tar 19.897018052354642 56\n",
            "test_mse_tar 28.617121784143734 56\n",
            "train_mae_tar 11.001708483695984 57\n",
            "train_mse_tar 13.520459508454845 57\n",
            "testing...................\n",
            "test_mae_tar 28.771111590952813 57\n",
            "test_mse_tar 33.725829718951864 57\n",
            "train_mae_tar 7.848545932769776 58\n",
            "train_mse_tar 10.271746054100444 58\n",
            "testing...................\n",
            "test_mae_tar 18.6328309759309 58\n",
            "test_mse_tar 25.067603342797447 58\n",
            "train_mae_tar 9.94471150636673 59\n",
            "train_mse_tar 19.51186598871139 59\n",
            "testing...................\n",
            "test_mae_tar 38.13432050053078 59\n",
            "test_mse_tar 42.18585884617643 59\n",
            "train_mae_tar 13.244224178791047 60\n",
            "train_mse_tar 16.613120170784875 60\n",
            "testing...................\n",
            "test_mae_tar 14.491961714587633 60\n",
            "test_mse_tar 19.119628248772035 60\n",
            "train_mae_tar 8.986758279800416 61\n",
            "train_mse_tar 11.169165274520862 61\n",
            "testing...................\n",
            "test_mae_tar 12.309837944899932 61\n",
            "test_mse_tar 17.71691326442646 61\n",
            "Best test MAE 12.309837944899932\n",
            "Best test MSE 17.71691326442646\n",
            "train_mae_tar 6.948446351289749 62\n",
            "train_mse_tar 8.728834033462649 62\n",
            "testing...................\n",
            "test_mae_tar 19.205592765083797 62\n",
            "test_mse_tar 24.938048478256245 62\n",
            "train_mae_tar 7.257499718666077 63\n",
            "train_mse_tar 9.52563213927445 63\n",
            "testing...................\n",
            "test_mae_tar 13.324242459067815 63\n",
            "test_mse_tar 18.818185750309766 63\n",
            "train_mae_tar 16.232634049654006 64\n",
            "train_mse_tar 21.419294714546467 64\n",
            "testing...................\n",
            "test_mae_tar 68.2556447499915 64\n",
            "test_mse_tar 72.00971669461381 64\n",
            "train_mae_tar 15.11207709312439 65\n",
            "train_mse_tar 20.698846623986782 65\n",
            "testing...................\n",
            "test_mae_tar 14.002425818503658 65\n",
            "test_mse_tar 21.056437084222342 65\n",
            "train_mae_tar 9.008335262537003 66\n",
            "train_mse_tar 12.706731119145584 66\n",
            "testing...................\n",
            "test_mae_tar 27.210109433041342 66\n",
            "test_mse_tar 30.936111519126374 66\n",
            "train_mae_tar 19.47122034430504 67\n",
            "train_mse_tar 27.232915470219282 67\n",
            "testing...................\n",
            "test_mae_tar 17.94808175292196 67\n",
            "test_mse_tar 25.695669625614073 67\n",
            "train_mae_tar 15.88225679397583 68\n",
            "train_mse_tar 23.370293198808746 68\n",
            "testing...................\n",
            "test_mae_tar 13.50704347936413 68\n",
            "test_mse_tar 18.97640112876794 68\n",
            "train_mae_tar 9.836992549896241 69\n",
            "train_mse_tar 20.786998820496994 69\n",
            "testing...................\n",
            "test_mae_tar 36.800275199020966 69\n",
            "test_mse_tar 40.14182548405458 69\n",
            "train_mae_tar 13.347348183393478 70\n",
            "train_mse_tar 22.957156069612413 70\n",
            "testing...................\n",
            "test_mae_tar 38.979832981206194 70\n",
            "test_mse_tar 41.973607116099586 70\n",
            "train_mae_tar 14.928602468967437 71\n",
            "train_mse_tar 18.12238794790406 71\n",
            "testing...................\n",
            "test_mae_tar 30.50252912617937 71\n",
            "test_mse_tar 33.94044425936755 71\n",
            "train_mae_tar 8.655036687850952 72\n",
            "train_mse_tar 11.602731776894588 72\n",
            "testing...................\n",
            "test_mae_tar 17.547602315492266 72\n",
            "test_mse_tar 25.772434730606424 72\n",
            "train_mae_tar 7.41315655708313 73\n",
            "train_mse_tar 12.941138600320103 73\n",
            "testing...................\n",
            "test_mae_tar 19.988599517677404 73\n",
            "test_mse_tar 24.08896941660354 73\n",
            "train_mae_tar 7.784844517707825 74\n",
            "train_mse_tar 9.958131278880215 74\n",
            "testing...................\n",
            "test_mae_tar 18.853919856155976 74\n",
            "test_mse_tar 26.656422268573714 74\n",
            "train_mae_tar 8.843013286590576 75\n",
            "train_mse_tar 11.959396621548214 75\n",
            "testing...................\n",
            "test_mae_tar 27.7127334981025 75\n",
            "test_mse_tar 32.10809607791728 75\n",
            "train_mae_tar 11.395514237880707 76\n",
            "train_mse_tar 16.005367123284806 76\n",
            "testing...................\n",
            "test_mae_tar 28.98292542861987 76\n",
            "test_mse_tar 35.57839118813429 76\n",
            "train_mae_tar 15.557806921005248 77\n",
            "train_mse_tar 23.24132331199119 77\n",
            "testing...................\n",
            "test_mae_tar 52.98736248137076 77\n",
            "test_mse_tar 56.99226869691246 77\n",
            "train_mae_tar 13.53761791586876 78\n",
            "train_mse_tar 17.479449363863623 78\n",
            "testing...................\n",
            "test_mae_tar 15.300457972514478 78\n",
            "test_mse_tar 23.792815180089256 78\n",
            "train_mae_tar 9.407502460479737 79\n",
            "train_mse_tar 14.485910672528242 79\n",
            "testing...................\n",
            "test_mae_tar 47.33788936953001 79\n",
            "test_mse_tar 51.057459174480826 79\n",
            "train_mae_tar 13.070951890945434 80\n",
            "train_mse_tar 17.65654424374837 80\n",
            "testing...................\n",
            "test_mae_tar 31.13464688952965 80\n",
            "test_mse_tar 39.12945570371006 80\n",
            "train_mae_tar 13.239606702327729 81\n",
            "train_mse_tar 21.554369071600753 81\n",
            "testing...................\n",
            "test_mae_tar 26.471464446828335 81\n",
            "test_mse_tar 30.248099222178293 81\n",
            "train_mae_tar 11.393693375587464 82\n",
            "train_mse_tar 13.795324337763615 82\n",
            "testing...................\n",
            "test_mae_tar 13.813664336747761 82\n",
            "test_mse_tar 19.301311068174073 82\n",
            "train_mae_tar 5.292141830921173 83\n",
            "train_mse_tar 7.869194243664541 83\n",
            "testing...................\n",
            "test_mae_tar 13.472713497620594 83\n",
            "test_mse_tar 19.85344522823586 83\n",
            "train_mae_tar 5.223899489641189 84\n",
            "train_mse_tar 7.8220411342501555 84\n",
            "testing...................\n",
            "test_mae_tar 18.204766201067574 84\n",
            "test_mse_tar 23.470931282196858 84\n",
            "train_mae_tar 9.287930285930633 85\n",
            "train_mse_tar 11.2537806757605 85\n",
            "testing...................\n",
            "test_mae_tar 16.340480267247067 85\n",
            "test_mse_tar 24.65584485032295 85\n",
            "train_mae_tar 9.327647817134856 86\n",
            "train_mse_tar 12.945529989111703 86\n",
            "testing...................\n",
            "test_mae_tar 31.240111942532696 86\n",
            "test_mse_tar 34.835381167569984 86\n",
            "train_mae_tar 16.766567087173463 87\n",
            "train_mse_tar 23.330642639428486 87\n",
            "testing...................\n",
            "test_mae_tar 41.344531045684334 87\n",
            "test_mse_tar 48.28627578624397 87\n",
            "train_mae_tar 15.177798652648926 88\n",
            "train_mse_tar 24.406106580515566 88\n",
            "testing...................\n",
            "test_mae_tar 34.28477860704253 88\n",
            "test_mse_tar 37.220586743227706 88\n",
            "train_mae_tar 14.638239920139313 89\n",
            "train_mse_tar 17.654802100845533 89\n",
            "testing...................\n",
            "test_mae_tar 21.593812236303016 89\n",
            "test_mse_tar 27.30545826128536 89\n",
            "train_mae_tar 11.10155314207077 90\n",
            "train_mse_tar 13.551102605848332 90\n",
            "testing...................\n",
            "test_mae_tar 18.59028029140038 90\n",
            "test_mse_tar 27.458441184725455 90\n",
            "train_mae_tar 5.064689940214157 91\n",
            "train_mse_tar 7.115725674122957 91\n",
            "testing...................\n",
            "test_mae_tar 18.42511180986332 91\n",
            "test_mse_tar 28.072109853659388 91\n",
            "train_mae_tar 8.00174412727356 92\n",
            "train_mse_tar 9.480437244450167 92\n",
            "testing...................\n",
            "test_mae_tar 23.748618687255473 92\n",
            "test_mse_tar 34.4915103302234 92\n",
            "train_mae_tar 13.06212415099144 93\n",
            "train_mse_tar 15.207633873225959 93\n",
            "testing...................\n",
            "test_mae_tar 14.003313233580771 93\n",
            "test_mse_tar 20.446124114821007 93\n",
            "train_mae_tar 7.220056474208832 94\n",
            "train_mse_tar 11.122721072287025 94\n",
            "testing...................\n",
            "test_mae_tar 22.11005863962294 94\n",
            "test_mse_tar 27.775797887863693 94\n",
            "train_mae_tar 10.262290942668916 95\n",
            "train_mse_tar 14.646098140711418 95\n",
            "testing...................\n",
            "test_mae_tar 52.16131202782257 95\n",
            "test_mse_tar 58.70158372521523 95\n",
            "train_mae_tar 13.483581686019898 96\n",
            "train_mse_tar 19.774099172803172 96\n",
            "testing...................\n",
            "test_mae_tar 39.08148015903521 96\n",
            "test_mse_tar 42.89559469303529 96\n",
            "train_mae_tar 19.190758085250856 97\n",
            "train_mse_tar 28.302239407923466 97\n",
            "testing...................\n",
            "test_mae_tar 37.874355660209176 97\n",
            "test_mse_tar 43.605941894209046 97\n",
            "train_mae_tar 12.436838245391845 98\n",
            "train_mse_tar 16.32033215904376 98\n",
            "testing...................\n",
            "test_mae_tar 15.12930404385434 98\n",
            "test_mse_tar 22.95987066664107 98\n",
            "train_mae_tar 8.37404569387436 99\n",
            "train_mse_tar 11.106491429638943 99\n",
            "testing...................\n",
            "test_mae_tar 15.47061050692691 99\n",
            "test_mse_tar 20.817075629732102 99\n",
            "train_mae_tar 8.613618469238281 100\n",
            "train_mse_tar 11.165953202521031 100\n",
            "testing...................\n",
            "test_mae_tar 27.408898014056533 100\n",
            "test_mse_tar 32.85822589601212 100\n",
            "one persantage finished!!\n",
            "[12.309837944899932]\n",
            "[17.71691326442646]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPCAqP4Bh5tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8776cf58-bc15-4054-ff0a-6bf09e2a01ae"
      },
      "source": [
        "print(test_best_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "d1qJssNDn0Ra",
        "outputId": "697c5b87-e446-44aa-99b9-f166bb1f47f3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x1 = [\"10%\",\"20%\",\"30%\",\"40%\",\"50%\",\"60%\",\"70%\",\"80%\",\"90%\" ]\n",
        "y1 = [91.08, 89.55, 91.23, 89.69, 95.50, 89.59, 89.15, 88.95, 83.64]\n",
        "y2 = [151.81, 153.22, 156.87, 152.98, 166.45, 159.49, 158.73, 145.24, 136.00]\n",
        "\n",
        "plt.plot(x1, y1, marker=\"o\")\n",
        "plt.plot(x1, y2, marker=\"o\")\n",
        "plt.title(\"Fine tune MAE and MSE value changes with few shot data SHA\")\n",
        "plt.xlabel(\"Fine tune Data Persantage\")\n",
        "plt.legend([\"fine tuned MAE\", \"fine tuned MSE\"])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5425c33390>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_1MBpgbzclK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}