{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drive Mount and Model Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11xolfmExWrorL9y8pNaTRzL6YLeUHF_0",
      "authorship_tag": "ABX9TyN8JQWKmuKpAlsjOeX85h0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukmals/crowd-monitoring-system-model-development/blob/main/Drive_Mount_and_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpNYrFdXWS0w",
        "outputId": "7a156674-cc11-48ec-8031-553aea95e0f4"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/GCC/Part 0\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scene_00_0  scene_01_3\tscene_03_2  scene_05_1\tscene_07_0  scene_08_3\n",
            "scene_00_1  scene_02_0\tscene_03_3  scene_05_2\tscene_07_1  scene_09_0\n",
            "scene_00_2  scene_02_1\tscene_04_0  scene_05_3\tscene_07_2  scene_09_1\n",
            "scene_00_3  scene_02_2\tscene_04_1  scene_06_0\tscene_07_3  scene_09_2\n",
            "scene_01_0  scene_02_3\tscene_04_2  scene_06_1\tscene_08_0  scene_09_3\n",
            "scene_01_1  scene_03_0\tscene_04_3  scene_06_2\tscene_08_1\n",
            "scene_01_2  scene_03_1\tscene_05_0  scene_06_3\tscene_08_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fbf3yO6Wp_v",
        "outputId": "f419af0e-4e7b-43fa-a58b-d634b2e517ed"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpvJWKE0XAjq",
        "outputId": "403a5dd2-7b70-45ee-efb4-ada4d259d54f"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen RAM Free: 12.7 GB  | Proc size: 118.0 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7HQR0DTXEGK"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from PIL import Image,ImageFilter,ImageDraw\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import ImageStat\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "# import from library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from torchvision import models"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMHRFd07Aohn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, \\\n",
        "                stride=1, NL='relu', same_padding=False, bn=False, dilation=1):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) // 2) if same_padding else 0\n",
        "        self.conv = []\n",
        "        if dilation==1:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=dilation, dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else nn.Identity()\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU()\n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      if self.bn is not None:\n",
        "          x = self.bn(x)\n",
        "      if self.relu is not None:\n",
        "          x = self.relu(x)   \n",
        "      return x\n",
        "  \n",
        "# the module definition for the multi-branch in the density head\n",
        "class MultiBranchModule(nn.Module):\n",
        "    def __init__(self, in_channels, sync=False):\n",
        "        super(MultiBranchModule, self).__init__()\n",
        "        self.branch_column1_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column1_2 = BasicConv2d(in_channels//2, in_channels, kernel_size=1, sync=sync)\n",
        "\n",
        "        self.branch_column2_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column2_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=(3, 3), padding=(1, 1), sync=sync)\n",
        "\n",
        "        self.branch_column3_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column3_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=5, padding=2, sync=sync)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_1 = self.branch_column1_1(x)\n",
        "        branch_1 = self.branch_column1_2(branch_1)\n",
        "\n",
        "        branch_2 = self.branch_column2_1(x)\n",
        "        branch_2 = self.branch_column2_2(branch_2)\n",
        "\n",
        "        branch_3 = self.branch_column3_1(x)\n",
        "        branch_3 = self.branch_column3_2(branch_3)\n",
        "\n",
        "        outputs = [branch_1, branch_2, branch_3, x]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "# the module definition for the basic conv module\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, sync=False, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        if sync:\n",
        "            # for sync bn\n",
        "            print('use sync inception')\n",
        "            self.bn = nn.SyncBatchNorm(out_channels, eps=0.001)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpM8HpbZArjq"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(img_path,train = True):\n",
        "    gt_path = img_path.replace('.png','.h5').replace('pngs','GT')\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    gt_file = h5py.File(gt_path, 'r')\n",
        "    target = np.asarray(gt_file['density'])\n",
        "    target = cv2.resize(target,(int(target.shape[1]/2.25), int(target.shape[0]/2.25)),interpolation = cv2.INTER_CUBIC)*64\n",
        "    return img,target\n",
        "\"\"\"\n",
        "create a list of file (full directory)\n",
        "\"\"\"\n",
        "\n",
        "def create_training_image_list(data_path):\n",
        "    \"\"\"\n",
        "    create a list of absolutely path of jpg file\n",
        "    :param data_path: must contain subfolder \"images\" with *.jpg  (example ShanghaiTech/part_A/train_data/)\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    DATA_PATH = data_path\n",
        "    image_path_list = glob.glob(os.path.join(DATA_PATH, \"pngs\", \"*.png\"))\n",
        "    return image_path_list\n",
        "\n",
        "\n",
        "def get_train_val_list(data_path):\n",
        "    DATA_PATH = data_path\n",
        "    scences = ['scene_00_0','scene_00_1','scene_00_2','scene_00_1','scene_01_0','scene_01_1','scene_01_2','scene_01_3']\n",
        "    image_path_list = []\n",
        "    for scene in scences:\n",
        "      image_path_list += glob.glob(os.path.join(DATA_PATH,scene, \"pngs\", \"*.png\"))\n",
        "    train, val = train_test_split(image_path_list, test_size=0.1)\n",
        "\n",
        "    print(\"train size \", len(train))\n",
        "    print(\"val size \", len(val))\n",
        "    return train, val\n",
        "\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, transform=None,  train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "        \n",
        "        #img = 255.0 * F.to_tensor(img)\n",
        "        \n",
        "        #img[0,:,:]=img[0,:,:]-92.8207477031\n",
        "        #img[1,:,:]=img[1,:,:]-95.2757037428\n",
        "        #img[2,:,:]=img[2,:,:]-104.877445883\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img,target\n",
        "\n",
        "\n",
        "        \n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self, pretrained=False):\n",
        "        super(TestNet, self).__init__()\n",
        "        \n",
        "        vgg = models.vgg16_bn(pretrained=pretrained)\n",
        "        \n",
        "        self.backend_feat  = [256,128,64]\n",
        "\n",
        "\n",
        "        # Front End Development VGG - 16 \n",
        "        features = list(vgg.features.children())\n",
        "        # get each stage of the VGG - 16\n",
        "        self.features1 = nn.Sequential(*features[0:6])\n",
        "        self.features2 = nn.Sequential(*features[6:13])\n",
        "        self.features3 = nn.Sequential(*features[13:23])\n",
        "        self.features4 = nn.Sequential(*features[23:33])\n",
        "        self.features5 = nn.Sequential(*features[33:43])\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        self.p5 = nn.Sequential(\n",
        "            Conv2d(512, 1024, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p4 = nn.Sequential(\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(512, 256, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p3 = nn.Sequential(\n",
        "            Conv2d(512 , 256, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p2 = nn.Sequential(\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p1 = nn.Sequential(\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(64, 64, 3, same_padding=True, NL='relu'),\n",
        "        ) \n",
        "\n",
        "        # Multi-Branch moules\n",
        "        self.multi_branch5 = nn.Sequential(\n",
        "            MultiBranchModule(512),\n",
        "            Conv2d(2048, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch4 = nn.Sequential(\n",
        "            MultiBranchModule(256),\n",
        "            Conv2d(1024, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch3 = nn.Sequential(\n",
        "            MultiBranchModule(128),\n",
        "            Conv2d(512, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch2 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch1 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 5,dilation = True)\n",
        "\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x1)\n",
        "        x3 = self.features3(x2)\n",
        "        x4 = self.features4(x3)\n",
        "        x5 = self.features5(x4)\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        x = self.p5(x5)\n",
        "        x5_out = x\n",
        "        x = F.upsample_bilinear(x, size=x4.size()[2:])\n",
        "\n",
        "        x = torch.cat([x4, x], 1)\n",
        "        x = self.p4(x)\n",
        "        x4_out = x\n",
        "        x = F.upsample_bilinear(x, size=x3.size()[2:])\n",
        "\n",
        "        x = torch.cat([x3, x], 1)\n",
        "        x = self.p3(x)\n",
        "        x3_out = x\n",
        "        x = F.upsample_bilinear(x, size=x2.size()[2:])\n",
        "\n",
        "        x = torch.cat([x2, x], 1)\n",
        "        x = self.p2(x)\n",
        "        x2_out = x\n",
        "        x = F.upsample_bilinear(x, size=x1.size()[2:])\n",
        "\n",
        "        x = torch.cat([x1, x], 1)\n",
        "        x = self.p1(x)\n",
        "        x1_out = x\n",
        "\n",
        "\n",
        "        # multi-branch predictions\n",
        "        x5_density = self.multi_branch5(x5_out)\n",
        "        x4_density = self.multi_branch4(x4_out)\n",
        "        x3_density = self.multi_branch3(x3_out)\n",
        "        x2_density = self.multi_branch2(x2_out)\n",
        "        x1_density = self.multi_branch1(x1_out)\n",
        "\n",
        "        # upsample the multi-branch predictions to be the same with the input size\n",
        "        x5_density = F.upsample_nearest(x5_density, size=x1.size()[2:])\n",
        "        x4_density = F.upsample_nearest(x4_density, size=x1.size()[2:])\n",
        "        x3_density = F.upsample_nearest(x3_density, size=x1.size()[2:])\n",
        "        x2_density = F.upsample_nearest(x2_density, size=x1.size()[2:])\n",
        "        x1_density = F.upsample_nearest(x1_density, size=x1.size()[2:])\n",
        "\n",
        "\n",
        "        density_map = torch.cat([x5_density, x4_density, x3_density, x2_density, x1_density], 1)\n",
        "\n",
        "\n",
        "        x_out = self.backend(density_map)\n",
        "        density_map_out = self.output_layer(x_out)\n",
        "        return density_map_out\n",
        "        #return density_map\n",
        "                \n",
        "                \n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    if dilation:\n",
        "        d_rate = 2\n",
        "    else:\n",
        "        d_rate = 1\n",
        "    layers = []\n",
        "    dilation_rates = [2,3,5]\n",
        "    #for v in cfg:\n",
        "    for v in range(len(cfg)):\n",
        "        if cfg[v] == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, cfg[v], kernel_size=3, padding=dilation_rates[v],dilation = dilation_rates[v])\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(cfg[v]), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = cfg[v]\n",
        "    return nn.Sequential(*layers)  "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OhXbVrGAu-l"
      },
      "source": [
        "model = TestNet()\n",
        "model = model.cuda()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXfSbYXOAyD-",
        "outputId": "7a85cb3f-768b-477d-c672-4c2630791669"
      },
      "source": [
        "path_list_file = \"/content/drive/MyDrive/GCC/all_list.txt\"\n",
        "def get_image_path(file_path):\n",
        "    file_path_list = file_path.split(\" \")\n",
        "    scene = file_path_list[3][4:]\n",
        "    image_number = file_path_list[4]\n",
        "    image_path = \"/content/drive/MyDrive/GCC/\"+\"Part\"+\" \"+scene[7]+scene\n",
        "    return image_path\n",
        "\n",
        "file = open(path_list_file, 'r')\n",
        "\n",
        "file_list = file.readlines()\n",
        "\n",
        "image_path_list = []\n",
        "\n",
        "for line in file_list:\n",
        "    image_path_list.append(get_image_path(line))\n",
        "\n",
        "print(len(image_path_list))\n",
        "\n",
        "\n",
        "def get_image_pathlist(path_list, part):\n",
        "    image_path_list_part_ = []\n",
        "    for line_ in path_list:\n",
        "        if line_.find(part)!=-1:\n",
        "            image_path_list_part_.append(line_)\n",
        "    return image_path_list_part_\n",
        "part_0_list = get_image_pathlist(image_path_list, \"Part 0\")\n",
        "print(len(part_0_list))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15212\n",
            "1793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2dFTSO_A8MK",
        "outputId": "0e7a405c-1725-403e-a28e-9b434a8e51e6"
      },
      "source": [
        "train_list, val_list = get_train_val_list(\"/content/drive/MyDrive/GCC/Part 0\")\n",
        "train_loader = torch.utils.data.DataLoader(ListDataset(train_list,\n",
        "                                                                shuffle=True,\n",
        "                                                                transform=transforms.Compose([\n",
        "                                                                    transforms.ToTensor(), transforms.Resize(480),transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                                                std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=1,\n",
        "                                                                num_workers=1),batch_size=1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size  324\n",
            "val size  36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmFQP8wbWN-e"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(ListDataset(val_list,\n",
        "                                  shuffle=False,\n",
        "                                  transform=transforms.Compose([transforms.ToTensor(), transforms.Resize(480),transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                                                  std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                  ]), train=False),\n",
        "              batch_size=1)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v1ZsRZXBBDC",
        "outputId": "0d5be649-5c63-4593-ab04-4c3c95e20c88"
      },
      "source": [
        "lr = 1e-5\n",
        "criterion = nn.MSELoss(size_average=False).cuda()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.95,weight_decay=5 * 1e-4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiRSQreBBGa1"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gMMTm2eBMXk",
        "outputId": "e088fe9f-6758-4bbe-8647-3f2bbbaecaad"
      },
      "source": [
        "for epoch in range(0,2):\n",
        "    mae_train = 0\n",
        "    losses = AverageMeter()\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    model.train()\n",
        "    end = time.time()\n",
        "\n",
        "    for i, (img, target) in enumerate(train_loader):\n",
        "\n",
        "        img = img.cuda()\n",
        "        img = Variable(img)\n",
        "\n",
        "        #forward\n",
        "        output = model(img)\n",
        "\n",
        "        target = target.type(torch.FloatTensor).unsqueeze(0).cuda()\n",
        "        target = Variable(target)\n",
        "        #print(target.shape)\n",
        "        #print(output.shape)\n",
        "\n",
        "        #backword\n",
        "        loss = criterion(output, target)\n",
        "        losses.update(loss.item(), img.size(0))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "\n",
        "        #calculate the MAE values\n",
        "        pred_map = output.data.cpu().numpy()\n",
        "        gt_map = target.data.cpu().numpy()\n",
        "        mae_train += abs(np.sum(pred_map) -np.sum(gt_map))\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            print('Epoch : {}, train loss : {}'.format(epoch, loss))\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                .format(\n",
        "                epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                data_time=data_time, loss=losses))\n",
        "            \n",
        "    mae_train = mae_train / len(train_loader)\n",
        "    print(' * TESTING MAE {mae:.3f} '.format(mae=mae_train))\n",
        "PATH = '/content/drive/MyDrive/GCC/GCC.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3770: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0, train loss : 60808.46875\n",
            "Epoch: [0][0/324]\tTime 6.422 (6.422)\tData 0.000 (0.000)\tLoss 60808.4688 (60808.4688)\t\n",
            "Epoch : 0, train loss : 23415.83203125\n",
            "Epoch: [0][20/324]\tTime 7.155 (6.930)\tData 0.000 (0.000)\tLoss 23415.8320 (22739.8360)\t\n",
            "Epoch : 0, train loss : 1451.77587890625\n",
            "Epoch: [0][40/324]\tTime 7.385 (6.874)\tData 0.000 (0.000)\tLoss 1451.7759 (35716.5426)\t\n",
            "Epoch : 0, train loss : 32671.890625\n",
            "Epoch: [0][60/324]\tTime 7.107 (6.837)\tData 0.000 (0.000)\tLoss 32671.8906 (30087.3963)\t\n",
            "Epoch : 0, train loss : 32300.404296875\n",
            "Epoch: [0][80/324]\tTime 7.049 (6.800)\tData 0.000 (0.000)\tLoss 32300.4043 (33299.0906)\t\n",
            "Epoch : 0, train loss : 703.3392944335938\n",
            "Epoch: [0][100/324]\tTime 7.170 (6.783)\tData 0.000 (0.000)\tLoss 703.3393 (35122.0315)\t\n",
            "Epoch : 0, train loss : 558.9595947265625\n",
            "Epoch: [0][120/324]\tTime 7.453 (6.767)\tData 0.000 (0.000)\tLoss 558.9596 (34704.8080)\t\n",
            "Epoch : 0, train loss : 34753.12109375\n",
            "Epoch: [0][140/324]\tTime 6.299 (6.757)\tData 0.000 (0.000)\tLoss 34753.1211 (35568.2823)\t\n",
            "Epoch : 0, train loss : 22043.78125\n",
            "Epoch: [0][160/324]\tTime 6.275 (6.758)\tData 0.000 (0.000)\tLoss 22043.7812 (33583.1665)\t\n",
            "Epoch : 0, train loss : 601.3082275390625\n",
            "Epoch: [0][180/324]\tTime 7.055 (6.757)\tData 0.000 (0.000)\tLoss 601.3082 (34565.3332)\t\n",
            "Epoch : 0, train loss : 506.56805419921875\n",
            "Epoch: [0][200/324]\tTime 7.101 (6.742)\tData 0.000 (0.000)\tLoss 506.5681 (34949.0831)\t\n",
            "Epoch : 0, train loss : 226312.28125\n",
            "Epoch: [0][220/324]\tTime 6.285 (6.728)\tData 0.000 (0.000)\tLoss 226312.2812 (38891.5871)\t\n",
            "Epoch : 0, train loss : 1811.581787109375\n",
            "Epoch: [0][240/324]\tTime 7.162 (6.722)\tData 0.000 (0.000)\tLoss 1811.5818 (40408.4032)\t\n",
            "Epoch : 0, train loss : 35186.3671875\n",
            "Epoch: [0][260/324]\tTime 7.045 (6.724)\tData 0.000 (0.000)\tLoss 35186.3672 (40094.8904)\t\n",
            "Epoch : 0, train loss : 38897.46875\n",
            "Epoch: [0][280/324]\tTime 6.293 (6.724)\tData 0.000 (0.000)\tLoss 38897.4688 (39972.2705)\t\n",
            "Epoch : 0, train loss : 352.84423828125\n",
            "Epoch: [0][300/324]\tTime 7.163 (6.720)\tData 0.000 (0.000)\tLoss 352.8442 (38221.0937)\t\n",
            "Epoch : 0, train loss : 555.840576171875\n",
            "Epoch: [0][320/324]\tTime 6.299 (6.723)\tData 0.000 (0.000)\tLoss 555.8406 (36573.5584)\t\n",
            " * TESTING MAE 9058.702 \n",
            "Epoch : 1, train loss : 39711.4765625\n",
            "Epoch: [1][0/324]\tTime 6.313 (6.313)\tData 0.000 (0.000)\tLoss 39711.4766 (39711.4766)\t\n",
            "Epoch : 1, train loss : 20917.2890625\n",
            "Epoch: [1][20/324]\tTime 6.408 (6.344)\tData 0.000 (0.000)\tLoss 20917.2891 (17028.1096)\t\n",
            "Epoch : 1, train loss : 1176.0162353515625\n",
            "Epoch: [1][40/324]\tTime 6.514 (6.355)\tData 0.000 (0.000)\tLoss 1176.0162 (30112.2893)\t\n",
            "Epoch : 1, train loss : 29057.939453125\n",
            "Epoch: [1][60/324]\tTime 6.286 (6.347)\tData 0.000 (0.000)\tLoss 29057.9395 (25698.8461)\t\n",
            "Epoch : 1, train loss : 29151.4453125\n",
            "Epoch: [1][80/324]\tTime 6.301 (6.340)\tData 0.000 (0.000)\tLoss 29151.4453 (28880.1485)\t\n",
            "Epoch : 1, train loss : 377.8259582519531\n",
            "Epoch: [1][100/324]\tTime 6.515 (6.350)\tData 0.000 (0.000)\tLoss 377.8260 (30661.7818)\t\n",
            "Epoch : 1, train loss : 454.3079528808594\n",
            "Epoch: [1][120/324]\tTime 6.533 (6.356)\tData 0.000 (0.000)\tLoss 454.3080 (30382.8517)\t\n",
            "Epoch : 1, train loss : 31167.0\n",
            "Epoch: [1][140/324]\tTime 6.268 (6.353)\tData 0.000 (0.000)\tLoss 31167.0000 (31259.6595)\t\n",
            "Epoch : 1, train loss : 19422.638671875\n",
            "Epoch: [1][160/324]\tTime 6.284 (6.345)\tData 0.000 (0.000)\tLoss 19422.6387 (29571.8136)\t\n",
            "Epoch : 1, train loss : 511.09393310546875\n",
            "Epoch: [1][180/324]\tTime 6.314 (6.341)\tData 0.000 (0.000)\tLoss 511.0939 (30527.6034)\t\n",
            "Epoch : 1, train loss : 486.8945617675781\n",
            "Epoch: [1][200/324]\tTime 6.249 (6.334)\tData 0.000 (0.000)\tLoss 486.8946 (31000.9124)\t\n",
            "Epoch : 1, train loss : 213291.09375\n",
            "Epoch: [1][220/324]\tTime 6.257 (6.329)\tData 0.000 (0.000)\tLoss 213291.0938 (34841.9556)\t\n",
            "Epoch : 1, train loss : 993.4632568359375\n",
            "Epoch: [1][240/324]\tTime 6.308 (6.326)\tData 0.000 (0.000)\tLoss 993.4633 (36343.3656)\t\n",
            "Epoch : 1, train loss : 32186.55078125\n",
            "Epoch: [1][260/324]\tTime 6.275 (6.321)\tData 0.000 (0.000)\tLoss 32186.5508 (36128.6790)\t\n",
            "Epoch : 1, train loss : 36160.44921875\n",
            "Epoch: [1][280/324]\tTime 6.276 (6.319)\tData 0.000 (0.000)\tLoss 36160.4492 (36132.9770)\t\n",
            "Epoch : 1, train loss : 268.0556335449219\n",
            "Epoch: [1][300/324]\tTime 6.293 (6.317)\tData 0.000 (0.000)\tLoss 268.0556 (34560.1454)\t\n",
            "Epoch : 1, train loss : 566.5501098632812\n",
            "Epoch: [1][320/324]\tTime 6.308 (6.316)\tData 0.000 (0.000)\tLoss 566.5501 (33070.8410)\t\n",
            " * TESTING MAE 5149.634 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk6BrwmOmlhJ"
      },
      "source": [
        "'/content/drive/MyDrive/GCC'\n",
        "PATH = '/content/drive/MyDrive/GCC/GCC.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDYXX3ZtbvUd",
        "outputId": "e878f090-a1a8-4cbc-da17-4d4ff4dc87ac"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/GCC/GCC.pth'\n",
        "\n",
        "model = TestNet().cuda()\n",
        "# load the trained model\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "print('successfully load model from', model_path)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  mae = 0\n",
        "\n",
        "  for i, (img, target) in enumerate(test_loader):\n",
        "      img = img.cuda()\n",
        "      img = Variable(img)   \n",
        "      output = model(img)\n",
        "\n",
        "\n",
        "      pred_map = output.data.cpu().numpy()\n",
        "      gt_map = target.data.cpu().numpy()\n",
        "      print(\"Model Predicted Count\", np.sum(pred_map))\n",
        "      print(\"Ground Trueth Count\", np.sum(gt_map))\n",
        "\n",
        "      mae += abs(np.sum(pred_map) -np.sum(gt_map))\n",
        "\n",
        "  mae = mae / len(test_loader)\n",
        "  print(' * TESTING MAE {mae:.3f} '.format(mae=mae))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully load model from /content/drive/MyDrive/GCC/GCC.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3770: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Predicted Count 32626.963\n",
            "Ground Trueth Count 34146.996\n",
            "Model Predicted Count 3591.9443\n",
            "Ground Trueth Count 1313.111\n",
            "Model Predicted Count 4361.9785\n",
            "Ground Trueth Count 19720.186\n",
            "Model Predicted Count 55314.926\n",
            "Ground Trueth Count 44810.703\n",
            "Model Predicted Count 5630.5586\n",
            "Ground Trueth Count 36030.066\n",
            "Model Predicted Count 11203.624\n",
            "Ground Trueth Count 27718.703\n",
            "Model Predicted Count 39146.984\n",
            "Ground Trueth Count 27133.748\n",
            "Model Predicted Count 39274.19\n",
            "Ground Trueth Count 29751.219\n",
            "Model Predicted Count 5354.5405\n",
            "Ground Trueth Count 21848.607\n",
            "Model Predicted Count 35095.14\n",
            "Ground Trueth Count 34788.113\n",
            "Model Predicted Count 15265.731\n",
            "Ground Trueth Count 4138.9697\n",
            "Model Predicted Count 3673.7407\n",
            "Ground Trueth Count 30971.176\n",
            "Model Predicted Count 13528.125\n",
            "Ground Trueth Count 4229.5723\n",
            "Model Predicted Count 35889.105\n",
            "Ground Trueth Count 29751.383\n",
            "Model Predicted Count 14277.929\n",
            "Ground Trueth Count 29101.375\n",
            "Model Predicted Count 2739.3733\n",
            "Ground Trueth Count 736.6368\n",
            "Model Predicted Count 7405.827\n",
            "Ground Trueth Count 4005.4368\n",
            "Model Predicted Count 17982.06\n",
            "Ground Trueth Count 4083.4954\n",
            "Model Predicted Count 6811.877\n",
            "Ground Trueth Count 10548.449\n",
            "Model Predicted Count 40288.816\n",
            "Ground Trueth Count 34442.723\n",
            "Model Predicted Count 17234.762\n",
            "Ground Trueth Count 9282.964\n",
            "Model Predicted Count 9375.435\n",
            "Ground Trueth Count 4156.142\n",
            "Model Predicted Count 7884.941\n",
            "Ground Trueth Count 5024.0786\n",
            "Model Predicted Count 3661.4\n",
            "Ground Trueth Count 34055.37\n",
            "Model Predicted Count 2932.25\n",
            "Ground Trueth Count 10931.692\n",
            "Model Predicted Count 4045.4019\n",
            "Ground Trueth Count 33262.586\n",
            "Model Predicted Count 36087.71\n",
            "Ground Trueth Count 21101.393\n",
            "Model Predicted Count 40328.504\n",
            "Ground Trueth Count 28441.992\n",
            "Model Predicted Count 1219.5327\n",
            "Ground Trueth Count 4219.6533\n",
            "Model Predicted Count 9758.713\n",
            "Ground Trueth Count 3096.3435\n",
            "Model Predicted Count 8875.261\n",
            "Ground Trueth Count 1665.8651\n",
            "Model Predicted Count 11120.479\n",
            "Ground Trueth Count 3899.8523\n",
            "Model Predicted Count 41138.49\n",
            "Ground Trueth Count 36096.133\n",
            "Model Predicted Count 10629.779\n",
            "Ground Trueth Count 3913.3423\n",
            "Model Predicted Count 4715.677\n",
            "Ground Trueth Count 4020.6223\n",
            "Model Predicted Count 4070.0085\n",
            "Ground Trueth Count 4496.9727\n",
            " * TESTING MAE 9999.171 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pQHLrFgBQwG",
        "outputId": "19715c03-e22e-484d-aa93-b35b8c1e1ba1"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen RAM Free: 11.2 GB  | Proc size: 2.6 GB\n",
            "GPU RAM Free: 9718MB | Used: 1723MB | Util  15% | Total 11441MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "20x7Ys_SHfx8",
        "outputId": "b393cdcd-387a-4a10-db68-76254cb607d2"
      },
      "source": [
        "import torch, gc\n",
        "#with torch.no_grad():\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |     776 MB |   10754 MB |   25591 GB |   25590 GB |\\n|       from large pool |     744 MB |   10713 MB |   25555 GB |   25554 GB |\\n|       from small pool |      32 MB |      52 MB |      35 GB |      35 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |     776 MB |   10754 MB |   25591 GB |   25590 GB |\\n|       from large pool |     744 MB |   10713 MB |   25555 GB |   25554 GB |\\n|       from small pool |      32 MB |      52 MB |      35 GB |      35 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    1256 MB |   10880 MB |   33430 MB |   32174 MB |\\n|       from large pool |    1212 MB |   10838 MB |   33360 MB |   32148 MB |\\n|       from small pool |      44 MB |      54 MB |      70 MB |      26 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  490522 KB |    1037 MB |   11091 GB |   11090 GB |\\n|       from large pool |  478477 KB |    1011 MB |   11049 GB |   11049 GB |\\n|       from small pool |   12045 KB |      27 MB |      41 GB |      41 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1032    |    2003    |    1844 K  |    1843 K  |\\n|       from large pool |     107    |     416    |     707 K  |     707 K  |\\n|       from small pool |     925    |    1686    |    1136 K  |    1135 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1032    |    2003    |    1844 K  |    1843 K  |\\n|       from large pool |     107    |     416    |     707 K  |     707 K  |\\n|       from small pool |     925    |    1686    |    1136 K  |    1135 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      87    |     269    |     586    |     499    |\\n|       from large pool |      65    |     248    |     551    |     486    |\\n|       from small pool |      22    |      27    |      35    |      13    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     219    |     234    |    1107 K  |    1106 K  |\\n|       from large pool |      46    |     111    |     405 K  |     405 K  |\\n|       from small pool |     173    |     189    |     701 K  |     701 K  |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VDGo4U6HmEY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}