{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load  GCC gt as csv and and train the model.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMEBJVCBTvEx9LXHw8fNTRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a25cf2937dbd4c949198cf1ba73b4486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a3eecdbf3044047988bfd071336ce52",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6e4f6c3c5424c85846915c70e0539f3",
              "IPY_MODEL_91093e4e01d14861bf0e59032b3db221",
              "IPY_MODEL_45b74a36926a44ebadcc4629c55fe5fd"
            ]
          }
        },
        "3a3eecdbf3044047988bfd071336ce52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6e4f6c3c5424c85846915c70e0539f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e7f0991b9305486eb108d108ce77b0b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89b8b2e4f5224f88916c802f6a2ee433"
          }
        },
        "91093e4e01d14861bf0e59032b3db221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_451786c85c7a40ff88670567c316f46f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553507836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553507836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6940ee516a294c51b8b39bc6b579711a"
          }
        },
        "45b74a36926a44ebadcc4629c55fe5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc9649cf4eef4593aac56127e062d286",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:05&lt;00:00, 109MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a2065310e074ffcb0864b9815a1287c"
          }
        },
        "e7f0991b9305486eb108d108ce77b0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89b8b2e4f5224f88916c802f6a2ee433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "451786c85c7a40ff88670567c316f46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6940ee516a294c51b8b39bc6b579711a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc9649cf4eef4593aac56127e062d286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a2065310e074ffcb0864b9815a1287c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rukmals/crowd-monitoring-system-model-development/blob/main/load_GCC_gt_as_csv_and_and_train_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWCvpL-qLEzC",
        "outputId": "270660ea-3c2b-48b1-d982-09c7e257a33c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwHrZ8FfLbtK",
        "outputId": "e4131915-6a3f-4b2b-dc5f-830e62af0e81"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=b688ac74958a3c796145a2c011d05a8f8ff228410a4ff6326a780c901532b4d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpiL-7tBLoba",
        "outputId": "15b30870-7ed2-4838-a16c-2a6a9ca81d09"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen RAM Free: 26.3 GB  | Proc size: 118.3 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amOitkNdNiZC"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from PIL import Image,ImageFilter,ImageDraw\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import ImageStat\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "# import from library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from torchvision import models"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3557jjBLqu4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, \\\n",
        "                stride=1, NL='relu', same_padding=False, bn=False, dilation=1):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) // 2) if same_padding else 0\n",
        "        self.conv = []\n",
        "        if dilation==1:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=dilation, dilation=dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else nn.Identity()\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU()\n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv(x)\n",
        "      if self.bn is not None:\n",
        "          x = self.bn(x)\n",
        "      if self.relu is not None:\n",
        "          x = self.relu(x)   \n",
        "      return x\n",
        "  \n",
        "# the module definition for the multi-branch in the density head\n",
        "class MultiBranchModule(nn.Module):\n",
        "    def __init__(self, in_channels, sync=False):\n",
        "        super(MultiBranchModule, self).__init__()\n",
        "        self.branch_column1_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column1_2 = BasicConv2d(in_channels//2, in_channels, kernel_size=1, sync=sync)\n",
        "\n",
        "        self.branch_column2_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column2_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=(3, 3), padding=(1, 1), sync=sync)\n",
        "\n",
        "        self.branch_column3_1 = BasicConv2d(in_channels, in_channels//2, kernel_size=1, sync=sync)\n",
        "        self.branch_column3_2 = BasicConv2d(in_channels // 2, in_channels, kernel_size=5, padding=2, sync=sync)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch_1 = self.branch_column1_1(x)\n",
        "        branch_1 = self.branch_column1_2(branch_1)\n",
        "\n",
        "        branch_2 = self.branch_column2_1(x)\n",
        "        branch_2 = self.branch_column2_2(branch_2)\n",
        "\n",
        "        branch_3 = self.branch_column3_1(x)\n",
        "        branch_3 = self.branch_column3_2(branch_3)\n",
        "\n",
        "        outputs = [branch_1, branch_2, branch_3, x]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "# the module definition for the basic conv module\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, sync=False, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        if sync:\n",
        "            # for sync bn\n",
        "            print('use sync inception')\n",
        "            self.bn = nn.SyncBatchNorm(out_channels, eps=0.001)\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)\n",
        "\n",
        "\n",
        "class TestNet(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(TestNet, self).__init__()\n",
        "        \n",
        "        vgg = models.vgg16_bn(pretrained=pretrained)\n",
        "        \n",
        "        self.backend_feat  = [256,128,64]\n",
        "\n",
        "\n",
        "        # Front End Development VGG - 16 \n",
        "        features = list(vgg.features.children())\n",
        "        # get each stage of the VGG - 16\n",
        "        self.features1 = nn.Sequential(*features[0:6])\n",
        "        self.features2 = nn.Sequential(*features[6:13])\n",
        "        self.features3 = nn.Sequential(*features[13:23])\n",
        "        self.features4 = nn.Sequential(*features[23:33])\n",
        "        self.features5 = nn.Sequential(*features[33:43])\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        self.p5 = nn.Sequential(\n",
        "            Conv2d(512, 1024, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p4 = nn.Sequential(\n",
        "            Conv2d(1024, 512, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(512, 256, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p3 = nn.Sequential(\n",
        "            Conv2d(512 , 256, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p2 = nn.Sequential(\n",
        "            Conv2d(256, 128, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "        )\n",
        "\n",
        "        self.p1 = nn.Sequential(\n",
        "            Conv2d(128, 64, 3, same_padding=True, NL='relu'),\n",
        "            Conv2d(64, 64, 3, same_padding=True, NL='relu'),\n",
        "        ) \n",
        "\n",
        "        # Multi-Branch moules\n",
        "        self.multi_branch5 = nn.Sequential(\n",
        "            MultiBranchModule(512),\n",
        "            Conv2d(2048, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch4 = nn.Sequential(\n",
        "            MultiBranchModule(256),\n",
        "            Conv2d(1024, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch3 = nn.Sequential(\n",
        "            MultiBranchModule(128),\n",
        "            Conv2d(512, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch2 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.multi_branch1 = nn.Sequential(\n",
        "            MultiBranchModule(64),\n",
        "            Conv2d(256, 1, 1, same_padding=True)\n",
        "        )\n",
        "\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 5,dilation = True)\n",
        "\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x1)\n",
        "        x3 = self.features3(x2)\n",
        "        x4 = self.features4(x3)\n",
        "        x5 = self.features5(x4)\n",
        "\n",
        "        # Front End Development P1 to P5 \n",
        "        x = self.p5(x5)\n",
        "        x5_out = x\n",
        "        x = F.upsample_bilinear(x, size=x4.size()[2:])\n",
        "\n",
        "        x = torch.cat([x4, x], 1)\n",
        "        x = self.p4(x)\n",
        "        x4_out = x\n",
        "        x = F.upsample_bilinear(x, size=x3.size()[2:])\n",
        "\n",
        "        x = torch.cat([x3, x], 1)\n",
        "        x = self.p3(x)\n",
        "        x3_out = x\n",
        "        x = F.upsample_bilinear(x, size=x2.size()[2:])\n",
        "\n",
        "        x = torch.cat([x2, x], 1)\n",
        "        x = self.p2(x)\n",
        "        x2_out = x\n",
        "        x = F.upsample_bilinear(x, size=x1.size()[2:])\n",
        "\n",
        "        x = torch.cat([x1, x], 1)\n",
        "        x = self.p1(x)\n",
        "        x1_out = x\n",
        "\n",
        "\n",
        "        # multi-branch predictions\n",
        "        x5_density = self.multi_branch5(x5_out)\n",
        "        x4_density = self.multi_branch4(x4_out)\n",
        "        x3_density = self.multi_branch3(x3_out)\n",
        "        x2_density = self.multi_branch2(x2_out)\n",
        "        x1_density = self.multi_branch1(x1_out)\n",
        "\n",
        "        # upsample the multi-branch predictions to be the same with the input size\n",
        "        x5_density = F.upsample_nearest(x5_density, size=x1.size()[2:])\n",
        "        x4_density = F.upsample_nearest(x4_density, size=x1.size()[2:])\n",
        "        x3_density = F.upsample_nearest(x3_density, size=x1.size()[2:])\n",
        "        x2_density = F.upsample_nearest(x2_density, size=x1.size()[2:])\n",
        "        x1_density = F.upsample_nearest(x1_density, size=x1.size()[2:])\n",
        "\n",
        "\n",
        "        density_map = torch.cat([x5_density, x4_density, x3_density, x2_density, x1_density], 1)\n",
        "\n",
        "\n",
        "        x_out = self.backend(density_map)\n",
        "        density_map_out = self.output_layer(x_out)\n",
        "        return density_map_out\n",
        "        #return density_map\n",
        "                \n",
        "                \n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    layers = []\n",
        "    dilation_rates = [2,3,5]\n",
        "    #for v in cfg:\n",
        "    for v in range(len(cfg)):\n",
        "        if cfg[v] == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, cfg[v], kernel_size=3, padding=dilation_rates[v],dilation = dilation_rates[v])\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(cfg[v]), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = cfg[v]\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1QMlYgDLxn8"
      },
      "source": [
        "import numbers\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import torch\n",
        "\n",
        "class LabelNormalize(object):\n",
        "    def __init__(self, para):\n",
        "        self.para = para\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # tensor = 1./(tensor+self.para).log()\n",
        "        tensor = torch.from_numpy(np.array(tensor))\n",
        "        tensor = tensor*self.para\n",
        "        return tensor\n",
        "\n",
        "# ===============================img tranforms============================\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if bbx is None:\n",
        "            for t in self.transforms:\n",
        "                img, mask = t(img, mask)\n",
        "            return img, mask\n",
        "        for t in self.transforms:\n",
        "            img, mask, bbx = t(img, mask, bbx)\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomHorizontallyFlip(object):\n",
        "    def __call__(self, img, mask, bbx=None):\n",
        "        if random.random() < 0.5:# 随机生成0-1之间的浮点数 ，每次执行生成的不一样\n",
        "            if bbx is None:\n",
        "                return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            w, h = img.size\n",
        "            xmin = w - bbx[:,3]\n",
        "            xmax = w - bbx[:,1]\n",
        "            bbx[:,1] = xmin\n",
        "            bbx[:,3] = xmax\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), bbx\n",
        "        if bbx is None:\n",
        "            return img, mask\n",
        "        return img, mask, bbx\n",
        "\n",
        "class RandomCrop(object):\n",
        "    def __init__(self, size, padding=0):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "        self.padding = padding\n",
        "\n",
        "    def __call__(self, img, mask):\n",
        "        # if self.padding > 0:\n",
        "        #     img = ImageOps.expand(img, border=self.padding, fill=0)\n",
        "        #     mask = ImageOps.expand(mask, border=self.padding, fill=0)\n",
        "        #\n",
        "        # assert img.size == mask.size\n",
        "        w, h = img.size\n",
        "        th, tw  = self.size\n",
        "        if w == tw and h == th:\n",
        "            return img, mask\n",
        "        if w < tw or h < th:\n",
        "            return img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST)\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ-2k7BAL50R"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "def load_data(img_path,train = True):\n",
        "    #path = \"/content/drive/MyDrive/GCC_CSV_DataSet/Part 0/scene_00_0/csv_den_maps_k15_s4_544_960\"\n",
        "    gt_path = img_path.replace('.png','.csv').replace('pngs_544_960','csv_den_maps_k15_s4_544_960')\n",
        "    img = Image.open(img_path)\n",
        "    target = pd.read_csv(gt_path, sep=',', header=None).values\n",
        "    target = target.astype(np.float32, copy=False)\n",
        "    target = Image.fromarray(target)\n",
        "    return img,target\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, main_transform = None , img_transform=None, gt_transform = None, train=False, batch_size=1, num_workers=4):\n",
        "        \"\"\"\n",
        "        if you have different image size, then batch_size must be 1\n",
        "        :param root:\n",
        "        :param shape:\n",
        "        :param shuffle:\n",
        "        :param transform:\n",
        "        :param train:\n",
        "        :param seen:\n",
        "        :param batch_size:\n",
        "        :param num_workers:\n",
        "        \"\"\"\n",
        "        #if train:\n",
        "            #root = root *4\n",
        "        if shuffle:\n",
        "            random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.main_transform = main_transform\n",
        "        self.img_transform = img_transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "\n",
        "        if self.main_transform is not None:\n",
        "            img, target = self.main_transform(img, target)\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.gt_transform is not None:\n",
        "            target = self.gt_transform(target)   \n",
        "        return img,target"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "a25cf2937dbd4c949198cf1ba73b4486",
            "3a3eecdbf3044047988bfd071336ce52",
            "e6e4f6c3c5424c85846915c70e0539f3",
            "91093e4e01d14861bf0e59032b3db221",
            "45b74a36926a44ebadcc4629c55fe5fd",
            "e7f0991b9305486eb108d108ce77b0b3",
            "89b8b2e4f5224f88916c802f6a2ee433",
            "451786c85c7a40ff88670567c316f46f",
            "6940ee516a294c51b8b39bc6b579711a",
            "fc9649cf4eef4593aac56127e062d286",
            "2a2065310e074ffcb0864b9815a1287c"
          ]
        },
        "id": "y9JI_qLxL-SG",
        "outputId": "6f0cbb6f-4113-4067-82c9-9e695cc73e3b"
      },
      "source": [
        "model = TestNet()\n",
        "model = model.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a25cf2937dbd4c949198cf1ba73b4486",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b3BMdhvMCyJ"
      },
      "source": [
        "def get_image_path(file_path):\n",
        "  file_path_list = file_path.split(\" \")\n",
        "  scene = file_path_list[3][4:]\n",
        "  image_number = file_path_list[4]\n",
        "  image_path = \"/content/drive/MyDrive/GCC_CSV_DataSet/\"+\"Part\"+\" \"+scene[7]+scene+\"/\"+\"pngs_544_960/\"+image_number+\".png\"\n",
        "  return image_path\n",
        "  \n",
        "def get_image_pathlist(path_list, part):\n",
        "    image_path_list_part_ = []\n",
        "    for line_ in path_list:\n",
        "        if line_.find(part)!=-1:\n",
        "            image_path_list_part_.append(line_)\n",
        "    return image_path_list_part_\n",
        "\n",
        "def extract_image_path_list(image_file, part):\n",
        "  file_ = open(image_file, 'r')\n",
        "  file_list = file_.readlines()\n",
        "  image_path_list_train = []  \n",
        "  for line in file_list:\n",
        "      image_path_list_train.append(get_image_path(line))\n",
        "  train_list = get_image_pathlist(image_path_list_train, part)\n",
        "  print(\"data size: \",len(train_list))\n",
        "  return train_list\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EtfrDC8Mf5q",
        "outputId": "02370f77-5387-4300-fd61-d9e93cdebc6e"
      },
      "source": [
        "train_list = '/content/drive/MyDrive/GCC/train_list.txt'\n",
        "part0_train_list = extract_image_path_list(train_list, \"Part 0\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  1320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbLio890MlVn",
        "outputId": "9f245e63-91a1-4638-8f7a-c2a25b32066e"
      },
      "source": [
        "test_list = '/content/drive/MyDrive/GCC/test_list.txt'\n",
        "part0_test_list = extract_image_path_list(test_list, \"Part 0\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size:  473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUF3XAxSMs-t"
      },
      "source": [
        "sou_main_transform = Compose([\n",
        "        RandomCrop((480,480)),\n",
        "        RandomHorizontallyFlip(),\n",
        "        # Rand_Augment()\n",
        "    ])\n",
        "train_loader = torch.utils.data.DataLoader(ListDataset(part0_train_list,shuffle=True,\n",
        "                                                                main_transform = sou_main_transform,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smrt_CsFO77T"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(ListDataset(part0_test_list,shuffle=True,\n",
        "                                                                main_transform = None,\n",
        "                                                                img_transform=transforms.Compose([\n",
        "                                                                transforms.ToTensor(), \n",
        "                                                                transforms.Normalize(mean=[0.302234709263, 0.291243076324, 0.269087553024],\n",
        "                                                                                 std=[0.227743327618, 0.211051672697, 0.184846073389]),\n",
        "                                                                ]),\n",
        "                                                                gt_transform = transforms.Compose([\n",
        "                                                                                LabelNormalize(100)\n",
        "                                                                ]),\n",
        "                                                                train=True,\n",
        "                                                                batch_size=2,\n",
        "                                                                num_workers=2),batch_size=2)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTXyNkc4NY9_",
        "outputId": "9efebaa6-0d98-4410-8f8d-5535e98c213d"
      },
      "source": [
        "lr = 1e-5\n",
        "criterion = nn.MSELoss(size_average=False).cuda()\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.95,weight_decay=5 * 1e-4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.98)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kyh5kLuNryj"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, cur_val):\n",
        "        self.cur_val = cur_val\n",
        "        self.sum += cur_val\n",
        "        self.count += 1\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry8xBvsGNui5"
      },
      "source": [
        "def mae_mse_update(pred,label,maes,mses=None,ssims=None,psnrs=None,losses=None,cls_id=None):\n",
        "        for num in range(pred.size()[0]):\n",
        "            sub_pred = pred[num].data.cpu().squeeze().numpy()/ 100\n",
        "            sub_label = label[num].data.cpu().squeeze().numpy() / 100\n",
        "            pred_cnt = np.sum(sub_pred)\n",
        "            gt_cnt =   np.sum(sub_label)\n",
        "            mae = abs(pred_cnt - gt_cnt)\n",
        "            mse = (pred_cnt - gt_cnt)*(pred_cnt - gt_cnt)\n",
        "\n",
        "            if ssims and psnrs is not None:\n",
        "                ssims.update(get_ssim(sub_label,sub_pred))\n",
        "                psnrs.update(get_psnr(sub_label,sub_pred))\n",
        "\n",
        "            if cls_id is not None:\n",
        "                maes.update(mae,cls_id)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item(),cls_id)\n",
        "                if mses is not None:\n",
        "                    mses.update(mse,cls_id)\n",
        "            else:\n",
        "                maes.update(mae)\n",
        "                if losses is not None:\n",
        "                    loss = F.mse_loss(pred.detach().squeeze(), label.detach().squeeze())\n",
        "                    losses.update(loss.item())\n",
        "                if mses is not None:\n",
        "                    mses.update(mse)\n",
        "\n",
        "        return pred_cnt,gt_cnt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN6re_JLcWLe",
        "outputId": "f2f19b6b-5647-47a9-8776-ac361b4805bd"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/TestNet_checkpoint_Part0_data_aug.pth'\n",
        "epoch = 4\n",
        "start_epoch = 0\n",
        "if (os.path.isfile(PATH))==True:\n",
        "  checkpoint = torch.load(PATH)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"Successfully load the check point\")\n",
        "else:\n",
        "  print(\"No check point Available!!!\")\n",
        "print(epoch , start_epoch)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No check point Available!!!\n",
            "4 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T7Z1ikiidqE",
        "outputId": "b49b11b1-4714-4f4a-baaf-c35492f5fa78"
      },
      "source": [
        "train_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/train_mae.txt\",\"a\")\n",
        "test_mae_file = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/test_mae.txt\",\"a\")\n",
        "train_mae_file.truncate(0)\n",
        "test_mae_file.truncate(0)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD8Mk-7MNzTf",
        "outputId": "995752d3-3b54-47c6-c5ee-0456c3a2b09d"
      },
      "source": [
        "for epoch in range(0,epoch):\n",
        "    mae_train = 0\n",
        "    losses = AverageMeter()\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    model.train()\n",
        "    end = time.time()\n",
        "    loss_list = []\n",
        "    mae_list =[]\n",
        "    best_predict_mae = 2000\n",
        "    train_mae = AverageMeter()\n",
        "    train_mse = AverageMeter()\n",
        "    for i, (img, target) in enumerate(train_loader):\n",
        "\n",
        "        img = img.cuda()\n",
        "        img = Variable(img)\n",
        "\n",
        "       \n",
        "        output = model(img)\n",
        "\n",
        "        loss = criterion(output.squeeze(), target.squeeze().cuda())\n",
        "        losses.update(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "\n",
        "        #calculate the MAE values\n",
        "        pred_map = output.data.cpu().numpy()\n",
        "        gt_map = target.data.cpu().numpy()\n",
        "        mae_train += abs(np.sum(pred_map) -np.sum(gt_map))\n",
        "\n",
        "        sou_pred_cnt, sou_label_cnt = mae_mse_update(output, target, train_mae, train_mse)\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch {}, Loss={:.4f} s_gt={:.1f} s_pre={:.1f}, lr={:.4f}'.format(\n",
        "                    epoch, loss.item(), sou_label_cnt,sou_pred_cnt, optimizer.param_groups[0]['lr']*10000))\n",
        "    \n",
        "    scheduler.step()  \n",
        "    mae_list.append(mae_train / len(train_loader))\n",
        "    loss_list.append(loss)\n",
        "    mae_train = mae_train / len(train_loader)\n",
        "    print('train_mae_sou', float(train_mae.avg), epoch)\n",
        "    print('train_mse_sou', float(np.sqrt(train_mse.avg)), epoch)\n",
        "    train_mae_file.write(str(train_mae.avg))\n",
        "    train_mae_file.write(\"\\n\")\n",
        "    torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, PATH) \n",
        "    print(\"testing...................\")  \n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      mae_test = 0\n",
        "      test_mae = AverageMeter()\n",
        "      test_mse = AverageMeter()\n",
        "      for j, (img_test, target_test) in enumerate(test_loader):\n",
        "          img_test = img_test.cuda()\n",
        "          img_test = Variable(img_test)   \n",
        "          output_test = model(img_test)\n",
        "\n",
        "          sou_pred_cnt_test, sou_label_cnt_test = mae_mse_update(output_test, target_test, test_mae, test_mse)\n",
        "          if j % 100 == 0:\n",
        "            print('Epoch {}, s_gt={:.1f} s_pre={:.1f} '.format(epoch, sou_label_cnt_test,sou_pred_cnt_test))\n",
        "      print('test_mae_sou', float(test_mae.avg), epoch)\n",
        "      print('test_mse_sou', float(np.sqrt(test_mse.avg)), epoch)\n",
        "      test_mae_file.write(str(test_mae.avg))\n",
        "      test_mae_file.write(\"\\n\")\n",
        "\n",
        "train_mae_file.close()\n",
        "test_mae_file.close()\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/GCC_CSV_DataSet/model/GCC_part0_csv.pth'\n",
        "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3770: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss=73910.4922 s_gt=1062.2 s_pre=1008.9, lr=0.0904\n",
            "train_mae_sou 121.94409040971236 0\n",
            "train_mse_sou 137.6792211795715 0\n",
            "testing...................\n",
            "Epoch 0, s_gt=37.0 s_pre=357.9 \n",
            "test_mae_sou 175.8745618547712 0\n",
            "test_mse_sou 202.86193309170915 0\n",
            "Epoch 1, Loss=54518.0859 s_gt=946.0 s_pre=997.1, lr=0.0904\n",
            "train_mae_sou 243.99453596635297 1\n",
            "train_mse_sou 406.95904198596827 1\n",
            "testing...................\n",
            "Epoch 1, s_gt=37.0 s_pre=381.6 \n",
            "test_mae_sou 172.30843244280135 1\n",
            "test_mse_sou 200.04243899621292 1\n",
            "Epoch 2, Loss=53811.8906 s_gt=1067.3 s_pre=1102.2, lr=0.0886\n",
            "train_mae_sou 218.41845703125 2\n",
            "train_mse_sou 362.8225603430092 2\n",
            "testing...................\n",
            "Epoch 2, s_gt=37.0 s_pre=370.5 \n",
            "test_mae_sou 158.86172703334265 2\n",
            "test_mse_sou 186.3009186673994 2\n",
            "Epoch 3, Loss=85896.5078 s_gt=1474.0 s_pre=1507.1, lr=0.0886\n",
            "testing...................\n",
            "Epoch 3, s_gt=37.0 s_pre=529.9 \n",
            "test_mae_sou 204.77099391392298 3\n",
            "test_mse_sou 247.81094258375143 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZvqFo-9OEoW"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_ZGUW82emSM"
      },
      "source": [
        "file2 = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/train_mae.txt\",\"r\")\n",
        "file3 = open(\"/content/drive/MyDrive/GCC_CSV_DataSet/test_mae.txt\",\"r\")\n",
        "List = file2.readlines()\n",
        "List2 = file3.readlines()\n",
        "epochs=[]\n",
        "y_train = []\n",
        "y_test = []\n",
        "for i_ in range(len(List)):\n",
        "  y_train.append(float(List[i_]))\n",
        "  epochs.append(i_)\n",
        "for j_ in range(len(List2)):\n",
        "  y_test.append(float(List2[j_]))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "JBvN2cuaew_I",
        "outputId": "34140350-026f-403c-ddc1-ce09f6e22b9c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x1 = epochs\n",
        "y1 = y_train\n",
        "y2 = y_test\n",
        "plt.plot(x1, y1)\n",
        "plt.plot(x1, y2)\n",
        "\n",
        "plt.legend([\"Train MAE\", \"Test MAE\"])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3602231990>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHdNrlmhzlS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}